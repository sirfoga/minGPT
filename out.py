 1/1: import os
 1/2:
import os

os.printcwd()
 1/3:
import os

os.getcwd()
 4/1:
import os

os.getcwd()
 4/2: import tensorflow
 5/1: import tensorflow
 5/2: import tensorflow as tf
 6/1:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  here = os.path.abspath(os.path.dirname(__file__))
  data_path = ps.path.join(here, '../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/2: os.getcwd()
 6/3:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = ps.path.join(here, '../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/4:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = os.path.join(here, '../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/5:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here + '../data/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/6:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here + '../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/7:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here + '/../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/8:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here / '../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
 6/9:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here).joinpath('../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
6/10:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here).joinpath('/../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
6/11:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = Path(here).joinpath('../data/fluo')

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
6/12:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
data_path
6/13: os.walk(data_path)
6/14: list(os.walk(data_path))
6/15:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/16:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('data/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/17: list(os.walk(data_path))
6/18:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('data/toy/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/19: list(os.walk(data_path))
6/20:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../../data/toy/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/21: list(os.walk(data_path))
6/22:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}'.format(data_path))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/23: list(os.walk(data_path))
6/24: list(os.walk(data_path))[1]
6/25: list(os.walk(data_path))[2]
6/26: list(os.walk(data_path))[1]
6/27: list(os.walk(data_path))
6/28: list(os.walk(data_path))[0]
6/29: list(os.walk(data_path))[0][1]
6/30:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (128, 128)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/31:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
6/32:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()
6/33: plot_train_sample(X_train, y_train)  # check if training data looks all right
6/34: plot_train_sample(X_train, y_train)  # check if training data looks all right
6/35:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = "grayscale"))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
6/36:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = "grayscale"))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = "grayscale"))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
6/37:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()
6/38: plot_train_sample(X_train, y_train)  # check if training data looks all right
6/39:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
6/40:
def unet(input_size, dropout, batch_norm):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    drop4 = Dropout(dropout)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    return Model(inputs = inputs, outputs = conv10)


model = unet(input_shape, 0.5, True)
model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
# model.summary()
6/41:
callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
6/42:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
6/43:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
6/44:
plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
6/45:
# plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
6/46:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
6/47:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
6/48:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # plt.plot(results.history["accuracy"], label="accuracy")
    # plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
6/49: tf.config.list_physical_devices(
6/50: tf.config.list_physical_devices()
6/51: tf.__VERSION__
6/52: tf.version
6/53: tf.version()
6/54: tf.version
6/55: tf.config.list_physical_devices('GPU')
6/56: tf.config.experimental.list_physical_devices(device_type=None)
6/57:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (10000, 10000)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/58:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = "grayscale"))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = "grayscale"))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
6/59:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (1024, 512)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
6/60:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = "grayscale"))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = "grayscale"))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
6/61:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # plt.plot(results.history["accuracy"], label="accuracy")
    # plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
6/62:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_height, im_width = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = "grayscale"))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = "grayscale"))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
6/63:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # plt.plot(results.history["accuracy"], label="accuracy")
    # plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
6/64:
def unet(input_size, dropout, batch_norm):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    drop4 = Dropout(dropout)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    return Model(inputs = inputs, outputs = conv10)


model = unet(input_shape, 0.5, True)
model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
# model.summary()
6/65:
callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=20, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
6/66:
def unet(input_size, dropout, batch_norm):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    drop4 = Dropout(dropout)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    return Model(inputs = inputs, outputs = conv10)


model = unet((1024, 512, 1)), 0.5, True)
model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
# model.summary()
6/67:
def unet(input_size, dropout, batch_norm):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    drop4 = Dropout(dropout)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    return Model(inputs = inputs, outputs = conv10)


model = unet((1024, 512, 1), 0.5, True)
model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
# model.summary()
6/68:
callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=20, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
6/69:
def unet(input_size, dropout, batch_norm):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    drop4 = Dropout(dropout)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    return Model(inputs = inputs, outputs = conv10)


model = unet((512, 1024, 1), 0.5, True)
model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
# model.summary()
6/70:
callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=20, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
6/71:
callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=4, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
 7/1:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
 7/2:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (1024, 512)
input_shape = (*image_size, 1)
verbose = 1
batch_size = 3
epochs = 25
best_model_weights = 'model.h5'
 7/3:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_height, im_width = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = "grayscale"))
        img = resize(img, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = "grayscale"))
        mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test
 7/4:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # plt.plot(results.history["accuracy"], label="accuracy")
    # plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
 7/5:
def unet(input_size, dropout, batch_norm):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    if batch_norm:
        conv1 = BatchNormalization(axis=3)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    if batch_norm:
        conv2 = BatchNormalization(axis=3)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    if batch_norm:
        conv3 = BatchNormalization(axis=3)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    if batch_norm:
        conv4 = BatchNormalization(axis=3)(conv4)
    drop4 = Dropout(dropout)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    return Model(inputs = inputs, outputs = conv10)


model = unet((512, 1024, 1), 0.5, True)
model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
# model.summary()
 7/6:
callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=4, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
 9/1:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
11/1:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
11/2:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = 'grayscale'))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = 'grayscale'))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
11/3:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/4:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/5:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0)
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/6:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0])
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/7:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/8:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, color_mode = 'grayscale'))
        img = resize(img, (im_width, im_height, 1), mode='reflect', preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = 'grayscale'))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
11/9:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/10:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        # img = resize(img, (im_width, im_height, 1), preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, color_mode = 'grayscale'))
        # mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
11/11:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/12:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
11/13:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/14:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout*0.5)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer=Adam(), loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()

from tensorflow.keras import backend as K
K.clear_session()
11/15:
import os

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
11/16:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout*0.5)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer=Adam(), loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()

from tensorflow.keras import backend as K
K.clear_session()
11/17:
verbose = 1
batch_size = 4
epochs = 20

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
11/18:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout*0.5)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()

from tensorflow.keras import backend as K
K.clear_session()
11/19:
verbose = 1
batch_size = 4
epochs = 20

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
11/20:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout*0.5)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()

# from tensorflow.keras import backend as K
# K.clear_session()
11/21:
verbose = 1
batch_size = 4
epochs = 20

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
11/22:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
11/23:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
11/24:
model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)

# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
12/1:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(results.history["accuracy"], label="accuracy")
    plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
12/2:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))

image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
12/3:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
12/4:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
12/5:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout*0.5)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
12/6:
verbose = 1
batch_size = 4
epochs = 20

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
12/7:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
12/8:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        save_img(img, 'wow.png')

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
12/9:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        save_img('wow.png', img)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
12/10:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        save_img('1.png', img)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)
        save_img('2.png', img)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
12/11: tf.config.list_physical_devices(
12/12: tf.config.list_physical_devices()
12/13: tf.experimental.config.list_physical_devices()
12/14: tf.config.experimental.list_physical_devices()
13/1:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
13/2:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt
13/3:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
13/4:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
13/5:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        save_img('1.png', img)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)
        save_img('2.png', img)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/6:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        save_img('1.png', img)
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        # save_img('1.png', img)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)
        save_img('2.png', img)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/7:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name))
        save_img('1.jpg', img)

        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        # save_img('1.png', img)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)
        save_img('2.png', img)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/8:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        x = load_img(imgs_path + '/' + img_name, grayscale=True)
        save_img('1.png', x)
        
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/9:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img, resize_img

import random
import numpy as np
from matplotlib import pyplot as plt
13/10:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img, resize

import random
import numpy as np
from matplotlib import pyplot as plt
13/11:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img, resize_img

import random
import numpy as np
from matplotlib import pyplot as plt
13/12:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img, resize_image

import random
import numpy as np
from matplotlib import pyplot as plt
13/13:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt
13/14:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/15:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/16:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        print(i)
        print(imgs_path + '/' + img_name)
        
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/17:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  # data_path = str(Path(here).joinpath('../data/toy/fluo'))
  data_path = '/home/h4/stfo194b/rp/martin/attila/data'

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
13/18:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  # data_path = str(Path(here).joinpath('../data/toy/fluo'))
  data_path = '/home/h4/stfo194b/rp/martin/attila/data/toy'

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
13/19:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  # data_path = str(Path(here).joinpath('../data/toy/fluo'))
  data_path = '/home/h4/stfo194b/rp/martin/attila/data/toy/fluo'

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
13/20:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        print(i)
        print(imgs_path + '/' + img_name)
        
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/21:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, (im_width, im_height, 1), preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, (im_width, im_height, 1), preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/22:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/23:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path += '/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
13/24:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/25:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/26:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/27:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = load_img(imgs_path + '/' + img_name, grayscale=True)
        img.show()
        img = resize(img, input_shape, preserve_range=True)
        
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/28:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = load_img(imgs_path + '/' + img_name, grayscale=True)
        img.show()
        img = img_to_array(img)
        img = resize(img, input_shape, preserve_range=True)
        
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/29:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        save_img('1.tiff', img, grayscale=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/30:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/31: X_train[0]
13/32: list(np.where(X_train > 0))
13/33: len(list(np.where(X_train > 0)))
13/34: list(np.where(X_train > 0))
13/35:
import IPython
def showimg(a):
    IPython.display.display(PIL.Image.fromarray(a))
13/36: showimg(X_train[0])
13/37:
import IPython
import PIL
def showimg(a):
    IPython.display.display(PIL.Image.fromarray(a))
13/38: showimg(X_train[0])
13/39:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        showimg(img)

        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/40:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = load_img(imgs_path + '/' + img_name, grayscale=True)
        showimg(img)

        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/41:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/42:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/43:
image_size = (1100, 700)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
13/44:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/45:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/46:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
13/47:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    list_imgs = next(os.walk(imgs_path))[2]
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        mask_name = img_name.replace('img_', 'mask_')
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/48:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    im_width, im_height = im_size
    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    
    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]
    
    for (i, img_name), (_, mask_name) in zip(list_imgs, list_masks):
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/49:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    y = np.zeros((len(list_imgs), im_width, im_height, 1), dtype=np.float32)
    
    for (i, img_name), (_, mask_name) in zip(list_imgs, list_masks):
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/50:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for (i, img_name), (_, mask_name) in zip(list_imgs, list_masks):
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/51:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for a, b in zip(list_imgs, list_masks):
        print(a, b)
        
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/52:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/53:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/54:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img = img_to_array(load_img(imgs_path + '/' + img_name, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze() / 255.0
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/55:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/56:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath('/').joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/57:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask = img_to_array(load_img(masks_path + '/' + mask_name, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/58:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
13/59:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
13/60:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
13/61:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
13/62:
verbose = 1
batch_size = 8
epochs = 50

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
13/63:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
13/64:
verbose = 1
batch_size = 32
epochs = 100

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/1:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
14/2:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
14/3:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt
14/4:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path += '/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
14/5:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
14/6:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/7:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/8:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/9:
verbose = 1
batch_size = 32
epochs = 100

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/10:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/11:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/12:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/13:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/14:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/15:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/16:
plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
# plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/17:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/18:
verbose = 1
batch_size = 8
epochs = 50

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/19:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/20:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/21:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/22:
image_size = (1024, 512)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
14/23:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/24:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/25:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/26:
verbose = 1
batch_size = 8
epochs = 50

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/27:
verbose = 1
batch_size = 4
epochs = 50

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/28:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
14/29:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img

import random
import numpy as np
from matplotlib import pyplot as plt
14/30:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path += '/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
14/31:
image_size = (1024, 512)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
14/32:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/33:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/34:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/35:
verbose = 1
batch_size = 4
epochs = 50

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/36:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
14/37:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/38:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True))
        img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/39:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/40:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.5, batchnorm=False)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/41:
verbose = 1
batch_size = 4
epochs = 50

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/42:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/43:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True, target_size=image_size))
        # img = resize(img, input_shape, preserve_range=True)
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True))
        mask = resize(mask, input_shape, preserve_range=True)

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/44:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/45:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True, target_size=image_size))
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True, target_size=image_size))

        # save images
        X[i, ..., 0] = img.squeeze()
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/46:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/47:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].contour(X[ix, ..., 0], colors='yellow')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/48:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/49:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0])
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/50:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True, target_size=image_size))
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True, target_size=image_size))

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/51:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0])
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/52:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/53:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True, target_size=image_size))
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True, target_size=image_size))

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/imags', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/54:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/55:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, colormode='grayscale', target_size=image_size))
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True, target_size=image_size))

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/56:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True, target_size=image_size))
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True, target_size=image_size))

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
14/57:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
14/58:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/59:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/60:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='softmax') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.05, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/61:
verbose = 1
batch_size = 4
epochs = 30

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/62:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape, name='img')
model = get_unet(input_img, 64, dropout=0.05, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/63:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 32, dropout=0.05, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/64:
verbose = 1
batch_size = 4
epochs = 30

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/65:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/66:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 128, dropout=0.05, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/67:
verbose = 1
batch_size = 4
epochs = 30

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/68:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/69:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/70:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 64, dropout=0.7, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/71:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 64, dropout=0.3, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
14/72:
verbose = 1
batch_size = 4
epochs = 30

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
14/73:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/74:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
14/75:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
15/1:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
15/2:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from tifffile import imread

import random
import numpy as np
from matplotlib import pyplot as plt
15/3: !pip install tifffile
15/4: !pip install --user tifffile
15/5:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from tifffile import imread

import random
import numpy as np
from matplotlib import pyplot as plt
15/6:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from tifffile import imread

import random
import numpy as np
from matplotlib import pyplot as plt
16/1:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
16/2:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from tifffile import imread

import random
import numpy as np
from matplotlib import pyplot as plt
16/3:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path += '/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
16/4:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
16/5:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        # load images
        img_path = str(Path(imgs_path).joinpath(img_name))
        img = img_to_array(load_img(img_path, grayscale=True, target_size=image_size))
        
        # load masks
        mask_path = str(Path(masks_path).joinpath(mask_name))
        mask = img_to_array(load_img(mask_path, grayscale=True, target_size=image_size))

        # save images
        X[i, ..., 0] = img.squeeze() / 255
        y[i] = mask / 255

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
16/6:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = resize(img, im_size)
        
        if normalize:  
            # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r

        return img
    
    def load_img(name):
        img_path = str(Path(imgs_path).joinpath(name))
        return load_tiff(img_path, normalize=True)
    
    def load_mask(name):
        mask_path = str(Path(masks_path).joinpath(name))
        return load_tiff(mask_path, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        X[i, ..., 0] = load_img(img_name).squeeze()
        y[i] = load_mask(mask_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
16/7:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
16/8:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
16/9:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 64, dropout=0.3, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
16/10:
verbose = 1
batch_size = 4
epochs = 20

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
17/1:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/2:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
17/3:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from tifffile import imread

import random
import numpy as np
from matplotlib import pyplot as plt
17/4:
try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path += '/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
17/5:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
17/6:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = resize(img, im_size)
        
        if normalize:  
            # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r  # todo: very slow

        return img
    
    def load_img(name):
        img_path = str(Path(imgs_path).joinpath(name))
        return load_tiff(img_path, normalize=True)
    
    def load_mask(name):
        mask_path = str(Path(masks_path).joinpath(name))
        return load_tiff(mask_path, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        X[i, ..., 0] = load_img(img_name).squeeze()
        y[i] = load_mask(mask_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
17/7:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/8:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 64, dropout=0.3, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
17/9:
verbose = 1
batch_size = 4
epochs = 20

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
17/10:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
17/11:
image_size = (256, 256)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
17/12:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = resize(img, im_size)
        
        if normalize:  
            # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r  # todo: very slow

        return img
    
    def load_img(name):
        img_path = str(Path(imgs_path).joinpath(name))
        return load_tiff(img_path, normalize=True)
    
    def load_mask(name):
        mask_path = str(Path(masks_path).joinpath(name))
        return load_tiff(mask_path, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        X[i, ..., 0] = load_img(img_name).squeeze()
        y[i] = load_mask(mask_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
17/13:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].set_title('image (input)')

    ax[1].imshow(y[ix].squeeze(), cmap='gray')
    ax[1].set_title('mask (output)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    # todo plt.plot(results.history["accuracy"], label="accuracy")
    # todo plt.plot(results.history["val_accuracy"], label="val_acc")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/14:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    plt.set_title('image (input)')

    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/15:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/16:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/17:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/18:
image_size = (1100, 700)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
17/19:
def get_data(imgs_path, masks_path, im_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = resize(img, im_size)
        
        if normalize:  
            # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r  # todo: very slow

        return img
    
    def load_img(name):
        img_path = str(Path(imgs_path).joinpath(name))
        return load_tiff(img_path, normalize=True)
    
    def load_mask(name):
        mask_path = str(Path(masks_path).joinpath(name))
        return load_tiff(mask_path, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]
    list_masks = next(os.walk(masks_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, (img_name, mask_name) in enumerate(zip(list_imgs, list_masks)):
        X[i, ..., 0] = load_img(img_name).squeeze()
        y[i] = load_mask(mask_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
17/20:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/21:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
17/22:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
18/1:
import os

from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
18/2:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tifffile import imread
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img, smart_resize
from sklearn.model_selection import train_test_split

import random
import numpy as np
from matplotlib import pyplot as plt
18/3:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tifffile import imread
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split

import random
import numpy as np
from matplotlib import pyplot as plt
18/4:
import os

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = '/content/gdrive/My Drive/Colab Notebooks/martin/fluo'
  # augmented: data_path += '/aug'
except:
  import os
  from pathlib import Path
  here = os.getcwd()  # os.path.abspath(os.path.dirname(__file__))
  data_path = str(Path(here).joinpath('../data/toy/fluo'))

print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
18/5:
image_size = (128, 128)  # original is 1100 x 700
input_shape = (*image_size, 1)
best_model_weights = 'model.h5'
18/6:
def get_data(imgs_path, masks_path, image_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = smart_resize(img, image_size)
        
        if normalize:  # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r  # todo very slow

        return img
    
    def load_image(name):
        f = str(Path(imgs_path).joinpath(name))
        return load_tiff(f, normalize=True)
    
    def load_mask(name):
        name = name.replace('img_', 'mask_')  # respective mask
        f = str(Path(masks_path).joinpath(name))
        return load_tiff(f, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float16)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float16)
    
    for i, img_name in enumerate(list_imgs):
        X[i, ..., 0] = load_image(img_name).squeeze()
        y[i] = load_mask(img_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
18/7:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tifffile import imread
from sklearn.transform import resize
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split

import random
import numpy as np
from matplotlib import pyplot as plt
18/8:
from tensorflow.keras import Input, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tifffile import imread
from skimage.transform import resize
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split

import random
import numpy as np
from matplotlib import pyplot as plt
18/9:
def get_data(imgs_path, masks_path, image_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = resize(img, image_size)
        
        if normalize:  # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r  # todo very slow

        return img
    
    def load_image(name):
        f = str(Path(imgs_path).joinpath(name))
        return load_tiff(f, normalize=True)
    
    def load_mask(name):
        name = name.replace('img_', 'mask_')  # respective mask
        f = str(Path(masks_path).joinpath(name))
        return load_tiff(f, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float16)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float16)
    
    for i, img_name in enumerate(list_imgs):
        X[i, ..., 0] = load_image(img_name).squeeze()
        y[i] = load_mask(img_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
18/10:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
18/11:
def get_data(imgs_path, masks_path, image_size):
    """ Get and resize train images and masks """
    
    def load_tiff(f, normalize=False):
        img = imread(f)
        img = img_to_array(img)
        img = resize(img, image_size)
        
        if normalize:  # normalize in [0, 1]
            m = min(img.ravel())
            M = max(img.ravel())
            r = M - m
            img = (img - m) / r  # todo very slow

        return img
    
    def load_image(name):
        f = str(Path(imgs_path).joinpath(name))
        return load_tiff(f, normalize=True)
    
    def load_mask(name):
        name = name.replace('img_', 'mask_')  # respective mask
        f = str(Path(masks_path).joinpath(name))
        return load_tiff(f, normalize=True)

    list_imgs = next(os.walk(imgs_path))[2]

    X = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    y = np.zeros((len(list_imgs), *input_shape), dtype=np.float32)
    
    for i, img_name in enumerate(list_imgs):
        X[i, ..., 0] = load_image(img_name).squeeze()
        y[i] = load_mask(img_name)

    return X, y

# get data
X, y = get_data(data_path + '/images', data_path + '/masks', image_size)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)  # split train and test

print('found {} samples: {} training, {} validation'.format(len(X), len(X_train), len(X_valid)))
18/12:
def plot_train_sample(X, y, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    plt.figure(figsize=(16, 16))
    plt.imshow(X[ix, ..., 0], cmap='gray')
    plt.contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    
    return ix

def plot_pred_sample(X, y, preds, ix=None):
    if ix is None:
        ix = random.randint(0, len(X) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(16, 8))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    ax[0].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[0].set_title('image + mask')

    ax[1].imshow(preds[ix].squeeze(), cmap='gray')
    ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('predicted + original mask')

    return ix

def plot_results(results):
    plt.figure(figsize=(24, 8))

    plt.plot(results.history["loss"], label="loss")
    plt.plot(results.history["val_loss"], label="val_loss")
    plt.plot(np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")

    plt.xlabel("epochs")
    plt.ylabel("log loss")
    plt.legend()

plot_train_sample(X_train, y_train)  # check if training data looks all right
18/13:
def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal",
               padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters, dropout=0.5, batchnorm=True):
    pooling = MaxPooling2D

    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = pooling((2, 2)) (c1)
    p1 = Dropout(dropout)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = pooling((2, 2)) (c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = pooling((2, 2)) (c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = pooling((2, 2)) (c4)
    p4 = Dropout(dropout)(p4)

    # u path
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input(input_shape)
model = get_unet(input_img, 64, dropout=0.3, batchnorm=True)

model.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])
# model.summary()
18/14:
verbose = 1
batch_size = 4
epochs = 30

callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(best_model_weights, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]
results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))

plot_results(results)

model.load_weights(best_model_weights)  # load best model
model.evaluate(X_valid, y_valid, verbose=verbose)  # evaluate on validation set

preds_train = model.predict(X_train, verbose=verbose)  # predict
preds_val = model.predict(X_valid, verbose=verbose)
18/15:
# plot_pred_sample(X_train, y_train, preds_train)  # predictions on training data
plot_pred_sample(X_valid, y_valid, preds_val)  # predictions on test data
24/1:
import time
import torch
from options.train_options import TrainOptions
from data import create_dataset
from models import create_model
from util.visualizer import Visualizer
24/2: opt = TrainOptions().parse()   # get training options
24/3: opt = TrainOptions()   # get training options
24/4: opt = TrainOptions()   # get training options
24/5: opt
25/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
25/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
25/3: tf.version.__version__
25/4: tf.version
25/5: tf.version.VERSION
25/6: tf.version.VERSION
25/7: tensorflow.keras.version
25/8: tf.keras.version
25/9: tf.keras.VERSION
25/10: import keras
25/11: from keras.layers.experimental.preprocessing import CenterCrop
25/12:
class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
25/13:
from tensorflow.keras import Layer

class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
25/14:
from tensorflow.python.keras.engine.base_layer import Layer

class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
25/15:
from tensorflow.python.keras.engine.base_layer import Layer

class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
25/16:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
25/17:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
25/18:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
25/19:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = list(imgs_path.iterdir())
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
25/20:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y

def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    crop_center_transformation(img_shape),
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
25/21:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
25/22: images, masks
25/23:
get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
25/24:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = list(imgs_path.iterdir())
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    print(img_path)
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
25/25:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = list(imgs_path.iterdir())
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    print(img_path)
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks

get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
25/26:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if f.endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    print(img_path)
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks

get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
25/27:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    print(img_path)
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks

get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
25/28:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    print(img_path)
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
25/29:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
25/30:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
25/31:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
25/32:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(12, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')
    
  return ix
25/33: plot_sample(X, y)  # check if data looks all right
25/34:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters *= 2
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = x.shape[-1] * 2
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters /= 2

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
25/35:
def do_training(model, X_train, X_test, y_train, y_testbest_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
25/36:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
25/37:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
25/38:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
      rm_percentiles_transformation(1, 98),  # threshold outliers
      normalize_transformation((0, 1)),  # pixel values in [0, 1]
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
25/39:
def plot_pred_sample(X, y, preds, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  
  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image + mask (contour)')

  ax[1].imshow(preds[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('predicted + original mask (contour)')

  return ix
25/40:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
25/41:
from tensorflow.python.eager import context
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.framework import tensor_shape
from tensorflow.python.framework import tensor_util
from tensorflow.python.keras import backend as K
from tensorflow.python.keras.engine.base_layer import Layer
from tensorflow.python.keras.engine.input_spec import InputSpec
from tensorflow.python.keras.utils import tf_utils
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import check_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import image_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import stateful_random_ops
from tensorflow.python.ops import stateless_random_ops
from tensorflow.python.ops import variables
from tensorflow.python.util.tf_export import keras_export

ResizeMethod = image_ops.ResizeMethod

class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
25/42:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
25/43:
from tensorflow.python.eager import context
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.framework import tensor_shape
from tensorflow.python.framework import tensor_util
from tensorflow.python.keras import backend as K
from tensorflow.python.keras.engine.base_layer import Layer
from tensorflow.python.keras.engine.input_spec import InputSpec
from tensorflow.python.keras.utils import tf_utils
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import check_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import image_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import stateful_random_ops
from tensorflow.python.ops import stateless_random_ops
from tensorflow.python.ops import variables
from tensorflow.python.util.tf_export import keras_export

ResizeMethod = image_ops.ResizeMethod

H_AXIS = 1
W_AXIS = 2

class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
25/44:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
25/45:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
25/46:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
25/47:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
25/48:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
25/49:
def plot_pred_sample(X, y, preds, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  
  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image + mask (contour)')

  ax[1].imshow(preds[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('predicted + original mask (contour)')

  return ix
25/50:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for ax, experiment in zip(axis, experiments):
  results = experiment['results']
  
  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
25/51:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for ax, experiment in zip(axis, experiments):
  results = experiment['results']

  print(ax)
  
  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
25/52:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for ax, experiment in zip(axis, experiments):
  results = experiment['results']

  print(axis)
  
  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
25/53:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for i, experiment in enumerate(experiments):
  results = experiment['results']

  print(axis[i])
  
  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
25/54:
fig, ax = plt.subplots(2, 2, figsize=(12, 8))

for i, experiment in enumerate(experiments):
  results = experiment['results']

  print(axis[i])
  
  ax[i].plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
25/55:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
25/56:
ix = None

for experiment in experiments:
  print(experiment['best_model_weights'])
  ix = plot_pred_sample(X, y, experiment['pred'], ix=ix)
25/57:
def plot_pred_sample(X, y, preds, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  
  im = ax[0].imshow(X[ix, ..., 0], cmap='gray')
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image + mask (contour)')

  ax[1].imshow(preds[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('predicted + original mask (contour)')

  return ix


ix = None

for experiment in experiments:
  print(experiment['best_model_weights'])
  ix = plot_pred_sample(X, y, experiment['pred'], ix=ix)
25/58:
def plot_pred_sample(X, y, preds, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  
  im = ax[0].imshow(X[ix, ..., 0], cmap='gray')
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image + mask (contour)')

  ax[1].imshow(preds[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('predicted + original mask (contour)')

  return ix
25/59:
ix = None

for experiment in experiments:
  print(experiment['best_model_weights'])
  ix = plot_pred_sample(X, y, experiment['pred'], ix=ix)
26/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
26/2:
from tensorflow.python.eager import context
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.framework import tensor_shape
from tensorflow.python.framework import tensor_util
from tensorflow.python.keras import backend as K
from tensorflow.python.keras.engine.base_layer import Layer
from tensorflow.python.keras.engine.input_spec import InputSpec
from tensorflow.python.keras.utils import tf_utils
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import check_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import image_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import stateful_random_ops
from tensorflow.python.ops import stateless_random_ops
from tensorflow.python.ops import variables
from tensorflow.python.util.tf_export import keras_export

ResizeMethod = image_ops.ResizeMethod

H_AXIS = 1
W_AXIS = 2

class CenterCrop(Layer):
  """Crop the central portion of the images to target height and width.
  Input shape:
    4D tensor with shape:
    `(samples, height, width, channels)`, data_format='channels_last'.
  Output shape:
    4D tensor with shape:
    `(samples, target_height, target_width, channels)`.
  If the input height/width is even and the target height/width is odd (or
  inversely), the input image is left-padded by 1 pixel.
  Arguments:
    height: Integer, the height of the output shape.
    width: Integer, the width of the output shape.
    name: A string, the name of the layer.
  """

  def __init__(self, height, width, name=None, **kwargs):
    self.target_height = height
    self.target_width = width
    self.input_spec = InputSpec(ndim=4)
    super(CenterCrop, self).__init__(name=name, **kwargs)

  def call(self, inputs):
    inputs_shape = array_ops.shape(inputs)
    img_hd = inputs_shape[H_AXIS]
    img_wd = inputs_shape[W_AXIS]
    img_hd_diff = img_hd - self.target_height
    img_wd_diff = img_wd - self.target_width
    checks = []
    checks.append(
        check_ops.assert_non_negative(
            img_hd_diff,
            message='The crop height {} should not be greater than input '
            'height.'.format(self.target_height)))
    checks.append(
        check_ops.assert_non_negative(
            img_wd_diff,
            message='The crop width {} should not be greater than input '
            'width.'.format(self.target_width)))
    with ops.control_dependencies(checks):
      bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
      bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
      bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
      bbox_size = array_ops.stack(
          [-1, self.target_height, self.target_width, -1])
      outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
      return outputs

  def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    return tensor_shape.TensorShape(
        [input_shape[0], self.target_height, self.target_width, input_shape[3]])

  def get_config(self):
    config = {
        'height': self.target_height,
        'width': self.target_width,
    }
    base_config = super(CenterCrop, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
26/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
26/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
26/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
26/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
26/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    crop_center_transformation(img_shape),
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
26/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
26/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(12, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')
    
  return ix
26/10: plot_sample(X, y)  # check if data looks all right
26/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
26/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
26/13:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
26/14:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
      rm_percentiles_transformation(1, 98),  # threshold outliers
      normalize_transformation((0, 1)),  # pixel values in [0, 1]
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
26/15:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    10,  # config.getint('training', 'epochs'),  # todo try 100
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/17:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
26/18:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184 CenterCrop')
26/19:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
26/20:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'], 
    config.getint('training', 'batch size'), 
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/21:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
26/22:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
26/23:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
26/24:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
26/25:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
26/26:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
26/27:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
26/28:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    crop_center_transformation(img_shape),
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
26/29:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
26/30:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(12, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')
    
  return ix
26/31: plot_sample(X, y)  # check if data looks all right
26/32:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
26/33:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
26/34:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
26/35:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
      rm_percentiles_transformation(1, 98),  # threshold outliers
      normalize_transformation((0, 1)),  # pixel values in [0, 1]
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
26/36:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/37:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
26/38:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/39:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'results': None,
#     'pred': None
#   }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
26/40:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/41:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    print(x.shape)
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    crop_center_transformation(img_shape),
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
26/42:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/43:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
      # rm_percentiles_transformation(1, 98),  # threshold outliers
      # normalize_transformation((0, 1)),  # pixel values in [0, 1]
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
26/44:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/45:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
26/46:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
26/47:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
26/48:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
26/49:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
26/50:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
26/51:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    print(x.shape)
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    crop_center_transformation(img_shape),
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
26/52:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
26/53:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(12, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')
    
  return ix
26/54: plot_sample(X, y)  # check if data looks all right
26/55:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
26/56:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
26/57:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'results': None,
#     'pred': None
#   }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
26/58:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
26/59:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/60:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = (36, 36)  # calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
26/61:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/62:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy']  # , MeanIoU(num_classes=2)]  # todo re-implement
}
26/63:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = (36, 36)  # calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
26/64:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
26/65:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.xlabel('# epochs')
  ax.ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
26/66:
fig, axis = plt.subplots(2, 2, figsize=(12, 8))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
26/67:
def plot_pred_sample(X, y, preds, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  
  im = ax[0].imshow(X[ix, ..., 0], cmap='gray')
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image + mask (contour)')

  ax[1].imshow(preds[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('predicted + original mask (contour)')

  return ix
26/68:
ix = None

for experiment in experiments:
  print(experiment['best_model_weights'])
  ix = plot_pred_sample(X, y, experiment['pred'], ix=ix)
26/69:
ix = None

for experiment in experiments:
  print(experiment['best_model_weights'])
  ix = plot_pred_sample(X_test, y_test, experiment['pred'], ix=ix)
26/70:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
27/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
27/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
27/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
27/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
27/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
27/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
27/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
27/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
27/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
27/10: plot_sample(X, y)  # check if data looks all right
27/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
27/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
27/13:
# from tensorflow.python.ops import math_ops
# from tensorflow.python.ops import confusion_matrix


def mean_IoU(y_true, y_pred):
    y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold
    inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)
    union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
    return K.mean((inter + K.epsilon()) / (union + K.epsilon()))
27/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', MeanIoU(num_classes=1), mean_IoU]  # todo re-implement
}
27/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
27/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
27/17:
def mean_IoU(y_true, y_pred):
  # y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean((inter + K.epsilon()) / (union + K.epsilon()))
27/18:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', MeanIoU(num_classes=1), mean_IoU]  # todo re-implement
}
27/19:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
27/20:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', MeanIoU(num_classes=1)]  # todo re-implement
}
27/21:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
27/22:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', MeanIoU(num_classes=2)]  # todo re-implement
}
27/23:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
27/24:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', MeanIoU(num_classes=2), mean_IoU]  # todo re-implement
}
27/25:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
27/26:
def mean_IoU(y_true, y_pred):
  y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean((inter + K.epsilon()) / (union + K.epsilon()))
27/27:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
28/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
28/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
28/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
28/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
28/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
28/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
28/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
28/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
28/10: plot_sample(X, y)  # check if data looks all right
28/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
28/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
28/13:
def mean_IoU(y_true, y_pred):
  y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean((inter + K.epsilon()) / (union + K.epsilon()))
28/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = _sub_tup(x, 4)  # conv
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/18:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/19:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/20:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/21:
def calc_padding_out_size(n_layers):
   """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = _sub_tup(x, 4)  # conv
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/23:
def calc_padding_out_size(n_layers):
   """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = _sub_tup(x, 4)  # conv todo why?
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/25:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = _sub_tup(x, 4)  # conv tod
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/26:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/27:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
28/28:
_, X_test, _, y_test = prepare_data(X, y, experiments[0], False)
ix = random.randint(0, len(X_test) - 1)  # random test image

_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/29:
_, X_test, _, y_test = prepare_data(X, y, experiments[0], False)
ix = random.randint(0, len(X_test) - 1)  # random test image

_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/30:
_, X_test, _, y_test = prepare_data(X, y, experiments[0], False)
ix = random.randint(0, len(X_test) - 1)  # random test image

_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  pred = experiment['pred']
  # ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/31:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']
  print(results.history)

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='val_loss')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
28/32:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']
  print(results.history)

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
28/33:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
28/34:
_, X_test, _, y_test = prepare_data(X, y, experiments[0], False)
ix = random.randint(0, len(X_test) - 1)  # random test image

_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/35:
_, X_test, _, y_test = prepare_data(X, y, experiments[0], False)
ix = random.randint(0, len(X_test) - 1)  # random test image

_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/36:
_, X_test, _, y_test = prepare_data(X, y, experiments[0], False)
ix = random.randint(0, len(X_test) - 1)  # random test image

_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  # ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/37:
ix = 5  # random test image
_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  # ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/38:
ix = 5  # random test image
_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/39:
ix = 5  # random test image
_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(12, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/40:
ix = 5  # random test image
_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 4))
for ax, experiment in zip(axis.ravel(), experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/41:
ix = 5  # random test image
_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  # ax.invert_yaxis()
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/42:
ix = 5  # random test image
_, axis = plt.subplots(1, 1, figsize=(8, 4))
axis.imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
axis.set_title('original image')

_, axis = plt.subplots(2, 2, figsize=(16, 8))
for ax, experiment in zip(axis.ravel(), experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  ax.imshow(pred[ix].squeeze(), cmap='gray')
  ax.contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax.set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/43:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  pred = experiment['pred']


  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (original mask as contour)'.format(experiment['best_model_weights']))
28/44:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  pred = experiment['pred']


  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))
28/45:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
28/46:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
28/47:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
28/48:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
28/49:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
28/50:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
28/51:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
28/52:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
28/53:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
28/54: plot_sample(X, y)  # check if data looks all right
28/55:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
28/56:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
28/57:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
28/58:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/59:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/60:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/61:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/62:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/63:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = _sub_tup(x, 4)  # conv
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/64:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/65:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
28/66:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
28/67:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
28/68:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
28/69:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
28/70:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
28/71:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
28/72:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
28/73:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
28/74: plot_sample(X, y)  # check if data looks all right
28/75:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
28/76:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
28/77:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
28/78:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/79:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv

    x = _sub_tup(x, 4)  # conv
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/80:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/81:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
28/82:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
28/83:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
28/84:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
28/85:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
28/86:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
28/87:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
28/88:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
28/89:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
28/90: plot_sample(X, y)  # check if data looks all right
28/91:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
28/92:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
28/93:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
28/94:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/95:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/96:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/97:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    if x % 8 == 0:
      x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/98:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/99:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    if x[0] % 8 == 0:
      x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/100:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
28/101:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
28/102:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
28/103:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
28/104:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
28/105:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
28/106:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
28/107:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
28/108:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
28/109:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
28/110: plot_sample(X, y)  # check if data looks all right
28/111:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
28/112:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
28/113:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
28/114:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
28/115:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    if x[0] % 8 == 0:
      x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
28/116:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
29/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
29/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
29/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
29/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
29/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
29/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
29/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
29/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
29/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
29/10: plot_sample(X, y)  # check if data looks all right
29/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
29/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
29/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
29/14:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None,
#     'pred': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None,
#     'pred': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
29/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    if x[0] % 8 == 0:
      x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
29/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
29/17:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # todo re-implement MeanIoU(num_classes=2)
}
29/18:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),  # todo what does it do?
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    10,  # config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
30/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
30/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
30/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
30/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
30/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
30/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
30/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
30/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
30/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 8))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
30/10: plot_sample(X, y)  # check if data looks all right
30/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
30/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
30/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
30/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
30/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
30/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
31/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
31/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
31/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
31/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
31/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
31/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
31/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
31/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
31/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
31/10: plot_sample(X, y)  # check if data looks all right
31/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
31/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
31/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
31/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
31/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
31/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
32/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
32/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
32/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
32/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
32/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
32/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
32/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
32/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
32/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
32/10: plot_sample(X, y)  # check if data looks all right
32/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
32/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
32/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
32/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
32/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
32/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
33/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
33/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
33/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
33/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
33/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
33/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
33/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
33/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
33/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
33/10: plot_sample(X, y)  # check if data looks all right
33/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
33/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=training_batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
33/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
33/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
33/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
33/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
34/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
34/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
34/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
34/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
34/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
34/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
34/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
34/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
34/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
34/10: plot_sample(X, y)  # check if data looks all right
34/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
34/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, training_batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose, batch_size=batch_size)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
34/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
34/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
34/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
34/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
34/17:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(X_test, verbose=verbose, batch_size=batch_size)
  
  return results

def do_inference(model, best_model_weights_file, data):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose)
  return preds_val
34/18:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test)
35/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
35/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
35/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
35/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
35/5:
import os
from pathlib import Path

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
print('getting data from {}, folders there are: {}'.format(data_path, list(os.walk(data_path))[0][1]))
35/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
35/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
35/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
35/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
35/10: plot_sample(X, y)  # check if data looks all right
35/11:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
35/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
35/13:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
35/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None,
    'pred': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None,
    'pred': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
35/15:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
35/16:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(experiment['best_model_weights'], monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  experiment['results'] = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['pred'] = do_inference(model, experiment['best_model_weights'], X_test, config.getint('training', 'batch size'))
35/17:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
35/18:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  pred = experiment['pred']


  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  metric = mean_IoU(y_test[ix], pred[ix])
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour), mean IOU: {}'.format(experiment['best_model_weights'], metric))
35/19:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  pred = experiment['pred']

  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  print(y_test[ix].shape)
  metric = mean_IoU(y_test[ix], pred[ix])
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour), mean IOU: {}'.format(experiment['best_model_weights'], metric))
35/20:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  pred = experiment['pred']

  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))
35/21:
def clean_data(x):
    return rm_percentiles_transformation(10, 90)(x)
35/22:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(clean_data(results.history['loss']), label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
35/23:
def clean_data(x):
    return rm_percentiles_transformation(10, 90)(np.array(x))
35/24:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(clean_data(results.history['loss']), label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
35/25:
def clean_data(x):
    return rm_percentiles_transformation(0, 90)(np.array(x))
35/26:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(clean_data(results.history['loss']), label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
35/27:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r', label='best')
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
35/28:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  results = experiment['results']

  ax.plot(results.history['loss'], label='loss')
  ax.plot(results.history['val_loss'], label='loss (val)')
  ax.plot(np.argmin(results.history['val_loss']), np.min(results.history['val_loss']), marker='x', color='r')
  
  ax.plot(results.history['mean_IoU'], label='mean IoU')
  ax.plot(results.history['val_mean_IoU'], label='mean_IoU (val)')
  ax.plot(np.argmax(results.history['val_mean_IoU']), np.max(results.history['val_mean_IoU']), marker='x', color='r')
  
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
35/29:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print a == b
35/30:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(a == b)
35/31:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(results == b)
35/32:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(results == b)
35/33:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b)
35/34:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(results.copy(), handle, protocol=pickle.HIGHEST_PROTOCOL)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b)
35/35: results
35/36: experiments
35/37:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(experiments, handle, protocol=pickle.HIGHEST_PROTOCOL)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == experiments)
35/38: experiments.keys()
35/39: experiments[0].keys()
35/40: type(experiments[0].results)
35/41: type(experiments[0]['results'])
35/42:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(experiments[0]['results'], handle, protocol=pickle.HIGHEST_PROTOCOL)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == experiments)
35/43:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]['results']), handle, protocol=pickle.HIGHEST_PROTOCOL)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == experiments)
35/44: np.array(experiments[0]['results'])
35/45: !pip install dill
35/46:
import dill
dill.dump_session('notebook_env.db')
35/47:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]['results']), handle)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == experiments)
35/48: np.array(experiments[0]['results'].history)
35/49:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]['results'].history), handle)

b = {}
with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == experiments)
35/50:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]['results'].history), handle)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == np.array(experiments[0]['results'].history)
35/51:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]['results'].history), handle)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == np.array(experiments[0]['results'].history))
35/52:
for i, e in enumerate(experiments):
    experiments[i]['history'] = e.history
35/53:
for i, e in enumerate(experiments):
    experiments[i]['history'] = e['results'].history
35/54: experiments
35/55: experiments[0]['history']
35/56: experiments[0]['results'] = None
35/57: experiments
35/58:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments), handle)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == np.array(experiments[0]['results'].history))
35/59:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]), handle)

with open('filename.pickle', 'rb') as handle:
    b = pickle.load(handle)

print(b == np.array(experiments[0]['results'].history))
35/60:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(np.array(experiments[0]), handle)
35/61:
import pickle

with open('filename.pickle', 'wb') as handle:
    for e in experiments:
        pickle.dump(e, handle)
35/62: experiments[0]['history']
35/63: experiments[0]
35/64:
for i, e in enumerate(experiments):
    experiments[i]['pred'] = None
35/65: experiments
35/66:
import json

with open('data.json', 'w') as fp:
    json.dump(experiments, fp)
35/67:
import pickle

with open('filename.pickle', 'wb') as handle:
    pickle.dump(experiments, handle)
35/68:
for i, e in enumerate(experiments):
    experiments[i]['history'] = np.array(e['history'])
35/69:
import json

with open('data.json', 'w') as fp:
    json.dump(experiments, fp)
35/70: experiments
36/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
37/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
37/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
37/3:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
37/4:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
37/5:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
37/6:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
37/7:
import os
from pathlib import Path
import json

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
experiments_path = Path(config.get('experiment', 'output folder')).resolve()
37/8:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
37/9:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
37/10:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
37/11:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(16, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
37/12: plot_sample(X, y)  # check if data looks all right
37/13:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
37/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
37/15:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
37/16:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
37/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
37/18:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = experiments_path / experiment['best_model_weights']
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
#   results = do_training(
#     model,
#     X_train,
#     X_test,
#     y_train,
#     y_test,
#     experiment['best_model_weights'],
#     config.getint('training', 'batch size'),
#     config.getint('training', 'epochs'),
#     callbacks,
#     compile_args
#   )
#   experiment['history'] = results.history
37/19:
experiments_file = experiments_path / config.get('experiment', 'out file')

with open(experiments_file, 'w') as fp:
    json.dump(experiments, fp)  # save for later processing
37/20:
experiments_file = experiments_path / config.get('experiment', 'output file')

with open(experiments_file, 'w') as fp:
    json.dump(experiments, fp)  # save for later processing
37/21:
with open(experiments_file, 'r') as fp:  # load experiments data
    experiments = json.load(fp)
37/22:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  ax.plot(experiment['history']['loss'], label='loss')
  ax.plot(experiment['history']['val_loss'], label='loss (val)')
  ax.plot(np.argmin(experiment['history']['val_loss']), np.min(experiment['history']['val_loss']), marker='x', color='r')
  
  ax.plot(experiment['history']['mean_IoU'], label='mean IoU')
  ax.plot(experiment['history']['val_mean_IoU'], label='mean IoU (val)')
  ax.plot(np.argmax(experiment['history']['val_mean_IoU']), np.max(experiment['history']['val_mean_IoU']), marker='x', color='r')
  
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
37/23:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  ax.plot(experiment['history']['loss'], label='loss')
  ax.plot(experiment['history']['val_loss'], label='loss (val)')
  ax.plot(np.argmin(experiment['history']['val_loss']), np.min(experiment['history']['val_loss']), marker='x', color='r')
  
  ax.plot(experiment['history']['mean_IoU'], label='mean IoU')
  ax.plot(experiment['history']['val_mean_IoU'], label='mean IoU (val)')
  ax.plot(np.argmax(experiment['history']['val_mean_IoU']), np.max(experiment['history']['val_mean_IoU']), marker='x', color='r')
  
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
37/24:
with open(experiments_file, 'r') as fp:  # load experiments data
    experiments = json.load(fp)
37/25:
fig, axis = plt.subplots(2, 2, figsize=(12, 12))

for ax, experiment in zip(axis.ravel(), experiments):
  ax.plot(experiment['history']['loss'], label='loss')
  ax.plot(experiment['history']['val_loss'], label='loss (val)')
  ax.plot(np.argmin(experiment['history']['val_loss']), np.min(experiment['history']['val_loss']), marker='x', color='r')
  
  ax.plot(experiment['history']['mean_IoU'], label='mean IoU')
  ax.plot(experiment['history']['val_mean_IoU'], label='mean IoU (val)')
  ax.plot(np.argmax(experiment['history']['val_mean_IoU']), np.max(experiment['history']['val_mean_IoU']), marker='x', color='r')
  
  ax.set_xlabel('# epochs')
  ax.set_ylabel('log loss')
  ax.legend()
  ax.set_title(experiment['best_model_weights'])
37/26:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }
  model = get_unet(**args)
  model_file = experiments_path / experiment['best_model_weights']
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  
  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))
37/27:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }
  model = get_unet(**args)
  model_file = str(experiments_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  
  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X_test[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y_test[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))
37/28:
for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }
  model = get_unet(**args)
  model_file = str(experiments_path / experiment['best_model_weights'])
  experiments['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
37/29:
for i, experiment in enumerate(experiments):
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  ix = random.randint(0, len(X_test) - 1)  # random test image
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }
  model = get_unet(**args)
  model_file = str(experiments_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
37/30:
def plot_sample(X, y, pred, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  _, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  
  plot_sample(X_test, y_test, pred)
37/31:
def plot_sample(X, y, pred, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 16))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  
  plot_sample(X_test, y_test, pred)
37/32:
def plot_sample(X, y, pred, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


for experiment in experiments:
  _, X_test, _, y_test = prepare_data(X, y, experiment, False)
  pred = experiment['pred']
  
  plot_sample(X_test, y_test, pred)
37/33:
def plot_history(experiments, last_n=None):
  if last_n is None:
    last_n = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][last_n:]
    val_loss = experiment['history']['val_loss'][last_n:]
    metric = experiment['history']['mean_IoU'][last_n:]
    val_metric = experiment['history']['val_mean_IoU'][last_n:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, 25)
37/34:
def plot_history(experiments, last_n=None):
  if last_n is None:
    last_n = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][last_n:]
    val_loss = experiment['history']['val_loss'][last_n:]
    metric = experiment['history']['mean_IoU'][last_n:]
    val_metric = experiment['history']['val_mean_IoU'][last_n:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, 40)
37/35:
def plot_history(experiments, last_n=None):
  if last_n is None:
    last_n = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][last_n:]
    val_loss = experiment['history']['val_loss'][last_n:]
    metric = experiment['history']['mean_IoU'][last_n:]
    val_metric = experiment['history']['val_mean_IoU'][last_n:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, 45)
37/36:
def plot_history(experiments, last_n=None):
  if last_n is None:
    last_n = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last_n:]
    val_loss = experiment['history']['val_loss'][-last_n:]
    metric = experiment['history']['mean_IoU'][-last_n:]
    val_metric = experiment['history']['val_mean_IoU'][-last_n:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
37/37:
def plot_history(experiments, last_n=None):
  if last_n is None:
    last_n = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last_n:]
    val_loss = experiment['history']['val_loss'][-last_n:]
    metric = experiment['history']['mean_IoU'][-last_n:]
    val_metric = experiment['history']['val_mean_IoU'][-last_n:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments)
37/38:
def plot_history(experiments, last_n=None):
  if last_n is None:
    last_n = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last_n:]
    val_loss = experiment['history']['val_loss'][-last_n:]
    metric = experiment['history']['mean_IoU'][-last_n:]
    val_metric = experiment['history']['val_mean_IoU'][-last_n:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, 40)
37/39:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, 40)
37/40:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')

    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.legend()
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/41:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 12))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/42:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(12, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/43:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(16, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/44:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU')
    ax.plot(val_metric, label='mean IoU (val)')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/45:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU', color='red')
    ax.plot(val_metric, label='mean IoU (val)', color='green')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/46:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss')
    ax.plot(val_loss, label='loss (val)')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

    ax.plot(metric, label='mean IoU', color='red')
    ax.plot(val_metric, label='mean IoU (val)', color='green')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_ylabel('log loss', color='orange')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/47:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss', color='g')
    ax.plot(val_loss, '--', label='loss (val)', color='g')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.set_ylabel('log loss', color='g')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis
    
    ax.plot(metric, label='mean IoU', color='b')
    ax.plot(val_metric, '--', label='mean IoU (val)', color='b')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.set_ylabel('mean IoU', color='b')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=40)
37/48:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss', color='g')
    ax.plot(val_loss, '--', label='loss (val)', color='g')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.set_ylabel('log loss', color='g')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis
    
    ax.plot(metric, label='mean IoU', color='b')
    ax.plot(val_metric, '--', label='mean IoU (val)', color='b')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.set_ylabel('mean IoU', color='b')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=45)
37/49:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='loss', color='g')
    ax.plot(val_loss, '--', label='loss (val)', color='g')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.set_ylabel('log loss', color='g')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis
    
    ax.plot(metric, label='mean IoU', color='b')
    ax.plot(val_metric, '--', label='mean IoU (val)', color='b')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.set_ylabel('mean IoU', color='b')
    ax.legend()
    
    ax.set_xlabel('# epochs')
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments)
38/1:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
38/2:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
38/3:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
38/4:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
38/5:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
38/6:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
38/7:
import os
from pathlib import Path
import json

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
experiments_path = Path(config.get('experiment', 'output folder')).resolve()
38/8:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
38/9:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
38/10:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
38/11:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(20, 8))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
38/12: plot_sample(X, y)  # check if data looks all right
38/13:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((None, ))
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  out = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=inp, outputs=out)
  return model
38/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
38/15:
def eps_divide(n, d):
  """ perform division using eps """
    
  return (n + K.epsilon()) / (d + K.epsilon())


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))
38/16:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'best_model_weights': 'with_same.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'best_model_weights': 'without_same.h5',
    'results': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'results': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]
}
38/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e ) convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def prepare_data(X, y, experiment, verbose=True):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('experiment {}: X ~ {}, y ~ {}'.format(experiment['best_model_weights'], X.shape, y.shape))
  
  return X_train, X_test, y_train, y_test
38/18:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
38/19:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((None, None, 1))
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  out = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=inp, outputs=out)
  return model
38/20:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
38/21:
def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * 2)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * 2)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
#     if using_skip_conn:
#       s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
#       x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / 2)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((None, None, 1))
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * 2 ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  out = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=inp, outputs=out)
  return model
38/22:
for experiment in experiments:
  X_train, X_test, y_train, y_test = prepare_data(X, y, experiment)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
39/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
39/2:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
39/3:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
39/4:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
39/5:
import os
from pathlib import Path
import json

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
experiments_path = Path(config.get('experiment', 'output folder')).resolve()
39/6:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
39/7:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
39/8:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
39/9:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(20, 8))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix
39/10: plot_sample(X, y)  # check if data looks all right
39/11:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def get_unet(img_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, use_se_blocks=False, dropout=0.0, batchnorm=False):
  n_dim = 2
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input(img_shape)
  x = inp
  x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, dropout, batchnorm)(x)
  x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)
  
  current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
  x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
  output = final_path(n_classes, final_activation, padding)(x)

  model = Model(inputs=[inp], outputs=[output])
  return model
39/12:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
39/13:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
39/14:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_blocks': False,  # usual
    'best_model_weights': 'with_same.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_blocks': False,  # usual
    'best_model_weights': 'without_same.h5',
    'results': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'use_se_blocks': False,  # usual
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'use_se_blocks': False,  # usual
    'results': None
  },
    {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_blocks': True
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_blocks': True,
    'best_model_weights': 'without_same_se.h5',
    'results': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_blocks': True,
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid_se.h5',
    'use_se_blocks': True,
    'results': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
39/15:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_blocks': False,  # usual
    'best_model_weights': 'with_same.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_blocks': False,  # usual
    'best_model_weights': 'without_same.h5',
    'results': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid.h5',
    'use_se_blocks': False,  # usual
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid.h5',
    'use_se_blocks': False,  # usual
    'results': None
  },
    {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_blocks': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_blocks': True,
    'best_model_weights': 'without_same_se.h5',
    'results': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_blocks': True,
    'results': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'best_model_weights': 'without_valid_se.h5',
    'use_se_blocks': True,
    'results': None
  }
]

img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
base_args = {
  'img_shape': (*img_shape, config.getint('image', 'depth')),
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
39/16:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
39/17:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = get_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
40/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
40/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
40/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
40/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
40/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
40/6:
import os
from pathlib import Path
import json

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
experiments_path = Path(config.get('experiment', 'output folder')).resolve()
40/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
40/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
40/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
40/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
40/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
40/12:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding)(x)
    return x

  return _f
40/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_size,
    pool_size,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
40/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
40/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
40/16:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
40/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
40/18:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
40/19:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding)(x)
    return x

  return _f
40/20:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
40/21:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
40/22:
experiments_file = experiments_path / config.get('experiment', 'output file')

with open(experiments_file, 'w') as fp:
    json.dump(experiments, fp)  # save for later processing
40/23:
experiments_file = experiments_path / config.get('experiment', 'output file')

with open(experiments_file, 'w') as fp:
    json.dump(str(experiments), fp)  # save for later processing
40/24:
with open(experiments_file, 'r') as fp:  # load experiments data
    experiments = json.load(fp)
40/25:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='train', color='g')
    ax.plot(val_loss, '--', label='val', color='g')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.set_ylabel('log loss', color='g')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis
    
    ax.plot(metric, label='train', color='b')
    ax.plot(val_metric, '--', label='val', color='b')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.set_ylabel('mean IoU', color='b')
    ax.legend()
    
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=45)
40/26: experiments
40/27:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = np.floor(len(experiments) / n_cols) + 1
  fig, axis = plt.subplots(2, 2, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='train', color='g')
    ax.plot(val_loss, '--', label='val', color='g')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.set_ylabel('log loss', color='g')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis
    
    ax.plot(metric, label='train', color='b')
    ax.plot(val_metric, '--', label='val', color='b')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.set_ylabel('mean IoU', color='b')
    ax.legend()
    
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=45)
40/28:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = np.floor(len(experiments) / n_cols) + 1
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 8))

  for ax, experiment in zip(axis.ravel(), experiments):
    loss = experiment['history']['loss'][-last:]
    val_loss = experiment['history']['val_loss'][-last:]
    metric = experiment['history']['mean_IoU'][-last:]
    val_metric = experiment['history']['val_mean_IoU'][-last:]
    
    ax.plot(loss, label='train', color='g')
    ax.plot(val_loss, '--', label='val', color='g')
    ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
    ax.set_ylabel('log loss', color='g')
    ax.legend()
    
    ax = ax.twinx()  # instantiate a second axes that shares the same x-axis
    
    ax.plot(metric, label='train', color='b')
    ax.plot(val_metric, '--', label='val', color='b')
    ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
    ax.set_ylabel('mean IoU', color='b')
    ax.legend()
    
    ax.set_title(experiment['best_model_weights'])
    

plot_history(experiments, last=45)
40/29:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 1
  n_rows = np.floor(len(experiments) / n_cols) + 1
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 8))
    
  def _plot_experiment(experiment, ax):
      loss = experiment['history']['loss'][-last:]
      val_loss = experiment['history']['val_loss'][-last:]
      metric = experiment['history']['mean_IoU'][-last:]
      val_metric = experiment['history']['val_mean_IoU'][-last:]

      ax.plot(loss, label='train', color='g')
      ax.plot(val_loss, '--', label='val', color='g')
      ax.plot(np.argmin(val_loss), np.min(val_loss), marker='x', color='r')
      ax.set_ylabel('log loss', color='g')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      ax.plot(metric, label='train', color='b')
      ax.plot(val_metric, '--', label='val', color='b')
      ax.plot(np.argmax(metric), np.max(metric), marker='x', color='r')
      ax.set_ylabel('mean IoU', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      _plot_experiment(experiment, ax)
    

plot_history(experiments, last=45)
40/30: experiments
41/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
41/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
41/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
41/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
41/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
41/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
experiments_path = Path(config.get('experiment', 'output folder')).resolve()
41/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
41/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
41/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
41/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
41/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
41/12:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding):
  def _f(x):
    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding)(x)
    return x

  return _f
41/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
41/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
41/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
41/16:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
41/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
41/18:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
41/19:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
experiments_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = experiments_path / config.get('experiment', 'output file')
41/20:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
41/21:
with open(experiments_file, 'w') as fp:
    json.dump(str(experiments), fp)  # save for later processing
41/22:
with open(experiments_file, 'r') as fp:  # load experiments data
    experiments = ast.literal_eval(json.load(fp))
41/23:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 8))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
42/1:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
42/2:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
42/3: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
42/4:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
42/5:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
42/6:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
42/7:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
42/8:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
42/9:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
42/10:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
42/11:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
42/12:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
42/13:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
42/14:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
42/15:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
42/16:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
42/17:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
42/18:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
42/19:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
42/20:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(experiments_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
42/21:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
42/22:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
42/23:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_test,
    y_train,
    y_test,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
42/24:
with open(experiments_file, 'w') as fp:
    json.dump(str(experiments), fp)  # save for later processing
42/25:
with open(experiments_file, 'r') as fp:  # load experiments data
    experiments = ast.literal_eval(json.load(fp))
42/26:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 8))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
43/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
43/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
43/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
43/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
43/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
43/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
43/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
43/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
43/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
43/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
43/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
43/12:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
43/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
43/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
43/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
43/16:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
43/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
43/18:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
43/19:
def save_experiments(experiments):
  with open(experiments_file, 'w') as fp:
    json.dump(str(experiments), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    return experiments
43/20:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
43/21:
def plot_sample(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn']
  }
  model = get_unet(**args)
  model_file = str(experiments_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_sample(X_test, y_test, experiments[i]['pred'], experiment['best_model_weights'])
  

save_experiments(experiments)
43/22:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
43/23:
def plot_sample(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(experiments_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_sample(X_test, y_test, experiments[i]['pred'], experiment['best_model_weights'])
  

save_experiments(experiments)
43/24:
def plot_sample(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_sample(X_test, y_test, experiments[i]['pred'], experiment['best_model_weights'])
  

save_experiments(experiments)
43/25:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
44/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
44/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
44/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
44/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
44/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
44/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
44/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
44/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
44/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
44/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
44/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
44/12:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
44/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
44/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
44/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
44/16:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
44/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
44/18:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
44/19:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(experiments), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    return experiments
44/20:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
44/21:
def plot_sample(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_sample(X_test, y_test, experiments[i]['pred'], experiment['best_model_weights'])
  

save_experiments(experiments)
44/22:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    return experiments
44/23:
def plot_sample(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_sample(X_test, y_test, experiments[i]['pred'], experiment['best_model_weights'])
  

save_experiments(experiments)
45/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
45/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
45/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
45/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
45/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
45/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
45/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
45/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
45/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
45/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
45/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
45/12:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
45/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
45/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
45/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/16:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
45/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
45/18:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/19:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
45/20:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
45/21:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  experiments[i]['pred'] = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  
  for ix in range(len(X_test)):
    plot_pred(X_test, y_test, experiments[i]['pred'], experiment['best_model_weights'], ix=ix)
  

save_experiments(experiments)
45/22:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'], ix=ix)
  

save_experiments(experiments)
45/23:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  print(mean_IoU(y[ix], pred[ix]))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'], ix=ix)


save_experiments(experiments)
45/24:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  print(mean_IoU(K.constant(y[ix]), K.constant(pred[ix])))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'], ix=ix)


save_experiments(experiments)
45/25:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'], ix=ix)


save_experiments(experiments)
45/26:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]), axis=[1,2])
  print(score)
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'], ix=ix)


save_experiments(experiments)
45/27:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]), axis=[1,2])
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'], ix=ix)


save_experiments(experiments)
45/28:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  score = mean_IoU(K.constant(y[ix]), K.constant(pred[ix]), axis=[1,2])
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/29:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  score = mean_IoU(K.constant(y[ix]), K.constant(pred[ix])
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/30:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
    
  score = mean_IoU(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/31:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  def f(y_true, y_pred):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
    iou = (intersection + smooth) / ( union + smooth)
    return iou
    
  score = f(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/32:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  def f(y_true, y_pred, smooth=eps):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
    iou = (intersection + smooth) / ( union + smooth)
    return iou
    
  score = f(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/33:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  def f(y_true, y_pred, smooth=1e-10):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
    iou = (intersection + smooth) / ( union + smooth)
    return iou
    
  score = f(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/34:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    
  def f(y_true, y_pred, smooth=1e-10):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
    iou = K.mean((intersection + smooth) / ( union + smooth))
    return iou
    
  score = f(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/35:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
#   y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
#   inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
#   union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
#   return K.mean(eps_divide(inter, union))
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/36:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/37:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, DSC]
}
45/38:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/39:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5, smooth=K.epsilon()):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/40:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/41:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5, smooth=K.epsilon()):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/42:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/43:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, DSC]
}
45/44:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/45:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=-1), axis=-2), axis=-3)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=-1), axis=-2), axis=-3) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5, smooth=K.epsilon()):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/46:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
    

    
  score = mean_IoU(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
45/47:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5, smooth=K.epsilon()):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1)
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/48:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, DSC]
}
45/49:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/50:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5, smooth=K.epsilon()):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1)
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def kk(y_true, y_pred):
  m = tf.keras.metrics.MeanIoU(num_classes=1)
  m.update_state(y_true, y_pred)
  return m.result()

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/51:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, kk, DSC]
}
45/52:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/53:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def mean_IoU(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter
  return K.mean(eps_divide(inter, union))

def wow(y_true, y_pred, threshold=0.5, smooth=K.epsilon()):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
  union = K.sum(y_true,-1) + K.sum(y_pred,-1)
  iou = K.mean((intersection + smooth) / ( union + smooth))
  return iou

def kk(y_true, y_pred):
  m = tf.keras.metrics.MeanIoU(num_classes=1)
  m.reset_states()
  m.update_state(y_true, y_pred)
  return m.result()

def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
45/54:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, kk, DSC]
}
45/55:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/56:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, tf.keras.metrics.MeanIoU(num_classes=1), DSC]
}
45/57:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/58:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, wow, tf.keras.metrics.MeanIoU(num_classes=2), DSC]
}
45/59:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
45/60:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = tf.keras.metrics.MeanIoU(num_classes=2)(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  print(K.eval(score))
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/1:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(y_true * y_pred, axis=-2), axis=-1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(y_true + y_pred, axis=-2), axis=-1) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
46/2: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
46/3:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
46/4:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
46/5:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
46/6:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
46/7:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
46/8:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
46/9:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f

def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(1, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
46/10:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
46/11:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
46/12:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
46/13:
filter_mult = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for skip_conn in reversed(skip_conns):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
46/14:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth'))  # todo variable-size input
  inp = Input(img_shape)  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
46/15:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
46/16:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(y_true * y_pred, axis=-2), axis=-1)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(y_true + y_pred, axis=-2), axis=-1) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
46/17:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', batch_metric(mean_IoU), DSC]
}
46/18:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
46/19:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # todo model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
46/20:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy',mean_IoU, DSC]
}
46/21:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # todo model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
46/22:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
46/23:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
46/24:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/25:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], pred[ix])
  print(score)
    
  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/26:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/27:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy',mean_IoU, tf.keras.metrics.MeanIoU(num_classes=2), DSC]
}
46/28:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # todo model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
46/29:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # todo model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
46/30:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(K.sum(y_true * y_pred, axis=-3), axis=-2)  # always 3D images (even if grayscale)
  union = K.sum(K.sum(y_true + y_pred, axis=-3), axis=-2) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/31:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, tf.keras.metrics.MeanIoU(num_classes=2), DSC]
}
46/32:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # todo model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
46/33:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/34:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'best_model_weights': 'with_same_se.h5',
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, tf.keras.metrics.MeanIoU(num_classes=2), DSC]
}
46/35:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # todo model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
46/36:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(experiment['best_model_weights'])

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax)
    

plot_history(experiments, last=45)
46/37:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/38:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5):
  def _sum(x):
    return K.sum(x)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth))


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/39:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/40:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/41:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/42:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], y[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(y[ix]))
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/43:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=K.epsilon(), threshold=0.5):
  def _sum(x):
    return K.sum(x)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth))


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/44:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/45:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(K.constant(y[ix]), K.constant(pred[ix]))
  print(score)
  score = tf.keras.metrics.MeanIoU(num_classes=2)(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/46:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=K.epsilon(), threshold=0.5):  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union, eps=smooth))


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/47:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], pred[ix])
  print(score)
  score = tf.keras.metrics.MeanIoU(num_classes=2)(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file, metrics, do_plot=False):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  

#   if do_plot:
#       plot_pred(X, y, pred, model_file)


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/48:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=K.epsilon(), threshold=0.5):  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return K.mean(eps_divide(2.0 * inter, union, eps=smooth))


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/49:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], pred[ix])
  print(score)
  score = tf.keras.metrics.MeanIoU(num_classes=2)(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file, metrics, do_plot=False):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  

#   if do_plot:
#       plot_pred(X, y, pred, model_file)


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/50:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], y[ix])
  print(score)
  score = tf.keras.metrics.MeanIoU(num_classes=2)(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file, metrics, do_plot=False):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  

#   if do_plot:
#       plot_pred(X, y, pred, model_file)


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/51:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def DSC(y_true, y_pred, smooth=K.epsilon(), threshold=0.5):  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred)
  return K.mean(eps_divide(2.0 * inter, union, eps=smooth))


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f
46/52:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], y[ix])
  print(score)
  score = tf.keras.metrics.MeanIoU(num_classes=2)(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file, metrics, do_plot=False):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  

#   if do_plot:
#       plot_pred(X, y, pred, model_file)


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
46/53:
def plot_pred(X, y, pred, model_name, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 2, figsize=(10, 4))
  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')
  
  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['best_model_weights']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))

  score = mean_IoU(y[ix], pred[ix])
  print(score)
  score = DSC(y[ix], pred[ix])
  print(score)
  score = tf.keras.metrics.MeanIoU(num_classes=2)(y[ix], pred[ix])
  print(score)

  return ix


# def do_evaluation(X_test, y_test, model, model_file, metrics, do_plot=False):
#   pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  

#   if do_plot:
#       plot_pred(X, y, pred, model_file)


for i, experiment in enumerate(experiments):
  _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_unet(**args)
  model_file = str(out_path / experiment['best_model_weights'])
  pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
  plot_pred(X_test, y_test, pred, experiment['best_model_weights'])


save_experiments(experiments)
47/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
47/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/12:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((None, None, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/16:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/17:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/18:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/19:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/20:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/21:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((572, 572, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/22:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/23:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/24:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/25:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4) / 2  # todo get from prev layers
          d_height = d_width  # todo rectangular images
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/26:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/27:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/28:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/29:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((None, None, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/30:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/31:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((256, 256, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/32:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/33:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/34:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/35: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/36:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/37:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/38:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/39:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/40:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/41:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/42:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/43:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/44:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/45:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/46:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((256, 256, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/47:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/48:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/49:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/50:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/51:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/52: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/53:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/54:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/55:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/56:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/57:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/58:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/59:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/60:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/61:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/62:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/63:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((256, 256, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/64:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/65:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/66:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/67:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, 4)  # conv
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/68:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/69:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((572, 572, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/70:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/71:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/72: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/73:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/74:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/75:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/76:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/77:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/78:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/79:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/80:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/81:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/82:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/83:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((572, 572, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/84:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/85:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/86:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/87:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/88:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/89: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/90:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/91:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/92:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/93:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/94:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/95:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/96:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/97:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/98:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/99:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/100:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((None, None, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/101:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/102:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/103:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/104:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/105:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/106:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((256, 256, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/107:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/108:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((512, 512, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/109: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/110:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/111:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/112:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/113:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/114:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/115:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/116:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/117:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/118:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/119:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/120:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((512, 512, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/121:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/122:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/123:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/124:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/125:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
47/126:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((572, 572, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/127: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
47/128:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
47/129:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Cropping2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import MeanIoU

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
47/130:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
47/131:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
experiments_file = out_path / config.get('experiment', 'output file')
47/132:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
47/133:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
47/134:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
47/135:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
47/136:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
47/137:
filter_mult = 2  # todo as arg

def _calc_crop_size(n_layer, conv_cropping):
  """ Calculates the crop size of the skip connection feature map
  given current layer and how much the convolution crops. Assumes the bottom layer is #1 """
  
  res = conv_cropping * 2 ** n_layer + (2 ** (n_layer - 1) - 1) * 2 ** 2 * conv_cropping
  res /= 2  # side crop
  return int(res)


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    cropped = 0  # todo x, y
    n_layers = 2  # todo as arg

    for _ in range(n_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if padding == 'valid':
        cropped += kernel_shape[0] - 1
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x, cropped

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):    
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path  
    x = pooling(x)  # ready for next block    
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x, cropped = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      x = concatenate([x, skip_conn])
    
    x, _ = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      using_skip_conn = not (skip_conn is None)
      if using_skip_conn:
        if padding == 'valid':
          d_width = _calc_crop_size(i + 1, 4)  # todo get from prev layers
          d_height = d_width  # todo rectangular images
            
          print('====', x.shape)
          print(skip_conn.shape)
          print(i, d_height)
          skip_conn = Cropping2D(((d_height, d_height), (d_width, d_width)))(skip_conn)
      
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
47/138:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((572, 572, config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
47/139:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
47/140:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
47/141:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'with_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'best_model_weights': 'without_same.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'best_model_weights': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'with_same_se.h5',
#     'results': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'best_model_weights': 'without_same_se.h5',
#     'results': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'best_model_weights': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'best_model_weights': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None
#   }
]

base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': 3,
  'pool_size': 2,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
47/142:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['best_model_weights']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
47/143:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  model_file = str(out_path / experiment['best_model_weights'])
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  # model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    experiment['best_model_weights'],
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
48/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
48/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
48/3:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
48/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
48/5: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
48/6:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
48/7:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
48/8:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
48/9:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
48/10:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
48/11:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
48/12:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
48/13:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
48/14:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
48/15:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
48/16:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
48/17:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
48/18:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
48/19:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
48/20:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
48/21:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
48/22:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model


args = {
  **base_args,
  'padding': experiment['padding'],
  'use_skip_conn': experiment['use_skip_conn'],
  'use_se_block': experiment['use_se_block']
}

verbose = config.getint('experiment', 'verbose')
model_file = str(out_path / experiment['name'] / 'model.h5')
callbacks = [
  EarlyStopping(patience=10, verbose=verbose),
  ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
  ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]

model = build_unet(**args)
# debug only model.summary()
48/23:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
48/24:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
48/25:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
48/26:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model


args = {
  **base_args,
  'padding': experiment['padding'],
  'use_skip_conn': experiment['use_skip_conn'],
  'use_se_block': experiment['use_se_block']
}

verbose = config.getint('experiment', 'verbose')
model_file = str(out_path / experiment['name'] / 'model.h5')
callbacks = [
  EarlyStopping(patience=10, verbose=verbose),
  ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
  ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
]

model = build_unet(**args)
# debug only model.summary()
48/27:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
48/28:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
48/29:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
48/30:
experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'with_same.h5',
    'results': None,
    'metrics': None
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same.h5',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid.h5',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se.h5',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se.h5',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se.h5',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
48/31:
def calc_padding_out_size(n_layers, conv_kernel_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_kernel_size - 11

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, conv_crop)
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)
      x = _div_tup(x, pool_size)

    x = _sub_tup(x, conv_crop)  # middle

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_size)
      x = _sub_tup(x, conv_crop)
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), conv_kernel_size, pool_size)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
48/32:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
48/33:
def calc_padding_out_size(n_layers, conv_kernel_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_kernel_size - 1

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    x = _sub_tup(x, conv_crop)
    
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)
      x = _div_tup(x, pool_size)

    x = _sub_tup(x, conv_crop)  # middle

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_size)
      x = _sub_tup(x, conv_crop)
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), conv_kernel_size, pool_size)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
48/34:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
48/35:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
48/36:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
      
    x = _sub_tup(x, 4)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), conv_kernel_size, pool_size)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
48/37:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
48/38:
def calc_padding_out_size(n_layers):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, 4)  # conv
      x = _div_tup(x, 2)  # pool

    x = _sub_tup(x, 4)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, 2)  # upsample
      x = _sub_tup(x, 4)  # conv
      
    x = _sub_tup(x, 4)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'))(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
48/39:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
48/40:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
48/41:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig('history.png')

plot_history(experiments, last=45)
48/42:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = p[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
save_experiments(experiments)
48/43:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = pred[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
save_experiments(experiments)
48/44:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = pred[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      experiments[i]['metrics']['DSC'].append(DSC(K.constant(y), K.constant(p)))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
save_experiments(experiments)
48/45:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
48/46:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = pred[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
save_experiments(experiments)
48/47:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true).double() + K.sum(y_pred).double()
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
48/48:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = pred[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
save_experiments(experiments)
49/1:
def calc_padding_out_size(n_layers, conv_layers, conv_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)  # conv
      x = _div_tup(x, pool_crop)  # pool

    x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    calc_padding_out_size(config.getint('unet', 'n layers'), 2, 3, 2)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
49/2:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  y_true = K.cast(y_true, dtype='float32')

  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/3: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
49/4:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
49/5:
import random
import numpy as np
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
49/6:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
49/7:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
49/8:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
49/9:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
49/10:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
49/11:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
49/12:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
49/13:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
49/14:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
49/15:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
49/16:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
49/17:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  y_true = K.cast(y_true, dtype='float32')

  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/18:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
49/19:
def calc_padding_out_size(n_layers, conv_layers, conv_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)  # conv
      x = _div_tup(x, pool_crop)  # pool

    x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    calc_padding_out_size(config.getint('unet', 'n layers'), 2, 3, 2)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
49/20:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/21:
def calc_padding_out_size(n_layers, conv_layers, conv_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)  # conv
      x = _div_tup(x, pool_crop)  # pool

    x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), 2, 3, 2)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
49/22:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/23:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/24:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/25:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/26:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/27:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)  # K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/28:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/29:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
    return 1.0
#   y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
#   intersection = K.sum(y_true * y_pred)
#   union = K.sum(y_true) + K.sum(y_pred)  # K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
#   return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/30:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/31:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)  # K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/32:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)
49/33:
experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
49/34:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
49/35:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/36:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred)  # K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # , DSC]
}
49/37:
for experiment in experiments:
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiment['history'] = results.history
49/38:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU]  # , DSC]
}
49/39:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
49/40:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig('history.png')

plot_history(experiments, last=45)
49/41:
for i, experiment in enumerate(experiments):
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
49/42:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5): 
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = K.sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
49/43:
for i, experiment in enumerate(experiments):
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
49/44:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
49/45:
for i, experiment in enumerate(experiments):
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
49/46:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig('history.png')


plot_history(experiments, last=45)
49/47:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = pred[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
save_experiments(experiments)
49/48:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))


def do_evaluation(X, y, experiments):
  plt.ioff()
    
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):
      X = X_test[ix, ..., 0]
      y = y_test[ix]
      p = pred[ix]
      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y, p))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X, y, p, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
49/49:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
49/50:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))
    plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_all_pred(X_test[ix, ..., 0], y_test[ix], pred[ix], experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
49/51:
def save_all_pred(X, y, pred, model_name, out_folder):
  for ix in range(len(X)):
    fig, ax = plt.subplots(1, 2, figsize=(10, 4))

    ax[0].imshow(X, cmap=config.get('image', 'cmap'))
    ax[0].set_title('original image')

    ax[1].imshow(pred.squeeze(), cmap='gray')
    ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
    ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

    fig.suptitle('sample #{} from {}'.format(ix, model_name))
    fig.savefig(out_folder / '{}.png'.format(ix))
    plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    print(len(X_test))
#     for ix in range(len(X_test)):      
#       experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]))
#       # experiments[i]['metrics']['DSC'].append(DSC(y, p))

#       save_all_pred(X_test[ix, ..., 0], y_test[ix], pred[ix], experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
49/52:
def save_pred(X, y, pred, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X, cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred.squeeze(), cmap='gray')
  ax[1].contour(y.squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_pred(X_test[ix, ..., 0], y_test[ix], pred[ix], experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
49/53:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
49/54: save_experiments(experiments)
49/55:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig('history.png')


plot_history(experiments, last=45)
49/56:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
50/1: experiments
50/2: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
50/3:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
50/4:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
50/5:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
50/6:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
50/7:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
50/8:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
50/9:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
50/10:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
50/11:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
50/12:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
50/13:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
50/14:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
50/15:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
50/16:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se.h5',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
50/17:
def calc_padding_out_size(n_layers, conv_layers, conv_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)  # conv
      x = _div_tup(x, pool_crop)  # pool

    x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), 2, 3, 2)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
50/18:
for i, experiment in enumerate(experiments):
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
50/19:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
50/20:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
50/21:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/22:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]))
      # experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/23: experiments
50/24: save_experiments(experiments)
50/25:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(y, p))

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/26:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(y_test[ix], pred[ix]).numpy())

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/27:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(y_test[ix], pred[ix], axis=[1, 2]).numpy())

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/28:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = K.sum(y_true) + K.sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
50/29:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(y_test[ix], pred[ix], axis=[1, 2]).numpy())

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/30:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(y_test[ix], pred[ix], axis=[1, 2]).numpy())

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/31:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = K.sum(y_true).astype('float32') + K.sum(y_pred).astype('float32')
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
50/32:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(y_test[ix], pred[ix], axis=[1, 2]).numpy())

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/33:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'with_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': False,  # usual
#     'name': 'without_same',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'valid',
#     'name': 'with_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid',
#     'use_se_block': False,  # usual
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': True,  # obviously
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'with_same_se',
#     'results': None,
#     'metrics': None
#   },
#   {
#     'use_skip_conn': False,
#     'padding': 'same',  # usual
#     'use_se_block': True,
#     'name': 'without_same_se',
#     'results': None,
#     'metrics': None
#   },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'results': None,
    'metrics': {}
  },
#   {
#     'use_skip_conn': False,
#     'padding': 'valid',
#     'name': 'without_valid_se',
#     'use_se_block': True,
#     'results': None,
#     'metrics': {}
#   }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
50/34:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']  

    experiments[i]['metrics']['mean IoU'] = []  # todo refactor
    experiments[i]['metrics']['DSC'] = []
    for ix in range(len(X_test)):      
      experiments[i]['metrics']['mean IoU'].append(mean_IoU(y_test[ix], pred[ix]).numpy())
      experiments[i]['metrics']['DSC'].append(DSC(K.constant(y_test[ix]), K.constant(pred[ix]), axis=[1, 2]).numpy())

      save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
      
      
do_evaluation(X, y, experiments)
50/35: save_experiments(experiments)
50/36: experiments
50/37:
for i, experiment in enumerate(experiments):
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
51/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
51/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
51/3:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
51/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
51/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
51/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
51/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
51/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
51/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
51/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
51/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
51/12:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
51/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
51/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
51/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'with_same',
    'metrics': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'without_same',
    'metrics': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid',
    'use_se_block': False,  # usual
    'metrics': None
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid',
    'use_se_block': False,  # usual
    'metrics': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'with_same_se',
    'metrics': None
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'without_same_se',
    'metrics': None
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid_se',
    'use_se_block': True,
    'metrics': {}
  }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
51/16:
def calc_padding_out_size(n_layers, conv_layers, conv_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)  # conv
      x = _div_tup(x, pool_crop)  # pool

    x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), 2, 3, 2)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('=== experiment {}'.format(experiment['name']))
    print('- training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('- validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('- test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
51/17:
for i, experiment in enumerate(experiments):
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = out_path / experiment['name']
  out_folder.mkdir(parents=True, exist_ok=True)
  
  model_file = str(out_folder / 'model.h5')
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
51/18:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
51/19:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.floor(len(experiments) / n_cols) + 1)
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
51/20:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    for metric in metrics:
      experiments[i]['metrics'][metric]['name'] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = experiments[i]['metrics'][metric]['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric]['name'].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
      if verbose:
        print('=== experiment {}'.format(experiment['name']))
        print('= metrics on test set (size: {})'.format(len(X_test)))

        for metric_name, metrics in experiment['metrics'].items():
          print('-- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metrics), np.median(metrics), np.std(metrics)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
51/21:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
51/22:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
      if verbose:
        print('=== experiment {}'.format(experiment['name']))
        print('= metrics on test set (size: {})'.format(len(X_test)))

        for metric_name, metrics in experiment['metrics'].items():
          print('-- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metrics), np.median(metrics), np.std(metrics)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
51/23: experiments  # save_experiments(experiments)
51/24:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    experiments[i]['metrics'] = {}
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
      if verbose:
        print('=== experiment {}'.format(experiment['name']))
        print('= metrics on test set (size: {})'.format(len(X_test)))

        for metric_name, metrics in experiment['metrics'].items():
          print('-- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metrics), np.median(metrics), np.std(metrics)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
51/25:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
      if verbose:
        print('=== experiment {}'.format(experiment['name']))
        print('= metrics on test set (size: {})'.format(len(X_test)))

        for metric_name, metrics in experiment['metrics'].items():
          print('-- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metrics), np.median(metrics), np.std(metrics)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
51/26: experiments  # save_experiments(experiments)
51/27:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    # experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
    if verbose:
      print('=== experiment {}'.format(experiment['name']))
      print('= metrics on test set (size: {})'.format(len(X_test)))

      for metric_name, metric_vals in experiment['metrics'].items():
        print('-- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metric_vals), np.median(metric_vals), np.std(metric_vals)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
51/28:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('original image')

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('{} (ground truth mask as contour)'.format(experiment['name']))

  fig.suptitle('sample #{} from {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(out_path / experiment['name'] / 'model.h5')
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
    if verbose:
      print('=== experiment {}'.format(experiment['name']))
      print('= metrics on test set (size: {})'.format(len(X_test)))

      for metric_name, metric_vals in experiment['metrics'].items():
        print('-- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metric_vals), np.median(metric_vals), np.std(metric_vals)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
51/29: experiments  # save_experiments(experiments)
51/30: save_experiments(experiments)
52/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
52/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
52/3:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
52/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
52/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
52/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
52/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
52/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
52/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
52/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
52/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
52/12:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
52/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
52/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
52/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'with_same',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'without_same',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'with_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'without_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid_se',
    'use_se_block': True,
    'metrics': {}
  }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
52/16:
def calc_padding_out_size(n_layers, conv_layers, conv_size, pool_size):
  """ calculate output size in a U-Net assuming PADDED (i.e "valid") convolutions """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      x = _sub_tup(x, conv_crop)  # conv
      x = _div_tup(x, pool_crop)  # pool

    x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  if experiment['padding'] == 'valid':  # we have to reduce size of output (i.e y)
    img_shape = X.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_padding_out_size(config.getint('unet', 'n layers'), 2, 3, 2)(img_shape)
    output_shape = (*img_out_shape, config.getint('image', 'depth'))
    
    transformations = [
      crop_center_transformation(output_shape),
    ]
    y = apply_transformations(y, transformations)  # reduce output size
    y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
52/17:
def get_model_output_folder(model_name):
  out_folder = out_path / experiment['name']
  return out_folder


def get_model_file(model_name, extension='.h5'):
  return get_model_output_folder(model_name) / 'model' + extension


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/18:
def get_model_output_folder(model_name):
  out_folder = out_path / experiment['name']
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/19:
def get_model_output_folder(model_name):
  out_folder = out_path / experiment['name']
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/20:
def get_model_output_folder(model_name):
  out_folder = out_path / experiment['name']
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/21:
def calc_out_size(n_layers, conv_layers, conv_size, pool_size, padding):
  """ calculate output size in a U-Net """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
      x = _div_tup(x, pool_crop)  # pool

    
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  img_shape = X.shape[1: 2 + 1]  # width, height of input images
  img_out_shape = calc_out_size(config.getint('unet', 'n layers'), 2, 3, 2, experiment['padding'])(img_shape)
  output_shape = (*img_out_shape, config.getint('image', 'depth'))

  transformations = [
    crop_center_transformation(output_shape),
  ]
  y = apply_transformations(y, transformations)  # reduce output size
  y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
52/22:
def get_model_output_folder(model_name):
  out_folder = out_path / experiment['name']
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/23:
def calc_out_size(n_layers, conv_layers, conv_size, pool_size, padding):
  """ calculate output size in a U-Net """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
      x = _div_tup(x, pool_crop)  # pool
    
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers - 1):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
    
    x = _mul_tup(x, pool_crop)  # upsample
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  img_shape = X.shape[1: 2 + 1]  # width, height of input images
  img_out_shape = calc_out_size(config.getint('unet', 'n layers'), 2, 3, 2, experiment['padding'])(img_shape)
  output_shape = (*img_out_shape, config.getint('image', 'depth'))

  transformations = [
    crop_center_transformation(output_shape),
  ]
  y = apply_transformations(y, transformations)  # reduce output size
  y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
52/24:
def get_model_output_folder(model_name):
  out_folder = out_path / experiment['name']
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/25:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
52/26:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      # _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
52/27:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('input image (sample #{})'.format(ix))

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('prediction (ground truth as contour)')

  fig.suptitle('model: {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments): 
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(get_model_file(experiment['name']))
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
    if verbose:
      print('=== experiment {}'.format(experiment['name']))
      print('= metrics on test set (size: {})'.format(len(X_test)))

      for metric_name, metric_vals in experiment['metrics'].items():
        print('- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metric_vals), np.median(metric_vals), np.std(metric_vals)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
52/28:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
52/29:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('input image (sample #{})'.format(ix))

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('prediction (ground truth as contour)')

  fig.suptitle('model: {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments):
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(get_model_file(experiment['name']))
    print(experiment, model_file)
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
    if verbose:
      print('=== experiment {}'.format(experiment['name']))
      print('= metrics on test set (size: {})'.format(len(X_test)))

      for metric_name, metric_vals in experiment['metrics'].items():
        print('- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metric_vals), np.median(metric_vals), np.std(metric_vals)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
52/30:
def get_model_output_folder(model_name):
  out_folder = out_path / model_name
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name


for i, experiment in enumerate(experiments):
  print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
  X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)
  
  args = {
    **base_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }

  verbose = config.getint('experiment', 'verbose')
  out_folder = get_model_output_folder(experiment['name'])
  out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing
  
  model_file = str(get_model_file(experiment['name']))
  callbacks = [
    EarlyStopping(patience=10, verbose=verbose),
    ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
    ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
  ]

  model = build_unet(**args)
  model.summary()
  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    model_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    callbacks,
    compile_args
  )
  experiments[i]['history'] = results.history
52/31:
def perform_experiments(experiments, X, y):
  for i, experiment in enumerate(experiments):
    print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)

    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }

    verbose = config.getint('experiment', 'verbose')
    out_folder = get_model_output_folder(experiment['name'])
    out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing

    model_file = str(get_model_file(experiment['name']))
    callbacks = [
      EarlyStopping(patience=10, verbose=verbose),
      ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
      ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
    ]

    model = build_unet(**args)
    model.summary()
    results = do_training(
      model,
      X_train,
      X_val,
      y_train,
      y_val,
      model_file,
      config.getint('training', 'batch size'),
      config.getint('training', 'epochs'),
      callbacks,
      compile_args
    )
    experiments[i]['history'] = results.history
        
        
perform_experiments(experiments, X, y)
52/32:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('input image (sample #{})'.format(ix))

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('prediction (ground truth as contour)')

  fig.suptitle('model: {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments):
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(get_model_file(experiment['name']))
    print(experiment, model_file)
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
    if verbose:
      print('=== experiment {}'.format(experiment['name']))
      print('= metrics on test set (size: {})'.format(len(X_test)))

      for metric_name, metric_vals in experiment['metrics'].items():
        print('- {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metric_vals), np.median(metric_vals), np.std(metric_vals)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
52/33: save_experiments(experiments)
53/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
53/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
53/3:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
53/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
53/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
53/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
53/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
53/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
53/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
53/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
53/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
53/12:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
53/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
53/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
53/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'with_same',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'without_same',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'with_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'without_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid_se',
    'use_se_block': True,
    'metrics': {}
  }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
53/16:
def calc_out_size(n_layers, conv_layers, conv_size, pool_size, padding):
  """ calculate output size in a U-Net """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x / y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
      x = _div_tup(x, pool_crop)  # pool
    
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers - 1):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
    
    x = _mul_tup(x, pool_crop)  # upsample
    x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  img_shape = X.shape[1: 2 + 1]  # width, height of input images
  img_out_shape = calc_out_size(config.getint('unet', 'n layers'), 2, 3, 2, experiment['padding'])(img_shape)
  output_shape = (*img_out_shape, config.getint('image', 'depth'))

  transformations = [
    crop_center_transformation(output_shape),
  ]
  y = apply_transformations(y, transformations)  # reduce output size
  y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test (not used): X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
53/17:
def get_model_output_folder(model_name):
  out_folder = out_path / model_name
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name
53/18:
def perform_experiments(experiments, X, y):
  for i, experiment in enumerate(experiments):
    print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)

    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }

    verbose = config.getint('experiment', 'verbose')
    out_folder = get_model_output_folder(experiment['name'])
    out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing

    model_file = str(get_model_file(experiment['name']))
    callbacks = [
      EarlyStopping(patience=10, verbose=verbose),
      ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
      ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
    ]

    model = build_unet(**args)
    model.summary()
    results = do_training(
      model,
      X_train,
      X_val,
      y_train,
      y_val,
      model_file,
      config.getint('training', 'batch size'),
      config.getint('training', 'epochs'),
      callbacks,
      compile_args
    )
    experiments[i]['history'] = results.history
        
        
perform_experiments(experiments, X, y)
53/19:
def calc_out_size(n_layers, conv_layers, conv_size, pool_size, padding):
  """ calculate output size in a U-Net """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x // y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
      x = _div_tup(x, pool_crop)  # pool
    
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers - 1):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
    
    x = _mul_tup(x, pool_crop)  # upsample
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  img_shape = X.shape[1: 2 + 1]  # width, height of input images
  img_out_shape = calc_out_size(config.getint('unet', 'n layers'), 2, 3, 2, experiment['padding'])(img_shape)
  output_shape = (*img_out_shape, config.getint('image', 'depth'))

  transformations = [
    crop_center_transformation(output_shape),
  ]
  y = apply_transformations(y, transformations)  # reduce output size
  y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test (not used): X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
53/20:
def perform_experiments(experiments, X, y):
  for i, experiment in enumerate(experiments):
    print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)

    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }

    verbose = config.getint('experiment', 'verbose')
    out_folder = get_model_output_folder(experiment['name'])
    out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing

    model_file = str(get_model_file(experiment['name']))
    callbacks = [
      EarlyStopping(patience=10, verbose=verbose),
      ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
      ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
    ]

    model = build_unet(**args)
    model.summary()
    results = do_training(
      model,
      X_train,
      X_val,
      y_train,
      y_val,
      model_file,
      config.getint('training', 'batch size'),
      config.getint('training', 'epochs'),
      callbacks,
      compile_args
    )
    experiments[i]['history'] = results.history
        
        
perform_experiments(experiments, X, y)
54/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
54/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
54/3:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
54/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
54/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
54/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
54/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
54/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
54/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
54/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
54/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
54/12:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
54/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
54/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
54/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'with_same',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'without_same',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'with_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'without_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid_se',
    'use_se_block': True,
    'metrics': {}
  }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
54/16:
def calc_out_size(n_layers, conv_layers, conv_size, pool_size, padding):
  """ calculate output size in a U-Net """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x // y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
      x = _div_tup(x, pool_crop)  # pool
    
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers - 1):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
    
    x = _mul_tup(x, pool_crop)  # upsample
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  img_shape = X.shape[1: 2 + 1]  # width, height of input images
  img_out_shape = calc_out_size(config.getint('unet', 'n layers'), 2, 3, 2, experiment['padding'])(img_shape)
  output_shape = (*img_out_shape, config.getint('image', 'depth'))

  transformations = [
    crop_center_transformation(output_shape),
  ]
  y = apply_transformations(y, transformations)  # reduce output size
  y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test (not used): X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
54/17:
def get_model_output_folder(model_name):
  out_folder = out_path / model_name
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name
54/18:
def perform_experiments(experiments, X, y):
  for i, experiment in enumerate(experiments):
    print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)

    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }

    verbose = config.getint('experiment', 'verbose')
    out_folder = get_model_output_folder(experiment['name'])
    out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing

    model_file = str(get_model_file(experiment['name']))
    callbacks = [
      EarlyStopping(patience=10, verbose=verbose),
      ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
      ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
    ]

    model = build_unet(**args)
    model.summary()
    results = do_training(
      model,
      X_train,
      X_val,
      y_train,
      y_val,
      model_file,
      config.getint('training', 'batch size'),
      config.getint('training', 'epochs'),
      callbacks,
      compile_args
    )
    experiments[i]['history'] = results.history
        
        
perform_experiments(experiments, X, y)
55/1: # todo assuming channels are last (i.e `keras.backend.set_image_data_format('channels_last')`)
55/2:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
55/3:
import random
import numpy as np

%matplotlib inline
from matplotlib import pyplot as plt

from tifffile import imread

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Reshape, Dense, multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from sklearn.preprocessing import minmax_scale
from tensorflow.keras.preprocessing.image import img_to_array, load_img, save_img
from sklearn.model_selection import train_test_split
55/4:
try:
  from tensorflow.keras.layers.experimental.preprocessing import CenterCrop
  
  print('using tensorflow.keras.layers.experimental.preprocessing.CenterCrop')
except:
  from tensorflow.python.eager import context
  from tensorflow.python.framework import dtypes
  from tensorflow.python.framework import ops
  from tensorflow.python.framework import tensor_shape
  from tensorflow.python.framework import tensor_util
  from tensorflow.python.keras import backend as K
  from tensorflow.python.keras.engine.base_layer import Layer
  from tensorflow.python.keras.engine.input_spec import InputSpec
  from tensorflow.python.keras.utils import tf_utils
  from tensorflow.python.ops import array_ops
  from tensorflow.python.ops import check_ops
  from tensorflow.python.ops import control_flow_ops
  from tensorflow.python.ops import image_ops
  from tensorflow.python.ops import math_ops
  from tensorflow.python.ops import stateful_random_ops
  from tensorflow.python.ops import stateless_random_ops
  from tensorflow.python.ops import variables
  from tensorflow.python.util.tf_export import keras_export

  ResizeMethod = image_ops.ResizeMethod

  H_AXIS = 1
  W_AXIS = 2

  class CenterCrop(Layer):
    """Crop the central portion of the images to target height and width.
    Input shape:
      4D tensor with shape:
      `(samples, height, width, channels)`, data_format='channels_last'.
    Output shape:
      4D tensor with shape:
      `(samples, target_height, target_width, channels)`.
    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.
    Arguments:
      height: Integer, the height of the output shape.
      width: Integer, the width of the output shape.
      name: A string, the name of the layer.
    """

    def __init__(self, height, width, name=None, **kwargs):
      self.target_height = height
      self.target_width = width
      self.input_spec = InputSpec(ndim=4)
      super(CenterCrop, self).__init__(name=name, **kwargs)

    def call(self, inputs):
      inputs_shape = array_ops.shape(inputs)
      img_hd = inputs_shape[H_AXIS]
      img_wd = inputs_shape[W_AXIS]
      img_hd_diff = img_hd - self.target_height
      img_wd_diff = img_wd - self.target_width
      checks = []
      checks.append(
          check_ops.assert_non_negative(
              img_hd_diff,
              message='The crop height {} should not be greater than input '
              'height.'.format(self.target_height)))
      checks.append(
          check_ops.assert_non_negative(
              img_wd_diff,
              message='The crop width {} should not be greater than input '
              'width.'.format(self.target_width)))
      with ops.control_dependencies(checks):
        bbox_h_start = math_ops.cast(img_hd_diff / 2, dtypes.int32)
        bbox_w_start = math_ops.cast(img_wd_diff / 2, dtypes.int32)
        bbox_begin = array_ops.stack([0, bbox_h_start, bbox_w_start, 0])
        bbox_size = array_ops.stack(
            [-1, self.target_height, self.target_width, -1])
        outputs = array_ops.slice(inputs, bbox_begin, bbox_size)
        return outputs

    def compute_output_shape(self, input_shape):
      input_shape = tensor_shape.TensorShape(input_shape).as_list()
      return tensor_shape.TensorShape(
          [input_shape[0], self.target_height, self.target_width, input_shape[3]])

    def get_config(self):
      config = {
          'height': self.target_height,
          'width': self.target_width,
      }
      base_config = super(CenterCrop, self).get_config()
      return dict(list(base_config.items()) + list(config.items()))

  print('using https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L121-L184')
55/5:
from configparser import ConfigParser

try:
    from google.colab import files
    
    print('upload `config.ini`')
    uploaded = files.upload()
except:
    print('no colab detected -> reading from local disk')

config = ConfigParser()
config.read('./config.ini')
55/6:
import os
from pathlib import Path
import json
import ast

try:
  from google.colab import drive
  drive.mount('/content/gdrive')
  data_path = Path(config.get('data folder', 'colab'))
except:
  import os
  from pathlib import Path
  here = Path(os.getcwd())
  data_path = here / config.get('data folder', 'taurus')

data_path = data_path.resolve()
out_path = Path(config.get('experiment', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)
experiments_file = out_path / config.get('experiment', 'output file')
55/7:
def load_tiff(f):
  return imread(f)


def load_image(f):
  return load_tiff(f)


def load_mask(f):
  return load_tiff(f)


def get_data(imgs_path, masks_path):
  list_imgs = [
      f
      for f in imgs_path.iterdir()
      if str(f).endswith('.tif')
  ]
  
  images = []
  masks = []
 
  for img_path in list_imgs:
    img = load_image(img_path).squeeze()
    
    mask_path = str(img_path).replace(str(imgs_path), str(masks_path)).replace('img_', 'mask_')
    mask = load_mask(mask_path)
     
    images.append(np.array(img))
    masks.append(np.array(mask))

  return images, masks
55/8:
def normalize_transformation(feature_range):
  def _f(x):
    shape = x.shape
    x = minmax_scale(x.ravel(), feature_range=feature_range)
    x = x.reshape(shape)  # original size
    return x
  
  return _f


def crop_center_transformation(shape):
  height, width, *_ = shape  # 3rd dim not needed

  def get_start_point(dim, cropping):
    return dim // 2 - cropping // 2
  
  def get_end_point(start, cropping):
    return start + cropping
  
  def _f(img):
    y, x, *_ = img.shape  # n channels not wanted
    (start_x, start_y) = (get_start_point(x, width), get_start_point(y, height))
    (end_x, end_y) = (get_end_point(start_x, width), get_end_point(start_y, height))
    return img[start_y : end_y, start_x : end_x, ...]
  
  return _f


def rm_percentiles_transformation(min_p=0.0, max_p=100.0):
  def _f(x):
    shape = x.shape
    x = x.ravel()
    new_min, new_max = np.percentile(x, [min_p, max_p])
    x[x < new_min] = new_min
    x[x > new_max] = new_max
    return x.reshape(shape)
  
  return _f


def add_dim():
  def _f(x):
    new_dim_index = len(x.shape)
    x = np.expand_dims(x, new_dim_index)
    return x

  return _f


def compose_transformations(transformations):
  def _f(x):
    for t in transformations:
      x = t(x)
    return x
  
  return _f


def apply_transformations(lst, transformations):
  t = compose_transformations(transformations) 
  return [
    t(x) for x in lst
  ]


def do_transformations(X, y, transformations):
  X = apply_transformations(X, transformations)
  y = apply_transformations(y, transformations)
  return X, y


def parse_data(raw):
  X, y = raw
  img_shape = (config.getint('image', 'width'), config.getint('image', 'height'))
  transformations = [
    np.array,  # just in case parser did not np.array-ed
    rm_percentiles_transformation(2, 98),  # threshold outliers
    normalize_transformation((0, 1)),  # pixel values in [0, 1]
    crop_center_transformation(img_shape),
    add_dim()
  ]
  X, y = apply_transformations(X, transformations), apply_transformations(y, transformations)
  X, y = np.array(X), np.array(y)  # python list -> np.array
  return X, y
55/9:
X, y = parse_data(
  get_data(
    data_path / config.get('data folder', 'images'),
    data_path / config.get('data folder', 'masks')
  )
)

print('X ~ {}, y ~ {}'.format(X.shape, y.shape))
55/10:
def plot_sample(X, y, ix=None):
  if ix is None:
    ix = random.randint(0, len(X) - 1)

  fig, ax = plt.subplots(1, 3, figsize=(15, 4))

  im = ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  fig.colorbar(im, ax=ax[0])
  ax[0].set_title('image ({} map)'.format(config.get('image', 'cmap')))

  ax[1].hist(X[ix, ...].ravel(), bins=256)
  ax[1].set_title('histogram of image')

  ax[2].imshow(y[ix].squeeze(), cmap='gray')
  ax[2].set_title('mask')

  fig.suptitle('sample #{}'.format(ix))
    
  return ix


plot_sample(X, y)  # check if data looks all right
55/11:
def se_block(r=16.0):
  def squeeze(x):
    return GlobalAveragePooling2D()(x)
  
  def fc(n_filters, activation):
    def _f(x):
      return Dense(n_filters, activation=activation, use_bias=False)(x)
    
    return _f
  
  def excite(x, n_channels, r):
    # se = Reshape(se_shape)(se)
    x = fc(n_channels // r, 'relu')(x)
    x = fc(n_channels, 'sigmoid')(x)
    return x

  def _f(x):
    n_channels = x.shape[-1]

    inp = x  # save for later
    x = squeeze(x)
    x = excite(x, n_channels, r)
    return multiply([inp, x])
  
  return _f
55/12:
filter_mult = 2  # todo as arg
n_conv_layers = 2  # todo as arg


def conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True):
  activation = 'relu'

  def _f(x):
    n_layers = 2

    for _ in range(n_conv_layers):
      x = Conv2D(n_filters, kernel_shape, padding=padding)(x)
      
      if batchnorm:
        x = BatchNormalization()(x)
      
      x = Activation(activation=activation)(x)
      
      if use_se_block:
        x = se_block()(x)

      if dropout > 0:
        x = Dropout(dropout)(x)

    return x

  return _f


def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  pooling = MaxPooling2D(pool_shape)

  def _f(x):
    x = conv2d_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm)(x)
    skip_conn = x  # save for expanding path
    x = pooling(x)  # ready for next block
    return x, skip_conn

  return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    skip_conns = []
    current_n_filters = n_filters

    for _ in range(n_layers):
      x, s = contracting_block(current_n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters * filter_mult)
      
      if not use_skip_conn:
        s = None  # not to be used
      
      skip_conns.append(s)

    return x, skip_conns

  return _f


def middle_path(kernel_shape, padding, dropout, batchnorm):
  def _f(x):
    n_filters = int(x.shape[-1] * filter_mult)
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  upsampling = UpSampling2D(pool_shape)

  def _f(x):
    if use_se_block:
      x = se_block()(x)
    
    x = upsampling(x)
    
    using_skip_conn = not (skip_conn is None)
    if using_skip_conn:
      s = CenterCrop(x.shape[1], x.shape[2])(skip_conn)
      x = concatenate([x, s])
    
    x = conv2d_block(n_filters, kernel_shape, padding, dropout, batchnorm)(x)
    return x

  return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm):
  def _f(x):
    current_n_filters = n_filters

    for i, skip_conn in enumerate(reversed(skip_conns)):
      x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
      current_n_filters = int(current_n_filters / filter_mult)

    return x

  return _f


def final_path(n_classes, activation, padding, use_se_block):
  def _f(x):
    if use_se_block:
      x = se_block()(x)

    x = Conv2D(n_classes, (1, 1), padding=padding, activation=activation)(x)
    return x

  return _f


def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm):
  def _f(x):
    x, skip_conns = contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm)(x)
    x = middle_path(kernel_shape, padding, dropout, batchnorm)(x)

    current_n_filters = skip_conns[-1].shape[-1] if use_skip_conn else n_filters * filter_mult ** (n_layers - 1)
    x = expanding_path(current_n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm)(x)
    x = final_path(n_classes, final_activation, padding, use_se_block)(x)
    return x

  return _f
55/13:
def build_unet(n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False):
  n_dim = 2  # todo as arg
  kernel_shape = (kernel_size, ) * n_dim
  pool_shape = (pool_size, ) * n_dim
  
  inp = Input((config.getint('image', 'width'), config.getint('image', 'height'), config.getint('image', 'depth')))  # save for later
  out = unet_block(
    n_filters,
    n_layers,
    kernel_shape,
    pool_shape,
    n_classes,
    final_activation,
    padding,
    use_skip_conn,
    use_se_block,
    dropout,
    batchnorm
  )(inp)
  
  model = Model(inputs=inp, outputs=out)
  return model
55/14:
def do_training(model, X_train, X_test, y_train, y_test, best_model_weights_file, batch_size, epochs, callbacks, compile_args):
  verbose = config.getint('experiment', 'verbose')
  
  model.compile(**compile_args)
  results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, validation_data=(X_test, y_test))
  
  return results

def do_inference(model, best_model_weights_file, data, batch_size):
  verbose = config.getint('experiment', 'verbose')
  
  model.load_weights(best_model_weights_file)
  preds_val = model.predict(data, verbose=verbose, batch_size=batch_size)
  return preds_val
55/15:
def eps_divide(n, d, eps=K.epsilon()):
  """ perform division using eps """
    
  return (n + eps) / (d + eps)


def iou(y_true, y_pred, threshold=0.5):
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  inter = K.sum(y_true * y_pred)
  union = K.sum(y_true + y_pred) - inter
  return eps_divide(inter, union)


def mean_IoU(y_true, y_pred, threshold=0.5):
  res = iou(y_true, y_pred, threshold=threshold)
  return K.mean(res)


def batch_metric(metric_func):
  def _f(y_true, y_pred):
    batch_size = y_true.shape[0]
    metric = []

    for batch in range(batch_size):
        value = metric_func(y_true[batch], y_pred[batch])
        metric.append(value)

    return np.array(metric, dtype=np.float32)

  return _f


def DSC(y_true, y_pred, smooth=1.0, threshold=0.5, axis=[1, 2, 3]):
  def _sum(x):
    return K.sum(x, axis=axis)
  
  y_pred = K.cast(K.greater(y_pred, threshold), dtype='float32')
  intersection = _sum(y_true * y_pred)
  union = _sum(y_true) + _sum(y_pred)
  return K.mean(eps_divide(2.0 * intersection, union + smooth, eps=smooth), axis=0)


experiments = [
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'with_same',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': False,  # usual
    'name': 'without_same',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid',
    'use_se_block': False,  # usual
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'with_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'same',  # usual
    'use_se_block': True,
    'name': 'without_same_se',
    'metrics': {}
  },
  {
    'use_skip_conn': True,  # obviously
    'padding': 'valid',
    'name': 'with_valid_se',
    'use_se_block': True,
    'metrics': {}
  },
  {
    'use_skip_conn': False,
    'padding': 'valid',
    'name': 'without_valid_se',
    'use_se_block': True,
    'metrics': {}
  }
]

conv_kernel_size = 3
pool_size = 2
base_args = {
  'n_filters': config.getint('unet', 'n filters'),
  'n_layers': config.getint('unet', 'n layers'),
  'kernel_size': conv_kernel_size,
  'pool_size': pool_size,
  'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
  'final_activation': config.get('unet', 'final activation'),
  'dropout': config.getfloat('unet', 'dropout'),
  'batchnorm': config.getboolean('unet', 'batchnorm')
}

compile_args = {
  'optimizer': config.get('training', 'optimizer'),
  'loss': config.get('training', 'loss'),
  'metrics': ['accuracy', mean_IoU, DSC]
}
55/16:
def calc_out_size(n_layers, conv_layers, conv_size, pool_size, padding):
  """ calculate output size in a U-Net """
  
  conv_crop = conv_layers * (conv_size - 1)
  pool_crop = pool_size

  def _div_tup(t, y):
    return (x // y for x in t)

  def _mul_tup(t, y):
    return (x * y for x in t)

  def _sub_tup(t, y):
    return (x - y for x in t)

  def _f(x):
    for _ in range(n_layers):  # contracting path
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
      
      x = _div_tup(x, pool_crop)  # pool
    
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # conv

    for _ in range(n_layers - 1):  # expanding path
      x = _mul_tup(x, pool_crop)  # upsample
      if padding == 'valid':
        x = _sub_tup(x, conv_crop)  # conv
    
    x = _mul_tup(x, pool_crop)  # upsample
    if padding == 'valid':
      x = _sub_tup(x, conv_crop)  # final
    
    x = tuple(int(_x) for _x in x)
    return x

  return _f


def train_validate_test_split(x, y, valid_size, test_size, *args, **kwargs):
  X_train, X_val, y_train, y_val = train_test_split(
    x, y, test_size=valid_size + test_size, *args, **kwargs
  )
  test_size = test_size / (test_size + valid_size)  # wrt to valid
  X_val, X_test, y_val, y_test = train_test_split(
    X_val, y_val, test_size=test_size, **kwargs
  )
  return X_train, X_val, X_test, y_train, y_val, y_test


def prepare_data(X, y, experiment, verbose=False):
  img_shape = X.shape[1: 2 + 1]  # width, height of input images
  img_out_shape = calc_out_size(config.getint('unet', 'n layers'), 2, 3, 2, experiment['padding'])(img_shape)
  output_shape = (*img_out_shape, config.getint('image', 'depth'))

  transformations = [
    crop_center_transformation(output_shape),
  ]
  y = apply_transformations(y, transformations)  # reduce output size
  y = np.array(y)

  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X, y, config.getfloat('experiment', 'val size'), config.getfloat('experiment', 'test size'), random_state=11
  )
  
  if verbose:
    print('= dataset training: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
    print('= dataset validation: X ~ {}, y ~ {}'.format(X_val.shape, y_val.shape))
    print('= dataset test (not used): X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
  
  return X_train, X_val, X_test, y_train, y_val, y_test
55/17:
def get_model_output_folder(model_name):
  out_folder = out_path / model_name
  return out_folder


def get_model_file(model_name, extension='.h5'):
  file_name = 'model' + extension
  return get_model_output_folder(model_name) / file_name
55/18:
def perform_experiments(experiments, X, y):
  for i, experiment in enumerate(experiments):
    print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(X, y, experiment, verbose=True)

    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }

    verbose = config.getint('experiment', 'verbose')
    out_folder = get_model_output_folder(experiment['name'])
    out_folder.mkdir(parents=True, exist_ok=True)  # mkdir -p, removes if existing

    model_file = str(get_model_file(experiment['name']))
    callbacks = [
      EarlyStopping(patience=10, verbose=verbose),
      ReduceLROnPlateau(factor=1e-1, patience=3, min_lr=1e-5, verbose=verbose),
      ModelCheckpoint(model_file, monitor='loss', verbose=verbose, save_best_only=True, save_weights_only=True)
    ]

    model = build_unet(**args)
    model.summary()
    results = do_training(
      model,
      X_train,
      X_val,
      y_train,
      y_val,
      model_file,
      config.getint('training', 'batch size'),
      config.getint('training', 'epochs'),
      callbacks,
      compile_args
    )
    experiments[i]['history'] = results.history
        
        
perform_experiments(experiments, X, y)
55/19:
def is_numpy_array(x):
  return type(x) == type(np.zeros(1))
  

def is_lst(x):
  return type(x) == type([])


def save_experiments(experiments):
  out = [
    {
      k: v.tolist() if is_numpy_array(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]
  
  with open(experiments_file, 'w') as fp:
    json.dump(str(out), fp)
      

def load_experiments():
  with open(experiments_file, 'r') as fp:
    experiments = ast.literal_eval(json.load(fp))
    experiments = [
      {
        k: np.array(v) if is_lst(v) else v
        for k, v in experiment.items()
      }
      for experiment in experiments
    ]
    
    return experiments
55/20:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=45)
55/21:
def save_pred(X, y, pred, ix, model_name, out_folder):
  fig, ax = plt.subplots(1, 2, figsize=(10, 4))

  ax[0].imshow(X[ix, ..., 0], cmap=config.get('image', 'cmap'))
  ax[0].set_title('input image (sample #{})'.format(ix))

  ax[1].imshow(pred[ix].squeeze(), cmap='gray')
  ax[1].contour(y[ix].squeeze(), colors='yellow', levels=[0.5])
  ax[1].set_title('prediction (ground truth as contour)')

  fig.suptitle('model: {}'.format(ix, model_name))
  fig.savefig(out_folder / '{}.png'.format(ix))
  plt.close(fig)


def do_evaluation(X, y, experiments, save_figs=False, verbose=False):
  for i, experiment in enumerate(experiments):
    _, _, X_test, _, _, y_test = prepare_data(X, y, experiment, verbose=False)
    args = {
      **base_args,
      'padding': experiment['padding'],
      'use_skip_conn': experiment['use_skip_conn'],
      'use_se_block': experiment['use_se_block']
    }  # todo build args from experiment
    model = build_unet(**args)
    model_file = str(get_model_file(experiment['name']))
    pred = do_inference(model, model_file, X_test, config.getint('training', 'batch size'))
    out_folder = out_path / experiment['name']
    
    metrics = [
      {
        'name': 'mean IoU',
        'callback': mean_IoU
      },
      {
        'name': 'DSC',
        'callback': lambda y_true, y_pred: DSC(K.constant(y_true), K.constant(y_pred), axis=[1, 2])
      }
    ]
    experiments[i]['metrics'] = {}
    for metric in metrics:
      experiments[i]['metrics'][metric['name']] = []  # reset
    
    for ix in range(len(X_test)):
      for metric in metrics:
        metric_f = metric['callback']
        metric_val = metric_f(y_test[ix], pred[ix]).numpy()
        experiments[i]['metrics'][metric['name']].append(metric_val)

      if save_figs:
        save_pred(X_test, y_test, pred, ix, experiment['name'], out_folder)
        
    if verbose:
      print('=== experiment # {} / {}: {}'.format(i, len(experiments), experiment['name']))
      print('= metrics on test set (size: {})'.format(len(X_test)))

      for metric_name, metric_vals in experiment['metrics'].items():
        print('= {:>10} ~ mean {:.3f} median {:.3f} std {:.3f}'.format(metric_name, np.mean(metric_vals), np.median(metric_vals), np.std(metric_vals)))


do_evaluation(X, y, experiments, save_figs=True, verbose=True)
55/22: save_experiments(experiments)
55/23:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=40)
55/24:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=30)
55/25:
def plot_history(experiments, last=None):
  if last is None:
    last = 0
  
  n_cols = 2
  n_rows = int(np.ceil(len(experiments) / n_cols))
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
  
  def _plot_key_results(ax, key, results, color, find_min=False, find_max=False):
      training = results[key]
      validation = results['val_{}'.format(key)]
    
      ax.plot(training, label='training {}'.format(key), color=color)
      ax.plot(validation, '--', label='validation {}'.format(key), color=color)
      
      if find_min:
        ax.plot(np.argmin(validation), np.min(validation), marker='x', color='r')
        
      if find_max:
        ax.plot(np.argmax(validation), np.max(validation), marker='x', color='r')
    
  def _plot_results(results, ax, title):
      _plot_key_results(ax, 'loss', results, 'C1', find_min=True)  # see https://matplotlib.org/3.1.1/users/dflt_style_changes.html
      ax.set_ylabel('log loss', color='C3')
      ax.legend()

      ax = ax.twinx()  # instantiate a second axes that shares the same x-axis

      _plot_key_results(ax, 'mean_IoU', results, 'C0', find_max=True)
      _plot_key_results(ax, 'DSC', results, 'C2', find_max=True)
      
      ax.set_ylabel('metrics', color='b')
      ax.legend()

      ax.set_title(title)

  for ax, experiment in zip(axis.ravel(), experiments):
      history = experiment['history']
      results = {
        k: history[k][-last:]
        for k in history.keys()
      }
      
      _plot_results(results, ax, experiment['name'])
    
  fig.savefig(out_path / 'history.png')


plot_history(experiments, last=40)
56/1: import scikit-learn
56/2: import sklearn
56/3:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
56/4: from tensorflow.keras import backend as K
58/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
58/2: _here
58/3:
def get_default_args(config):
  conv_kernel_size = 3
  pool_size = 2

  model_args = {
    'n_filters': config.getint('unet', 'n filters'),
    'n_layers': config.getint('unet', 'n layers'),
    'kernel_size': conv_kernel_size,
    'pool_size': pool_size,
    'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
    'final_activation': config.get('unet', 'final activation'),
    'dropout': config.getfloat('unet', 'dropout'),
    'batchnorm': config.getboolean('unet', 'batchnorm')
  }

  compile_args = {
    'optimizer': config.get('training', 'optimizer'),
    'loss': config.get('training', 'loss'),
    'metrics': ['accuracy', mean_IoU, DSC]
  }

  return model_args, compile_args


def do_experiment(experiment, data, config, out_path):  # todo refactor
  def _fix_data_shape(img_out_shape):
    def _f(x):
      output_shape = (*img_out_shape, config.getint('image', 'depth'))

      transformations = [
        crop_center_transformation(output_shape),
      ]
      x = apply_transformations(x, transformations)  # reduce output size
      x = np.array(x)
      return x

    return _f


  def _prepare_data(data):
    (X_train, X_val, X_test, y_train, y_val, y_test) = data  # unpack

    img_shape = y_train.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_out_size(
      config.getint('unet', 'n layers'),
      2,
      3,
      2,
      experiment['padding']
    )(img_shape)

    y_train = _fix_data_shape(img_out_shape)(y_train)
    y_val = _fix_data_shape(img_out_shape)(y_val)
    y_test = _fix_data_shape(img_out_shape)(y_test)

    return (X_train, X_val, X_test, y_train, y_val, y_test)


  (X_train, X_val, X_test, y_train, y_val, y_test) = _prepare_data(data)

  if config.getint('experiments', 'verbose'):
    describe(X_train, X_val, X_test, y_train, y_val, y_test)

  model_args, compile_args = get_default_args(config)
  args = {
    **model_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_model(**args)
  weights_file = str(get_weights_file(out_path, experiment['name']))

  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    weights_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    compile_args,
    config.getint('experiments', 'verbose')
  )

  stats, preds = do_evaluation(
    model,
    weights_file,
    X_test,
    y_test,
    config.getint('training', 'batch size'),
    config.getint('experiments', 'verbose')
  )

  plot_preds(
    X_test,
    y_test,
    preds,
    cmap=config.get('image', 'cmap'),
    title='model: {}'.format(experiment['name']),
    out_folder=get_model_output_folder(out_path, experiment['name'])
  )

  return results, stats


def do_experiments(experiments, data, config, out_path):  # todo refactor
  if config.getint('experiments', 'verbose'):
    print('ready to perform {} experiments'.format(len(experiments)))

  X, y = data  # unpack
  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X,
    y,
    config.getfloat('experiment', 'val size'),
    config.getfloat('experiment', 'test size')
  )

  for i, experiment in enumerate(experiments):
    if config.getint('experiments', 'verbose'):
      print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))

    data = (X_train, X_val, X_test, y_train, y_val, y_test)
    results, eval_stats = do_experiment(experiment, data, config, out_path)

    experiments[i]['history'] = results.history
    experiments[i]['eval'] = eval_stats

  last_epochs = int(config.getint('training', 'epochs') * 0.8)
  plot_history(experiments, out_path / 'history.png', last=last_epochs)

  return experiments
58/4:
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data folder', 'images')
masks_path = data_path / config.get('data folder', 'masks')
raw = get_data(images_path, masks_path)
X, y = parse_data(
raw,
(config.getint('image', 'width'), config.getint('image', 'height'))
)
58/5:
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
raw = get_data(images_path, masks_path)
X, y = parse_data(
raw,
(config.getint('image', 'width'), config.getint('image', 'height'))
)
58/6:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
58/7:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
58/8:
experiments_file = _here / config.get('experiments', 'output file')

with open(experiments_file, 'r') as fp:
    experiments = json.loads(fp)
58/9:
experiments_file = _here / config.get('experiments', 'output file')

import json
with open(experiments_file, 'r') as fp:
    experiments = json.loads(fp)
58/10:
experiments_file = _here / config.get('experiments', 'output file')

import json
with open(experiments_file, 'r') as fp:
    experiments = json.load(fp)
58/11: experiments
58/12: X.shape
58/13: do_experiments(experiments, (X, y), config, out_path)
59/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
59/2:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
60/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
62/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
63/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
64/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
65/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
66/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
67/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
68/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
70/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
70/2: !python --version
70/3: !python --version
70/4:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
70/5:
from pathlib import Path

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
70/6:
import os
print("PYTHONPATH:", os.environ.get('PYTHONPATH'))
print("PATH:", os.environ.get('PATH'))
70/7:
import os
print("PYTHONPATH:", os.environ.get('PYTHONPATH'))
print("PATH:", os.environ.get('PATH'))
70/8:
import os
print("PYTHONPATH:", os.environ.get('PYTHONPATH'))
print("PATH:", os.environ.get('PATH'))
70/9: !module load modenv/ml
70/10:
!module load modenv/ml
!module load modenv/scs5
!module load scikit-learn
!module load Keras
!module load TensorFlow
70/11:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
70/12:
from pathlib import Path
import tensorflow
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
70/13:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
71/1: import tensorflow
72/1: import tensorflow
73/1:
from tensorflow.keras import backend as K
K.clear_session()

import tensorflow as tf
tf.config.experimental.list_physical_devices()
74/1:
!module load modenv/ml
!module load modenv/scs5
!module load scikit-learn
!module load Keras
!module load TensorFlow
74/2:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
74/3: !python --version
78/1: !python --version
78/2:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
79/1: import numpy
79/2: import tensorflow
79/3: import keras
80/1: !python --version
80/2:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
81/1: !python --version
81/2: !python --version
81/3: !which python
82/1: !python --version
82/2: !python --version
82/3: !which python
83/1: !which python
83/2: !conda install keras
84/1: !which python
84/2: !python --version
85/1: !python --version
85/2: !python --version
86/1: !python --version
86/2: !python --version
86/3: !python --version
86/4: import tifffile
87/1: import tifffile
87/2: import tifffile
87/3: !which python
88/1: !which python
89/1: import tifffile
89/2: !which python
90/1: !which python
91/1: !which python
91/2: !python --version
91/3: import tifffile
92/1: !python --version
93/1: !python --version
93/2: !python --version
93/3: import tifffile
94/1: !python --version
94/2: import tifffile
95/1: !python --version
95/2: import tifffile
95/3:
import tifffile
import keras
96/1: !python --version
96/2: import tifffile
97/1: !python --version
97/2: import tifffile
98/1: !python --version
98/2: import tifffile
98/3: import tensorflow
98/4: import scikit-learn
98/5: import scikit
98/6: import sklearn
98/7: import keras
98/8: import sklearn
98/9:
import sklearn
import tifffile
99/1: !python --version
99/2: import tensorflow
99/3: import keras
99/4: !python --version
99/5: import tifffile
99/6:
import tifffile
import sklearn
101/1:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
101/2: !python --version
101/3:
def get_default_args(config):
  conv_kernel_size = 3
  pool_size = 2

  model_args = {
    'n_filters': config.getint('unet', 'n filters'),
    'n_layers': config.getint('unet', 'n layers'),
    'kernel_size': conv_kernel_size,
    'pool_size': pool_size,
    'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
    'final_activation': config.get('unet', 'final activation'),
    'dropout': config.getfloat('unet', 'dropout'),
    'batchnorm': config.getboolean('unet', 'batchnorm')
  }

  compile_args = {
    'optimizer': config.get('training', 'optimizer'),
    'loss': config.get('training', 'loss'),
    'metrics': ['accuracy', mean_IoU, DSC]
  }

  return model_args, compile_args


def do_experiment(experiment, data, config, out_path):  # todo refactor
  def _fix_data_shape(img_out_shape):
    def _f(x):
      output_shape = (*img_out_shape, config.getint('image', 'depth'))

      transformations = [
        crop_center_transformation(output_shape),
      ]
      x = apply_transformations(x, transformations)  # reduce output size
      x = np.array(x)
      return x

    return _f


  def _prepare_data(data):
    (X_train, X_val, X_test, y_train, y_val, y_test) = data  # unpack

    img_shape = y_train.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_out_size(
      config.getint('unet', 'n layers'),
      2,
      3,
      2,
      experiment['padding']
    )(img_shape)

    y_train = _fix_data_shape(img_out_shape)(y_train)
    y_val = _fix_data_shape(img_out_shape)(y_val)
    y_test = _fix_data_shape(img_out_shape)(y_test)

    return (X_train, X_val, X_test, y_train, y_val, y_test)


  (X_train, X_val, X_test, y_train, y_val, y_test) = _prepare_data(data)

  if config.getint('experiments', 'verbose'):
    describe(X_train, X_val, X_test, y_train, y_val, y_test)

  model_args, compile_args = get_default_args(config)
  args = {
    **model_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_model(**args)
  weights_file = str(get_weights_file(out_path, experiment['name']))

  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    weights_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    compile_args,
    config.getint('experiments', 'verbose')
  )

  stats, preds = do_evaluation(
    model,
    weights_file,
    X_test,
    y_test,
    config.getint('training', 'batch size'),
    config.getint('experiments', 'verbose')
  )

  plot_preds(
    X_test,
    y_test,
    preds,
    cmap=config.get('image', 'cmap'),
    title='model: {}'.format(experiment['name']),
    out_folder=get_model_output_folder(out_path, experiment['name'])
  )

  return results, stats


def do_experiments(experiments, data, config, out_path):  # todo refactor
  if config.getint('experiments', 'verbose'):
    print('ready to perform {} experiments'.format(len(experiments)))

  X, y = data  # unpack
  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X,
    y,
    config.getfloat('experiment', 'val size'),
    config.getfloat('experiment', 'test size')
  )

  for i, experiment in enumerate(experiments):
    if config.getint('experiments', 'verbose'):
      print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))

    data = (X_train, X_val, X_test, y_train, y_val, y_test)
    results, eval_stats = do_experiment(experiment, data, config, out_path)

    experiments[i]['history'] = results.history
    experiments[i]['eval'] = eval_stats

  last_epochs = int(config.getint('training', 'epochs') * 0.8)
  plot_history(experiments, out_path / 'history.png', last=last_epochs)

  return experiments
101/4:
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
raw = get_data(images_path, masks_path)
X, y = parse_data(
  raw,
  (config.getint('image', 'width'), config.getint('image', 'height'))
)
101/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/6:
experiments_file = _here / config.get('experiments', 'output file')
# experiments = load_experiments(experiments_file)
experiments_file
101/7:
experiments_file = _here / config.get('experiments', 'output file')
# experiments = load_experiments(experiments_file)
with open(experiments_file, 'r') as fp:
  experiments = ast.literal_eval(json.load(fp))
101/8:
experiments_file = _here / config.get('experiments', 'output file')
# experiments = load_experiments(experiments_file)
with open(experiments_file, 'r') as fp:
  experiments = json.load(fp)
101/9:
experiments_file = _here / config.get('experiments', 'output file')
# experiments = load_experiments(experiments_file)
import json
with open(experiments_file, 'r') as fp:
  experiments = json.load(fp)
101/10:
experiments_file = _here / config.get('experiments', 'output file')
# experiments = load_experiments(experiments_file)
import json
with open(experiments_file, 'r') as fp:
  experiments = json.load(fp)
101/11: experiments
101/12: do_experiments(experiments, (X, y), config, out_path)
101/13: do_experiments(experiments, (X, y), config, out_path)
101/14:
def get_default_args(config):
  conv_kernel_size = 3
  pool_size = 2

  model_args = {
    'n_filters': config.getint('unet', 'n filters'),
    'n_layers': config.getint('unet', 'n layers'),
    'kernel_size': conv_kernel_size,
    'pool_size': pool_size,
    'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
    'final_activation': config.get('unet', 'final activation'),
    'dropout': config.getfloat('unet', 'dropout'),
    'batchnorm': config.getboolean('unet', 'batchnorm')
  }

  compile_args = {
    'optimizer': config.get('training', 'optimizer'),
    'loss': config.get('training', 'loss'),
    'metrics': ['accuracy', mean_IoU, DSC]
  }

  return model_args, compile_args


def do_experiment(experiment, data, config, out_path):  # todo refactor
  def _fix_data_shape(img_out_shape):
    def _f(x):
      output_shape = (*img_out_shape, config.getint('image', 'depth'))

      transformations = [
        crop_center_transformation(output_shape),
      ]
      x = apply_transformations(x, transformations)  # reduce output size
      x = np.array(x)
      return x

    return _f


  def _prepare_data(data):
    (X_train, X_val, X_test, y_train, y_val, y_test) = data  # unpack

    img_shape = y_train.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_out_size(
      config.getint('unet', 'n layers'),
      2,
      3,
      2,
      experiment['padding']
    )(img_shape)

    y_train = _fix_data_shape(img_out_shape)(y_train)
    y_val = _fix_data_shape(img_out_shape)(y_val)
    y_test = _fix_data_shape(img_out_shape)(y_test)

    return (X_train, X_val, X_test, y_train, y_val, y_test)


  (X_train, X_val, X_test, y_train, y_val, y_test) = _prepare_data(data)

  if config.getint('experiments', 'verbose'):
    describe(X_train, X_val, X_test, y_train, y_val, y_test)

  model_args, compile_args = get_default_args(config)
  args = {
    **model_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_model(**args)
  weights_file = str(get_weights_file(out_path, experiment['name']))

  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    weights_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    compile_args,
    config.getint('experiments', 'verbose')
  )

  stats, preds = do_evaluation(
    model,
    weights_file,
    X_test,
    y_test,
    config.getint('training', 'batch size'),
    config.getint('experiments', 'verbose')
  )

  plot_preds(
    X_test,
    y_test,
    preds,
    cmap=config.get('image', 'cmap'),
    title='model: {}'.format(experiment['name']),
    out_folder=get_model_output_folder(out_path, experiment['name'])
  )

  return results, stats


def do_experiments(experiments, data, config, out_path):  # todo refactor
  if config.getint('experiments', 'verbose'):
    print('ready to perform {} experiments'.format(len(experiments)))

  X, y = data  # unpack
  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X,
    y,
    config.getfloat('experiments', 'val size'),
    config.getfloat('experiments', 'test size')
  )

  for i, experiment in enumerate(experiments):
    if config.getint('experiments', 'verbose'):
      print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))

    data = (X_train, X_val, X_test, y_train, y_val, y_test)
    results, eval_stats = do_experiment(experiment, data, config, out_path)

    experiments[i]['history'] = results.history
    experiments[i]['eval'] = eval_stats

  last_epochs = int(config.getint('training', 'epochs') * 0.8)
  plot_history(experiments, out_path / 'history.png', last=last_epochs)

  return experiments
101/15: do_experiments(experiments, (X, y), config, out_path)
101/16:
def get_default_args(config):
  conv_kernel_size = 3
  pool_size = 2

  model_args = {
    'img_depth': config.getint('image', 'depth'),
    'n_filters': config.getint('unet', 'n filters'),
    'n_layers': config.getint('unet', 'n layers'),
    'kernel_size': conv_kernel_size,
    'pool_size': pool_size,
    'n_classes': 1,  # the other is 1 - ... (because it's a probability distribution)
    'final_activation': config.get('unet', 'final activation'),
    'dropout': config.getfloat('unet', 'dropout'),
    'batchnorm': config.getboolean('unet', 'batchnorm')
  }

  compile_args = {
    'optimizer': config.get('training', 'optimizer'),
    'loss': config.get('training', 'loss'),
    'metrics': ['accuracy', mean_IoU, DSC]
  }

  return model_args, compile_args


def do_experiment(experiment, data, config, out_path):  # todo refactor
  def _fix_data_shape(img_out_shape):
    def _f(x):
      output_shape = (*img_out_shape, config.getint('image', 'depth'))

      transformations = [
        crop_center_transformation(output_shape),
      ]
      x = apply_transformations(x, transformations)  # reduce output size
      x = np.array(x)
      return x

    return _f


  def _prepare_data(data):
    (X_train, X_val, X_test, y_train, y_val, y_test) = data  # unpack

    img_shape = y_train.shape[1: 2 + 1]  # width, height of input images
    img_out_shape = calc_out_size(
      config.getint('unet', 'n layers'),
      2,
      3,
      2,
      experiment['padding']
    )(img_shape)

    y_train = _fix_data_shape(img_out_shape)(y_train)
    y_val = _fix_data_shape(img_out_shape)(y_val)
    y_test = _fix_data_shape(img_out_shape)(y_test)

    return (X_train, X_val, X_test, y_train, y_val, y_test)


  (X_train, X_val, X_test, y_train, y_val, y_test) = _prepare_data(data)

  if config.getint('experiments', 'verbose'):
    describe(X_train, X_val, X_test, y_train, y_val, y_test)

  model_args, compile_args = get_default_args(config)
  args = {
    **model_args,
    'padding': experiment['padding'],
    'use_skip_conn': experiment['use_skip_conn'],
    'use_se_block': experiment['use_se_block']
  }
  model = build_model(**args)
  weights_file = str(get_weights_file(out_path, experiment['name']))

  results = do_training(
    model,
    X_train,
    X_val,
    y_train,
    y_val,
    weights_file,
    config.getint('training', 'batch size'),
    config.getint('training', 'epochs'),
    compile_args,
    config.getint('experiments', 'verbose')
  )

  stats, preds = do_evaluation(
    model,
    weights_file,
    X_test,
    y_test,
    config.getint('training', 'batch size'),
    config.getint('experiments', 'verbose')
  )

  plot_preds(
    X_test,
    y_test,
    preds,
    cmap=config.get('image', 'cmap'),
    title='model: {}'.format(experiment['name']),
    out_folder=get_model_output_folder(out_path, experiment['name'])
  )

  return results, stats


def do_experiments(experiments, data, config, out_path):  # todo refactor
  if config.getint('experiments', 'verbose'):
    print('ready to perform {} experiments'.format(len(experiments)))

  X, y = data  # unpack
  X_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(
    X,
    y,
    config.getfloat('experiments', 'val size'),
    config.getfloat('experiments', 'test size')
  )

  for i, experiment in enumerate(experiments):
    if config.getint('experiments', 'verbose'):
      print('=== experiment # {} / {}: {}'.format(i + 1, len(experiments), experiment['name']))

    data = (X_train, X_val, X_test, y_train, y_val, y_test)
    results, eval_stats = do_experiment(experiment, data, config, out_path)

    experiments[i]['history'] = results.history
    experiments[i]['eval'] = eval_stats

  last_epochs = int(config.getint('training', 'epochs') * 0.8)
  plot_history(experiments, out_path / 'history.png', last=last_epochs)

  return experiments
101/17: do_experiments(experiments, (X, y), config, out_path)
101/18:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file, json_only=True)
101/19:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
101/20:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file, json_only=True)
101/21:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
101/22:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file, json_only=True)
101/23:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/24:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/25:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/26:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/27:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/28:
with open(experiments_file, 'r') as fp:
  experiments = fp.read()  # json.load(fp)
101/29:
with open(experiments_file, 'r') as fp:
  experiments = json.load(fp)  # json.load(fp)
101/30:
with open(experiments_file, 'r') as fp:
  experiments = json.load(fp)  # json.load(fp)
experiments
101/31:
with open(experiments_file, 'r') as fp:
  experiments = ast.literal_eval(json.load(fp))  # json.load(fp)
101/32:
import ast
with open(experiments_file, 'r') as fp:
  experiments = ast.literal_eval(json.load(fp))  # json.load(fp)
101/33:
import ast
with open(experiments_file, 'r') as fp:
  experiments = json.load(fp)  # json.load(fp)
101/34:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/35:
def load_experiments(experiments_file):  # todo refactor (not here)
  with open(experiments_file, 'r') as fp:
    experiments = json.load(fp)

  experiments = ast.literal_eval(experiments)
  return [
    {
      k: np.array(v) if is_lst(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]


experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/36:
def load_experiments(experiments_file):  # todo refactor (not here)
  with open(experiments_file, 'r') as fp:
    experiments = json.load(fp)

  try:
    experiments = ast.literal_eval(experiments)
  except:
    pass

  return [
    {
      k: np.array(v) if is_lst(v) else v
      for k, v in experiment.items()
    }
    for experiment in experiments
  ]


experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/37:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/38:
from attila.util.data import is_lst, is_numpy_array
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/39:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/40:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
101/41:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
101/42:
from pathlib import Path
import numpy as np

from attila.util.config import get_config
from attila.util.plots import plot_preds, plot_history

from attila.data.parse import parse_data, get_data
from attila.data.experiments import load_experiments, save_experiments

from attila.nn.models.unet import calc_out_size, build as build_model
from attila.nn.metrics import mean_IoU, DSC
from attila.nn.core import do_training, do_evaluation

from attila.data.prepare import train_validate_test_split, get_weights_file, get_model_output_folder, describe
from attila.data.trans import crop_center_transformation, apply_transformations

_here = Path('.').resolve()
101/43:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
102/1: import tifffile
103/1: import keras
103/2: import tensorflow
103/3: import sklearn
103/4: import tifffile
103/5: import tifffile
103/6: !which python
103/7: !python --version
103/8: import tifffil1
105/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
105/2: !which python
105/3:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments

_here = Path('.').resolve()
105/4: import keras
105/5: import tensorflow
105/6: import sklearn
105/7: import tifffile
105/8: import numpy
105/9:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
105/10:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
105/11:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
105/12:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
105/13:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
105/14:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
105/15:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
105/16:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
105/17:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
105/18:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
105/19:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
105/20:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
105/21:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
106/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
106/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
106/3: import numpy
107/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
108/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
108/2: import numpy
108/3: import keras
109/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
109/2: import tensorflow
109/3: import keras
111/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
111/2: import keras
112/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
112/2: import keras
112/3: import tifffile
112/4: !pip install tifffile
112/5: import tifffile
112/6: !which python
114/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
114/2: !which python
114/3: import keras
114/4:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
114/5: !which python
115/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
115/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
116/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
116/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
117/1:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
117/2:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
117/3: import keras
117/4:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
118/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
119/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
119/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
120/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
120/2: import matplotlib
120/3:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
121/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
121/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
122/1: !module list
122/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
123/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
123/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
123/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
123/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
123/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
123/6:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
123/7:
do_experiments(experiments, (X, y), config, out_path)
# save_experiments(experiments, out_path / config.get('experiments', 'output file'))
123/8: experiments = do_experiments(experiments, (X, y), config, out_path)
123/9: save_experiments(experiments, out_path / config.get('experiments', 'output file'))
124/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
125/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
125/2:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
125/3:
from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments, save_experiments
from attila.experiments.do import do_experiments
125/4:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
125/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
125/6:
from attila.util.plots import plot_sample

plot_sample(X, y, cmap='magma')
125/7:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
125/8:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
experiments
125/9:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
125/10:
experiments = do_experiments(experiments, (X, y), config, out_path)
save_experiments(experiments, out_path / config.get('experiments', 'output file'))
125/11:
from attila.experiments.tools import create_tex_experiments

create_tex_experiments(experiments, config)
126/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
126/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
127/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
127/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
127/3:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
127/4: !conda intall skimage
127/5: !conda install skimage
127/6: !conda install scikit-image
127/7: !conda install -y scikit-image
128/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
128/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
128/3:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
129/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
129/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
130/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
130/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
131/1: import skimage
131/2:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
131/3:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
131/4:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
131/5:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
131/6:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
131/7:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
131/8:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
131/9: plot_sample(X, y)
131/10: plot_sample(X, y)
131/11:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
131/12: experiments
131/13: do_batch_experiments(experiments, (X, y), config, out_path)
131/14: do_batch_experiments(experiments, (X, y), config, out_path)
131/15: do_batch_experiments(experiments, (X, y), config, out_path)
131/16: do_batch_experiments(experiments, (X, y), config, out_path)
133/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
133/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
133/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
133/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
133/5: plot_sample(X, y)
133/6:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
133/7: do_batch_experiments(experiments, (X, y), config, out_path)
133/8: do_batch_experiments(experiments, (X, y), config, out_path)
133/9: do_batch_experiments(experiments, (X, y), config, out_path)
133/10: do_batch_experiments(experiments, (X, y), config, out_path)
133/11: do_batch_experiments(experiments, (X, y), config, out_path)
133/12: do_batch_experiments(experiments, (X, y), config, out_path)
133/13:
import tensorflow as tf
tf.enable_eager_execution()

do_batch_experiments(experiments, (X, y), config, out_path)
133/14: do_batch_experiments(experiments, (X, y), config, out_path)
133/15: do_batch_experiments(experiments, (X, y), config, out_path)
133/16: import tensorflow as tf
133/17: tf.constant([[1, 2], [5, 6]], dtype=tf.float16)
133/18:
x = tf.constant([[[1, 2], [5, 6]], [[1, 2], [5, 6]]], dtype=tf.float16)
y = tf.constant([[[1, 2], [5, 6]], [[1, 2], [5, 6]]], dtype=tf.float16)
133/19: K.divide(K.sum(x, 1), K.sum(x, 1))
133/20:
import tensorflow as tf
from tensorflow.keras import backend as K
133/21: K.divide(K.sum(x, 1), K.sum(x, 1))
133/22: K.sum(x, 1) / K.sum(x, 1)
133/23: K.sum(x, 1) / K.sum(x, 5)
133/24: K.sum(x, 1) / np.sum(x, 5)
133/25:
import tensorflow as tf
from tensorflow.keras import backend as K
import numpy as np
133/26: K.sum(x, 1) / np.sum(x, 5)
133/27: K.sum(x, y)
133/28: K.sum(x, y)
133/29:
x = tf.constant([[[1, 2], [5, 6]], [[1, 2], [5, 6]]], dtype=tf.float16)
y = tf.constant([[[1, 2], [5, 6]], [[1, 2], [5, 6]]], dtype=tf.float16)
133/30: K.sum(x, y)
133/31:
x = tf.dtypes.cast(x, tf.float32)
y = tf.dtypes.cast(y, tf.float32)
133/32: K.sum(x, y)
133/33: x
133/34: K.prod(x, y)
133/35: K.dot(x, y)
133/36: K.prod(x, y)
133/37:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
133/38:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
133/39:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
133/40:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
133/41: plot_sample(X, y)
133/42:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
133/43: do_batch_experiments(experiments, (X, y), config, out_path)
133/44: do_batch_experiments(experiments, (X, y), config, out_path)
133/45: do_batch_experiments(experiments, (X, y), config, out_path)
133/46: do_batch_experiments(experiments, (X, y), config, out_path)
133/47: do_batch_experiments(experiments, (X, y), config, out_path)
133/48: do_batch_experiments(experiments, (X, y), config, out_path)
133/49: do_batch_experiments(experiments, (X, y), config, out_path)
133/50:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
133/51:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
133/52:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
133/53:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
133/54: plot_sample(X, y)
133/55:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
133/56: do_batch_experiments(experiments, (X, y), config, out_path)
133/57: do_batch_experiments(experiments, (X, y), config, out_path)
133/58: do_batch_experiments(experiments, (X, y), config, out_path)
133/59: do_batch_experiments(experiments, (X, y), config, out_path)
133/60: do_batch_experiments(experiments, (X, y), config, out_path)
133/61: do_batch_experiments(experiments, (X, y), config, out_path)
133/62: do_batch_experiments(experiments, (X, y), config, out_path)
133/63: do_batch_experiments(experiments, (X, y), config, out_path)
133/64: do_batch_experiments(experiments, (X, y), config, out_path)
133/65: do_batch_experiments(experiments, (X, y), config, out_path)
133/66: do_batch_experiments(experiments, (X, y), config, out_path)
133/67: do_batch_experiments(experiments, (X, y), config, out_path)
133/68: do_batch_experiments(experiments, (X, y), config, out_path)
133/69: do_batch_experiments(experiments, (X, y), config, out_path)
133/70: do_batch_experiments(experiments, (X, y), config, out_path)
133/71: do_batch_experiments(experiments, (X, y), config, out_path)
133/72: do_batch_experiments(experiments, (X, y), config, out_path)
133/73: do_batch_experiments(experiments, (X, y), config, out_path)
133/74: do_batch_experiments(experiments, (X, y), config, out_path)
133/75: do_batch_experiments(experiments, (X, y), config, out_path)
133/76: do_batch_experiments(experiments, (X, y), config, out_path)
133/77: do_batch_experiments(experiments, (X, y), config, out_path)
133/78: do_batch_experiments(experiments, (X, y), config, out_path)
133/79: do_batch_experiments(experiments, (X, y), config, out_path)
133/80: do_batch_experiments(experiments, (X, y), config, out_path)
134/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
134/2:
%matplotlib inline

from pathlib import Path

from attila.util.config import get_config
from attila.data.parse import parse_data, get_data
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.util.plots import plot_sample
134/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
134/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
134/5: plot_sample(X, y)
134/6:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
134/7: do_batch_experiments(experiments, (X, y), config, out_path)
134/8: do_batch_experiments(experiments, (X, y), config, out_path)
134/9: do_batch_experiments(experiments, (X, y), config, out_path)
134/10: do_batch_experiments(experiments, (X, y), config, out_path)
134/11: do_batch_experiments(experiments, (X, y), config, out_path)
134/12: experiments
134/13: do_batch_experiments(experiments, (X, y), config, out_path)
134/14: do_batch_experiments(experiments, (X, y), config, out_path)
134/15:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
134/16: experiments
134/17: do_batch_experiments(experiments, (X, y), config, out_path)
134/18: plot_sample(X, y, ix=20)
134/19:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
134/20:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
134/21: plot_sample(X, y)
134/22:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
134/23: do_batch_experiments(experiments, (X, y), config, out_path)
136/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
136/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
136/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
136/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
136/5: plot_sample(X, y)
136/6: plot_sample(X, y)
136/7: plot_sample(X, y)
136/8: plot_sample(X, y)
136/9: plot_sample(X, y)
136/10: plot_sample(X, y, ix=20)
136/11: plot_sample(X, y, ix=20)
136/12: plot_sample(X, y, ix=20)
136/13: plot_sample(X, y, ix=20)
136/14:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
136/15: do_batch_experiments(experiments, (X, y), config, out_path)
136/16: create_tex_experiments(config, out_path)
136/17: do_batch_experiments(experiments, (X, y), config, out_path)
136/18: plot_sample(X, y, ix=20)
136/19: plot_sample(X, y)
136/20: plot_sample(X, y)
136/21: plot_sample(X, y)
136/22: plot_sample(X, y)
136/23: plot_sample(X, y)
136/24: plot_sample(X, y)
136/25: do_batch_experiments(experiments, (X, y), config, out_path)
136/26: do_batch_experiments(experiments, (X, y), config, out_path)
136/27: do_batch_experiments(experiments, (X, y), config, out_path)
136/28: do_batch_experiments(experiments, (X, y), config, out_path)
136/29: do_batch_experiments(experiments, (X, y), config, out_path)
136/30: do_batch_experiments(experiments, (X, y), config, out_path)
136/31: do_batch_experiments(experiments, (X, y), config, out_path)
136/32: plot_sample(X, y)
136/33: plot_sample(X, y)
136/34: plot_sample(X, y)
136/35: do_batch_experiments(experiments, (X, y), config, out_path)
136/36: do_batch_experiments(experiments, (X, y), config, out_path)
136/37: do_batch_experiments(experiments, (X, y), config, out_path)
136/38: do_batch_experiments(experiments, (X, y), config, out_path)
136/39: do_batch_experiments(experiments, (X, y), config, out_path)
136/40: do_batch_experiments(experiments, (X, y), config, out_path)
136/41: plot_sample(X, y, ix=22)
136/42: y[22, ...].shape
136/43: np.sum(y[22, ...], axis=0)
136/44:
import numpy as np

np.sum(y[22, ...], axis=0)
136/45:
import numpy as np

np.sum(y[22, ...], axis=1)
136/46:
import numpy as np

np.sum(y[22, ...], axis=2)
136/47:
import numpy as np

np.sum(y[22, ..., 0])
136/48:
import numpy as np

np.sum(y[22, ..., 1])
136/49:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
136/50:
import numpy as np

np.sum(y[22, ..., 1])
136/51: plot_sample(X, y, ix=22)
136/52: do_batch_experiments(experiments, (X, y), config, out_path)
136/53: plot_sample(X, y, ix=22)
136/54: do_batch_experiments(experiments, (X, y), config, out_path)
136/55: plot_sample(X, y, ix=22)
136/56: plot_sample(X, y)
136/57: do_batch_experiments(experiments, (X, y), config, out_path)
136/58: do_batch_experiments(experiments, (X, y), config, out_path)
136/59: do_batch_experiments(experiments, (X, y), config, out_path)
136/60: do_batch_experiments(experiments, (X, y), config, out_path)
136/61: create_tex_experiments(config, out_path)
138/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
138/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
138/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
138/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
138/5: plot_sample(X, y)
138/6:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
138/7: do_batch_experiments(experiments, (X, y), config, out_path)
138/8: plot_sample(X, y)
138/9: plot_sample(X, y)
138/10: plot_sample(X, y)
138/11: do_batch_experiments(experiments, (X, y), config, out_path)
138/12: do_batch_experiments(experiments, (X, y), config, out_path)
139/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
139/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
139/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
139/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
139/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
139/6: do_batch_experiments(experiments, (X, y), config, out_path)
139/7: do_batch_experiments(experiments, (X, y), config, out_path)
139/8:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
139/9:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
139/10:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
139/11:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
141/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
141/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
141/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
141/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
141/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
141/6: do_batch_experiments(experiments, (X, y), config, out_path)
141/7: do_batch_experiments(experiments, (X, y), config, out_path)
143/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
143/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
143/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
143/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
143/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
143/6: do_batch_experiments(experiments, (X, y), config, out_path)
143/7: do_batch_experiments(experiments, (X, y), config, out_path)
145/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
145/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
145/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
145/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
145/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
145/6: do_batch_experiments(experiments, (X, y), config, out_path)
145/7: do_batch_experiments(experiments, (X, y), config, out_path)
147/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
147/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
147/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
147/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
147/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
147/6: do_batch_experiments(experiments, (X, y), config, out_path)
147/7: do_batch_experiments(experiments, (X, y), config, out_path)
148/1: do_batch_experiments(experiments, (X, y), config, out_path)
148/2: do_batch_experiments(experiments, (X, y), config, out_path)
148/3:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
148/4:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
148/5:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
148/6:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
148/7:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
148/8: do_batch_experiments(experiments, (X, y), config, out_path)
148/9: do_batch_experiments(experiments, (X, y), config, out_path)
149/1: do_batch_experiments(experiments, (X, y), config, out_path)
149/2:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
149/3:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
149/4:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
149/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
149/6:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
149/7: do_batch_experiments(experiments, (X, y), config, out_path)
149/8:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
149/9:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
149/10:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
149/11: do_batch_experiments(experiments, (X, y), config, out_path)
151/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
151/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
151/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
151/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
151/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
151/6: do_batch_experiments(experiments, (X, y), config, out_path)
152/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
152/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
152/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
152/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
152/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
152/6: do_batch_experiments(experiments, (X, y), config, out_path)
152/7:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
152/8: do_batch_experiments(experiments, (X, y), config, out_path)
154/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
154/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
154/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
154/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
154/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
154/6: do_batch_experiments(experiments, (X, y), config, out_path)
155/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
155/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
155/3:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
155/4:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
155/5:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
155/6:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
155/7:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
155/8:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
155/9: do_batch_experiments(experiments, (X, y), config, out_path)
155/10:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
155/11: do_batch_experiments(experiments, (X, y), config, out_path)
157/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
157/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
157/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
157/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
157/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
157/6: do_batch_experiments(experiments, (X, y), config, out_path)
157/7: do_batch_experiments(experiments, (X, y), config, out_path)
158/1: do_batch_experiments(experiments, (X, y), config, out_path)
159/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
159/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
159/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
159/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
159/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
159/6: do_batch_experiments(experiments, (X, y), config, out_path)
159/7:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
159/8:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
159/9:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
159/10: do_batch_experiments(experiments, (X, y), config, out_path)
161/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
161/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
161/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
161/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
161/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
161/6: do_batch_experiments(experiments, (X, y), config, out_path)
162/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
162/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
162/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
162/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
162/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
162/6: do_batch_experiments(experiments, (X, y), config, out_path)
163/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
163/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
163/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
163/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
163/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
163/6: do_batch_experiments(experiments, (X, y), config, out_path)
165/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
165/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
165/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
165/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
165/5:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
165/6: do_batch_experiments(experiments, (X, y), config, out_path)
166/1: do_batch_experiments(experiments, (X, y), config, out_path)
166/2:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
166/3:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
166/4:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
166/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
166/6:
experiments_file = _here / config.get('experiments', 'output file')
experiments = load_experiments(experiments_file)
166/7: do_batch_experiments(experiments, (X, y), config, out_path)
168/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
168/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
168/3:
_here = Path('.').resolve()
config = get_config(_here / './config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
168/4:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
168/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
168/6:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
168/7: do_batch_experiments(experiments, (X, y), config, out_path)
169/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
169/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
169/3:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
169/4:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
169/5:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
169/6:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
169/7:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
169/8:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
169/9: do_batch_experiments(experiments, (X, y), config, out_path)
169/10: create_tex_experiments(config, out_path)
169/11: create_tex_experiments(config, out_path)
170/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
170/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
170/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
170/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
170/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
170/6: do_batch_experiments(experiments, (X, y), config, out_path)
170/7: create_tex_experiments(config, out_path)
170/8:
import numpy as np
from tensorflow.keras import backend as K

from attila.experiments.data import load_experiments
from attila.experiments.do import get_model
from attila.util.config import is_verbose


def create_tex_table_configurations(experiments, config):
    row_table_f = '{} & {} & {} & {} & {} & {} \\\\'

    print('creating .tex table for {} experiments configurations\n'.format(len(experiments)))

    rows = []
    for experiment in experiments:
        model, _ = get_model(experiment, config)

        trainable_params = sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])
        n_layers = len(model.layers)

        row_table = row_table_f.format(
            experiment['name'],
            '\\cmark{}' if experiment['use_skip_conn'] else '\\xmark{}',
            '\\cmark{}' if experiment['use_se_block'] else '\\xmark{}',
            experiment['padding'],
            n_layers,
            trainable_params
        )
        rows.append(row_table)
    return rows


def create_tex_table_results(experiments):
    row_table_f = '{} & {} & {} \\\\'
    metric_keys = ['batch_metric-mean_IoU', 'batch_metric-mean_DSC']

    print('creating .tex table for {} experiments results\n'.format(len(experiments)))

    for experiment in experiments:
        results = experiment['stats']
        for key in metric_keys:  # save for later processing
            experiment[key] = np.mean(results[key])

    best_values = {
        key: np.max([
            experiment[key] for experiment in experiments
        ])
        for key in metric_keys
    }

    out = {}

    rows = []
    for experiment in experiments:
        out[experiment['name']] = {
            key: experiment[key]
            for key in metric_keys
        }

        for key in metric_keys:
            if experiment[key] == best_values[key]:
                experiment[key] = '\\textbf{{{:.3f}}}'.format(experiment[key])
            else:
                delta = 100 - 100 * experiment[key] / best_values[key]
                experiment[key] = '{:.3f} (-{:.1f} \%)'.format(experiment[key], delta)

        row_table = row_table_f.format(
            experiment['name'],
            *(experiment[key] for key in metric_keys)
        )
        rows.append(row_table)

    return rows, out


def create_tex_table_runs_results(runs):
    row_table_f = '{} & {} & {} \\\\'
    metric_keys = list(list(runs[0].values())[0].keys())  # keys of all models
    model_names = list(runs[0].keys())

    print('creating .tex table for {} runs\n'.format(len(runs)))

    out = {
        model: {
            key: np.mean([
                run[model][key]
                for run in runs
            ])  # across all runs
            for key in metric_keys
        }
        for model in model_names
    }

    best_values = {
        key: np.max([
            out[model_name][key]
            for model_name in model_names
        ])  # across all models
        for key in metric_keys
    }

    rows = []
    for model_name, results in out.items():
        for key in metric_keys:
            if results[key] == best_values[key]:
                results[key] = '\\textbf{{{:.3f}}}'.format(results[key])
            else:
                delta = 100 - 100 * results[key] / best_values[key]
                results[key] = '{:.3f} (-{:.1f} \%)'.format(results[key], delta)

        row_table = row_table_f.format(
            model_name,
            *(results[key] for key in metric_keys)
        )
        rows.append(row_table)

    return rows, out


def write2(stuff, out_file):
    with open(out_file, 'w') as w:
        w.write(stuff)


def append2(stuff, out_file):
    with open(out_file, 'a') as w:
        w.write('\n')
        w.write(stuff)


def append_rows2(rows, out_file):
    append2('\n'.join(rows), out_file)


def create_tex_experiments(config, out_folder, out_file=None):
    nruns = config.getint('experiments', 'nruns')
    all_runs = []
    if out_file:
        write2('', out_file)

    for nrun in range(nruns):
        folder = out_folder / 'run-{}'.format(nrun)
        results_file = folder / config.get('experiments', 'output file')
        results = load_experiments(results_file)

        if is_verbose('experiments', config):
            print('run #{}: loaded {} results from {}'.format(nrun + 1, len(results), results_file))

        rows = create_tex_table_configurations(results, config)
        if out_file:
            append_rows2(rows, out_file)
        else:
            print(rows)

        rows, run_results = create_tex_table_results(results)
        if out_file:
            append_rows2(rows, out_file)
        else:
            print(rows)

        all_runs.append(run_results)

    rows, _ = create_tex_table_runs_results(all_runs)
    if out_file:
        append_rows2(rows, out_file)
    else:
        print(rows)
170/9: create_tex_experiments(config, out_path)
170/10:
out_f = out_path / 'tables.tex'
create_tex_experiments(config, out_path, out_f)
170/11:
import numpy as np
from tensorflow.keras import backend as K

from attila.experiments.data import load_experiments
from attila.experiments.do import get_model
from attila.util.config import is_verbose


def create_tex_table_configurations(experiments, config):
    row_table_f = '{} & {} & {} & {} & {} & {} \\\\'

    print('creating .tex table for {} experiments configurations'.format(len(experiments)))

    rows = []
    for experiment in experiments:
        model, _ = get_model(experiment, config)

        trainable_params = sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])
        n_layers = len(model.layers)

        row_table = row_table_f.format(
            experiment['name'],
            '\\cmark{}' if experiment['use_skip_conn'] else '\\xmark{}',
            '\\cmark{}' if experiment['use_se_block'] else '\\xmark{}',
            experiment['padding'],
            n_layers,
            trainable_params
        )
        rows.append(row_table)
    return rows


def create_tex_table_results(experiments):
    row_table_f = '{} & {} & {} \\\\'
    metric_keys = ['batch_metric-mean_IoU', 'batch_metric-mean_DSC']

    print('creating .tex table for {} experiments results'.format(len(experiments)))

    for experiment in experiments:
        results = experiment['stats']
        for key in metric_keys:  # save for later processing
            experiment[key] = np.mean(results[key])

    best_values = {
        key: np.max([
            experiment[key] for experiment in experiments
        ])
        for key in metric_keys
    }

    out = {}

    rows = []
    for experiment in experiments:
        out[experiment['name']] = {
            key: experiment[key]
            for key in metric_keys
        }

        for key in metric_keys:
            if experiment[key] == best_values[key]:
                experiment[key] = '\\textbf{{{:.3f}}}'.format(experiment[key])
            else:
                delta = 100 - 100 * experiment[key] / best_values[key]
                experiment[key] = '{:.3f} (-{:.1f} \%)'.format(experiment[key], delta)

        row_table = row_table_f.format(
            experiment['name'],
            *(experiment[key] for key in metric_keys)
        )
        rows.append(row_table)

    return rows, out


def create_tex_table_runs_results(runs):
    row_table_f = '{} & {} & {} \\\\'
    metric_keys = list(list(runs[0].values())[0].keys())  # keys of all models
    model_names = list(runs[0].keys())

    print('creating .tex table for {} runs'.format(len(runs)))

    out = {
        model: {
            key: np.mean([
                run[model][key]
                for run in runs
            ])  # across all runs
            for key in metric_keys
        }
        for model in model_names
    }

    best_values = {
        key: np.max([
            out[model_name][key]
            for model_name in model_names
        ])  # across all models
        for key in metric_keys
    }

    rows = []
    for model_name, results in out.items():
        for key in metric_keys:
            if results[key] == best_values[key]:
                results[key] = '\\textbf{{{:.3f}}}'.format(results[key])
            else:
                delta = 100 - 100 * results[key] / best_values[key]
                results[key] = '{:.3f} (-{:.1f} \%)'.format(results[key], delta)

        row_table = row_table_f.format(
            model_name,
            *(results[key] for key in metric_keys)
        )
        rows.append(row_table)

    return rows, out


def write2(stuff, out_file):
    with open(out_file, 'w') as w:
        w.write(stuff)


def append2(stuff, out_file):
    with open(out_file, 'a') as w:
        w.write('\n')
        w.write(stuff)


def append_rows2(rows, out_file):
    append2('\n'.join(rows), out_file)


def create_tex_experiments(config, out_folder, out_file=None):
    nruns = config.getint('experiments', 'nruns')
    all_runs = []
    if out_file:
        write2('', out_file)

    for nrun in range(nruns):
        folder = out_folder / 'run-{}'.format(nrun)
        results_file = folder / config.get('experiments', 'output file')
        results = load_experiments(results_file)

        if is_verbose('experiments', config):
            print('=== run #{}: loaded {} results from {}'.format(nrun + 1, len(results), results_file))

        rows = create_tex_table_configurations(results, config)
        if out_file:
            append_rows2(rows, out_file)
        else:
            print(rows)

        rows, run_results = create_tex_table_results(results)
        if out_file:
            append_rows2(rows, out_file)
        else:
            print(rows)

        all_runs.append(run_results)

    rows, _ = create_tex_table_runs_results(all_runs)
    if out_file:
        append_rows2(rows, out_file)
    else:
        print(rows)
170/12:
out_f = out_path / 'tables.tex'
create_tex_experiments(config, out_path, out_f)
170/13:
def append_rows2(rows, out_file):
    stuff = '\n'.join(rows)
    stuff = '\n' + stuff + '\n'
    append2(stuff, out_file)
170/14:
out_f = out_path / 'tables.tex'
create_tex_experiments(config, out_path, out_f)
171/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
171/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
171/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
171/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
171/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
171/6: do_batch_experiments(experiments, (X, y), config, out_path)
172/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
172/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
172/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
172/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
172/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
172/6: do_batch_experiments(experiments, (X, y), config, out_path)
172/7: do_batch_experiments(experiments, (X, y), config, out_path)
173/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
173/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
173/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
173/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
173/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
173/6: do_batch_experiments(experiments, (X, y), config, out_path)
174/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
174/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
174/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
174/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
174/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
174/6: do_batch_experiments(experiments, (X, y), config, out_path)
175/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
175/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
175/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
175/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
175/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
175/6: do_batch_experiments(experiments, (X, y), config, out_path)
176/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
176/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
176/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
176/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
176/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
176/6: do_batch_experiments(experiments, (X, y), config, out_path)
178/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
178/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
178/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
178/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
178/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
178/6: do_batch_experiments(experiments, (X, y), config, out_path)
179/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
179/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
179/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
179/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
179/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
179/6: do_batch_experiments(experiments, (X, y), config, out_path)
179/7: do_batch_experiments(experiments, (X, y), config, out_path)
179/8: do_batch_experiments(experiments, (X, y), config, out_path)
180/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
180/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
180/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
180/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
180/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
180/6: do_batch_experiments(experiments, (X, y), config, out_path)
181/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
181/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
181/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
181/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
181/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
181/6: do_batch_experiments(experiments, (X, y), config, out_path)
181/7: do_batch_experiments(experiments, (X, y), config, out_path)
181/8: create_tex_experiments(config, out_path, out_path / 'tables.tex')
181/9: do_batch_experiments(experiments, (X, y), config, out_path)
181/10: do_batch_experiments(experiments, (X, y), config, out_path)
181/11: create_tex_experiments(config, out_path, out_path / 'tables.tex')
182/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
182/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
182/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
182/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
182/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
182/6: do_batch_experiments(experiments, (X, y), config, out_path)
183/6: do_batch_experiments(experiments, (X, y), config, out_path)
185/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
185/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
185/3:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
185/4:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
185/5:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
185/6:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
185/7:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
185/8: do_batch_experiments(experiments, (X, y), config, out_path)
185/9: do_batch_experiments(experiments, (X, y), config, out_path)
187/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
187/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
187/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
187/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
187/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
187/6: do_batch_experiments(experiments, (X, y), config, out_path)
187/7: do_batch_experiments(experiments, (X, y), config, out_path)
189/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
189/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
189/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
189/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
189/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
189/6: do_batch_experiments(experiments, (X, y), config, out_path)
189/7: do_batch_experiments(experiments, (X, y), config, out_path)
191/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
191/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
191/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
191/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
191/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
191/6: do_batch_experiments(experiments, (X, y), config, out_path)
191/7: do_batch_experiments(experiments, (X, y), config, out_path)
193/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
193/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
193/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
193/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
193/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
193/6: do_batch_experiments(experiments, (X, y), config, out_path)
194/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
194/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
194/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
194/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
194/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
194/6: do_batch_experiments(experiments, (X, y), config, out_path)
195/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
195/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
195/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
195/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
195/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
195/6: do_batch_experiments(experiments, (X, y), config, out_path)
195/7: do_batch_experiments(experiments, (X, y), config, out_path)
197/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
197/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
197/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
197/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
197/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
197/6: do_batch_experiments(experiments, (X, y), config, out_path)
198/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
198/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
198/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
198/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
198/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
198/6: do_batch_experiments(experiments, (X, y), config, out_path)
199/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
199/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
199/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
199/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
199/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
199/6: do_batch_experiments(experiments, (X, y), config, out_path)
201/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
201/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
201/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
201/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
201/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
201/6: do_batch_experiments(experiments, (X, y), config, out_path)
201/7: do_batch_experiments(experiments, (X, y), config, out_path)
203/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
203/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
203/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
203/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
203/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
203/6: do_batch_experiments(experiments, (X, y), config, out_path)
203/7: do_batch_experiments(experiments, (X, y), config, out_path)
204/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
204/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
205/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
205/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
205/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
205/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
205/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
205/6: do_batch_experiments(experiments, (X, y), config, out_path)
205/7:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
205/8: do_batch_experiments(experiments, (X, y), config, out_path)
207/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
207/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
207/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
207/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
207/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
207/6: do_batch_experiments(experiments, (X, y), config, out_path)
208/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
208/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
208/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
208/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
208/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
208/6: do_batch_experiments(experiments, (X, y), config, out_path)
210/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
210/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
210/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
210/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
210/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
210/6: do_batch_experiments(experiments, (X, y), config, out_path)
212/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
212/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
212/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
212/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
212/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
212/6: do_batch_experiments(experiments, (X, y), config, out_path)
214/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
214/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
215/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
215/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.util.config import get_config
from attila.util.plots import plot_sample
from attila.experiments.data import load_experiments
from attila.experiments.do import do_batch_experiments
from attila.experiments.tools import create_tex_experiments
215/3:
_here = Path('.').resolve()
config = get_config(_here / 'config.ini')

data_path = _here / config.get('data', 'folder')
data_path = data_path.resolve()

out_path = Path(config.get('experiments', 'output folder')).resolve()
out_path.mkdir(parents=True, exist_ok=True)

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
215/4:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
215/5:
experiments_file = _here / 'experiments.json'
experiments = load_experiments(experiments_file)
215/6: do_batch_experiments(experiments, (X, y), config, out_path)
216/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
216/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
217/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
217/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
217/3:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
217/4: _here = Path('.').resolve()
217/5:
config, data_path, out_path, models_config = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
217/6:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
217/7:
models_config = load_json(models_config)
do_batch_experiments(models_config, (X, y), config, out_path)
217/8:
models_config = load_json(models_config)
do_batch_experiments(models_config, (X, y), config, out_path)
217/9:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
217/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
217/11:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
217/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
217/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
217/14:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
217/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
219/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
219/3:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
219/4: _here = Path('.').resolve()
219/5:
config, data_path, out_path, models_config = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
219/6:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
219/7:
models_config = load_json(models_config)
do_batch_experiments(models_config, (X, y), config, out_path)
219/8:
models_config = load_json(models_config)
do_batch_experiments(models_config, (X, y), config, out_path)
219/9:
# config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
219/10:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
219/11:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/14:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/16:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/17:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
219/18:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
221/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
221/3: _here = Path('.').resolve()
221/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
221/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
221/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/8:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/9:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/11:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/14:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
221/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/16:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
221/17:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/18:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
221/19:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/20:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
221/21:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
221/22:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
222/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
222/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
222/3: _here = Path('.').resolve()
222/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
222/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
222/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
222/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
222/8:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
222/9:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
222/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
223/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
223/3: _here = Path('.').resolve()
223/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
223/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
223/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/7:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
223/8:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
223/9:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/10:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
223/11:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
223/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/13:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
223/14:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
223/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/16:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
223/17:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
223/18:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/19:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
223/20:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
223/21:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
223/22:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
225/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
225/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
225/3: _here = Path('.').resolve()
225/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
225/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
225/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
225/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
225/8:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
225/9:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
225/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
225/11:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
225/12:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
225/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
225/14:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
225/15:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
225/16:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
225/17:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
226/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
226/3: _here = Path('.').resolve()
226/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
226/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
226/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/7:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
226/8: y.shape
226/9:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
226/10:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
226/11:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
226/12: y.shape
226/13:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
226/14: y.shape
226/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/16:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/17:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/18:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/19:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/20:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
226/21:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/22:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/23:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/24:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
226/25:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/26:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/27:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
226/28:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/29:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/30:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
226/31:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/32:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/33:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/34:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/35:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/36:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
226/37:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
y.shape
226/38:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
227/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
227/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
227/3: _here = Path('.').resolve()
227/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
227/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
227/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
227/7:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
227/8:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
227/9:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
227/10: config
227/11: config.get('training', 'loss')
227/12:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
227/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
228/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
228/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
228/3: _here = Path('.').resolve()
228/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
228/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
228/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
229/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
229/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
229/3: _here = Path('.').resolve()
229/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
229/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
229/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
229/7:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
229/8:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
229/9:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
229/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
229/11:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
230/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
230/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
230/3: _here = Path('.').resolve()
230/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
230/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
230/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
230/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
230/8:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
230/9:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
230/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
231/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
231/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
231/3: _here = Path('.').resolve()
231/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
231/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
231/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
231/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
231/8:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
232/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
232/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
232/3: _here = Path('.').resolve()
232/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
232/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
232/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
233/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
233/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
233/3: _here = Path('.').resolve()
233/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
233/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
233/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
233/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
234/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
234/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
234/3: _here = Path('.').resolve()
234/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
234/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
234/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
234/7:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
234/8:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
234/9:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
234/10:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
234/11:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
234/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
234/13:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
234/14:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
234/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
234/16:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
235/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
235/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
235/3: _here = Path('.').resolve()
235/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
235/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
235/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
235/7:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
235/8:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
235/9:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
235/10:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
235/11:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
235/12:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
235/13:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
235/14:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
236/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
236/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
236/3: _here = Path('.').resolve()
236/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
236/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
236/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
236/7:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
236/8:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
237/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
237/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
237/3: _here = Path('.').resolve()
237/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
237/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
237/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
237/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
237/8:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
237/9:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
237/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
238/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
238/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
238/3: _here = Path('.').resolve()
238/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
238/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
238/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
239/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
239/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
from attila.util.config import get_env
from attila.util.io import load_json
239/3: _here = Path('.').resolve()
239/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
239/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
239/6:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
239/7:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
239/8: !conda install livelossplot
239/9: import livelossplot
239/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
243/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
243/2:
%matplotlib inline

from pathlib import Path

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json
from attila.util.plots import extract_preds
243/3: _here = Path('.').resolve()
243/4:
config, data_path, out_path, models_config_path = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
243/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
243/6:
model_config = {
  "use_skip_conn":true,
  "padding":"same",
  "use_se_block":false,
  "name":"with_same"
}
243/7:
model_config = {
  "use_skip_conn": True,
  "padding":"same",
  "use_se_block": False,
  "name":"with_same"
}
243/8: config.set('training', 'epochs', 42)
243/9: config.setint('training', 'epochs', 42)
243/10: config.set('training', 'epochs', '42')
243/11: config.getint('training', 'epochs')
243/12:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)
config.set('experiments', 'val size', '0.08')  # not very necessary to validate

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
243/13:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json
from attila.util.plots import extract_preds
243/14:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)
config.set('experiments', 'val size', '0.08')  # not very necessary to validate

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
243/15: len(X_train)
243/16: len(X_train) * 0.02
243/17: len(X_train) * 0.2
243/18:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json
from attila.util.plots import extract_preds
243/19:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)
config.set('experiments', 'val size', '0.8')  # not very necessary to validate

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('testing data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 5
plot_ids = np.random.randint(len(X_test), size=num_plots)
243/20: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/21:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('training', 'epochs', '20')  # or any other small amount
243/22: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/23:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)
config.set('experiments', 'val size', '0.8')  # not very necessary to validate

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 5
plot_ids = np.random.randint(len(X_test), size=num_plots)
243/24: config.getfloat('experiments', 'val size')
243/25: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/26: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/27:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)
config.set('experiments', 'val size', '0.1')  # not very necessary to validate

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 5
plot_ids = np.random.randint(len(X_test), size=num_plots)
243/28: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/29:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)
config.set('experiments', 'val size', '0.0')  # not very necessary to validate

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 5
plot_ids = np.random.randint(len(X_test), size=num_plots)
243/30:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.0')  # not very necessary to validate
config.set('training', 'batch size', 2)
config.set('training', 'epochs', '20')  # or any other small amount
243/31:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.0')  # not very necessary to validate
config.set('training', 'batch size', '2')
config.set('training', 'epochs', '20')  # or any other small amount
243/32: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/33:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.01')  # not very necessary to validate
config.set('training', 'batch size', '2')
config.set('training', 'epochs', '20')  # or any other small amount
243/34: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/35:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')
config.set('training', 'epochs', '20')  # or any other small amount
243/36: summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)
243/37:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
243/38:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')
config.set('training', 'epochs', '20')  # or any other small amount
243/39:
summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/40:
config.set('data', 'aug', True)

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/41:
config.set('data', 'aug', 'True')
config.getboolean('data', 'aug')
243/42:
config.set('data', 'aug', 'False')
config.getboolean('data', 'aug')
243/43:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/44:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/45:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/46:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/47:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/48:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/49:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/50:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.6')  # not very necessary to validate
config.set('training', 'batch size', '2')
config.set('training', 'epochs', '2')  # or any other small amount
243/51:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/52:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/53:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/54:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.6')  # not very necessary to validate
config.set('training', 'batch size', '2')
config.set('training', 'epochs', '1')  # or any other small amount
243/55:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/56:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'out' / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/57: summary
243/58: summary['stats']
243/59: summary['stats']['attila_metrics_mean_IoU']
243/60: len(summary['stats']['attila_metrics_mean_IoU'])
243/61:
config.set('experiments', 'test size', '0.95')  # or any other big amount (< 1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 5
plot_ids = np.random.randint(len(X_test), size=num_plots)
243/62:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '10')
config.set('training', 'epochs', '1')  # or any other small amount
243/63:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '10')
config.set('training', 'epochs', '20')  # or any other small amount
243/64:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '1')
config.set('training', 'epochs', '20')  # or any other small amount
243/65:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '1')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
243/66:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/67:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
243/68:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
243/69:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
244/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
244/2:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
244/3: _here = Path('.').resolve()
244/4:
config, data_path, out_path, _ = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
244/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
244/6:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))
245/1:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
247/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
247/2:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
247/3: _here = Path('.').resolve()
247/4:
config, data_path, out_path, _ = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
247/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
247/6:
config.set('experiments', 'test size', '0.95')  # or any other big amount (< 1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 4
plot_ids = np.random.randint(len(X_test), size=num_plots)
247/7:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
247/8:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
247/9:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trails' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
248/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
248/2:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
249/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
249/2:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
249/3:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
249/4:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
249/5: from attila.patch.layers import CenterCrop
249/6: _here = Path('.').resolve()
249/7:
config, data_path, out_path, _ = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
249/8:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
249/9:
config.set('experiments', 'test size', '0.95')  # or any other big amount (< 1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 4
plot_ids = np.random.randint(len(X_test), size=num_plots)
249/10:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
249/11:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/12:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
249/13:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle
from attila.util.plots import extract_preds
249/14: _here = Path('.').resolve()
249/15:
config, data_path, out_path, _ = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
249/16:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
249/17:
config.set('experiments', 'test size', '0.95')  # or any other big amount (< 1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 4
plot_ids = np.random.randint(len(X_test), size=num_plots)
249/18:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
249/19:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/20:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/21:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/22:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/23:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/24:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/25:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/26:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/27:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/28:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/29:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/30:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/31:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)
  plot_history(
    summary['history'],
    out_folder=folder
  )
  print('history img saved in {}'.format(model_folder))
249/32:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/33:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/34:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/35:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)
  plot_history(
    summary['history'],
    out_folder=folder
  )
  print('history img saved in {}'.format(model_folder))
249/36:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle, dirs
from attila.util.plots import extract_preds
249/37:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)
  plot_history(
    summary['history'],
    out_folder=folder
  )
  print('history img saved in {}'.format(model_folder))
249/38:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle, dirs, get_summary
from attila.util.plots import extract_preds
249/39:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)
  plot_history(
    summary['history'],
    out_folder=folder
  )
  print('history img saved in {}'.format(model_folder))
249/40:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle, dirs, get_summary
from attila.util.plots import extract_preds, plot_history
249/41:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)
  plot_history(
    summary['history'],
    last=0,
    out_folder=folder,
  )
  print('history img saved in {}'.format(model_folder))
249/42:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)
  plot_history(
    summary['history'],
    last=0,
    out_folder=folder,
  )
  print('history img saved in {}'.format(folder))
249/43:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)

  plot_history(
    summary['history'],
    last=0,
    out_folder=folder,
  )
  print('history img saved in {}'.format(folder))
  
  plot_preds(
    summary['preds'],
    config.get('image', 'cmap'),
    folder
  )
249/44:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle, dirs, get_summary
from attila.util.plots import extract_preds, plot_history, plot_preds
249/45:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)

  plot_history(
    summary['history'],
    last=0,
    out_folder=folder,
  )
  print('history img saved in {}'.format(folder))
  
  plot_preds(
    summary['preds'],
    config.get('image', 'cmap'),
    folder
  )
249/46:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/47:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle, dirs, get_summary
from attila.util.plots import extract_preds, plot_history, plot_preds
249/48:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/49:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/50:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/51:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/52:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/53:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/54:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/55:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/56:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/57:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/58:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
249/59:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
250/2:
%matplotlib inline

from pathlib import Path
from sklearn.model_selection import train_test_split
import numpy as np

from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments, do_experiment
from attila.util.config import get_env
from attila.util.io import load_json, stuff2pickle, dirs, get_summary
from attila.util.plots import extract_preds, plot_history, plot_preds
250/3: _here = Path('.').resolve()
250/4:
config, data_path, out_path, _ = get_env(_here)
out_path.mkdir(parents=True, exist_ok=True)  # rm and mkdir if existing

images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')
250/5:
raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
250/6:
config.set('experiments', 'test size', '0.95')  # or any other big amount (< 1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 4
plot_ids = np.random.randint(len(X_test), size=num_plots)
250/7:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.5')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
250/8:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/9:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/10: import cv2
250/11:
config.set('experiments', 'test size', '0.9')  # or any other big amount (< 1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=config.getfloat('experiments', 'test size'),
    random_state=42  # reproducible results
)
print('train/val data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))

num_plots = 4
plot_ids = np.random.randint(len(X_test), size=num_plots)
250/12:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.3')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '20')  # or any other small amount
250/13:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/14:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/15:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/16:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/17:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/18:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/19:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/20:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/21:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/22:
experiment = {
  "use_skip_conn": True,
  "padding": "same",
  "use_se_block": False,
  "name": "with_same"
}

config.set('experiments', 'val size', '0.3')  # not very necessary to validate
config.set('training', 'batch size', '2')  # very mini-batch size
config.set('training', 'epochs', '50')  # or any other small amount
250/23:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/24:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/25:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/26:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/27:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/28:
config.set('data', 'aug', 'False')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'no-aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/29:
config.set('data', 'aug', 'True')

summary = do_experiment(experiment, (X_train, X_test, y_train, y_test), 0, config, plot_ids)

out_folder = out_path / 'trials' / 'to-aug-or-not' / 'aug'
out_folder.mkdir(parents=True, exist_ok=True)
out_f = out_folder / config.get('experiments', 'output file')
stuff2pickle(summary, out_f)
250/30:
for folder in dirs(out_path / 'trials' / 'to-aug-or-not'):
  summary = get_summary(folder, config)

  plot_history(
    summary['history'],
    last=0,
    out_folder=folder,
  )
  print('history img saved in {}'.format(folder))
  
  plot_preds(
    summary['preds'],
    config.get('image', 'cmap'),
    folder
  )
251/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
251/2:
%matplotlib inline

from pathlib import Path
251/3:
from attila.util.config import get_env
from attila.util.plots import plot_history, plot_preds
from attila.util.io import load_pickle, append_rows2text, load_json, get_summary, dirs
from attila.experiments.tools import experiment2tex, runs2tex
251/4: _here = Path('.').resolve()
251/5: config, data_path, out_path, models_config_path = get_env(_here)
251/6: from attila.data.parse import parse_data, get_data
251/7: from attila.data.parse import parse_data, get_data
251/8:
images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')

raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
251/9:
config.set('training', 'batch size', '4')
config.set('training', 'epochs', '10')
config.set('data', 'aug', 'False')
251/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/11:
from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
251/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/14:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/16:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/17:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/18:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/19:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/20:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/21:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/22:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/23:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
251/24:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
252/2:
%matplotlib inline

from pathlib import Path
252/3:
from attila.util.config import get_env
from attila.util.plots import plot_history, plot_preds
from attila.util.io import load_pickle, append_rows2text, load_json, get_summary, dirs
from attila.experiments.tools import experiment2tex, runs2tex
252/4: _here = Path('.').resolve()
252/5: config, data_path, out_path, models_config_path = get_env(_here)
252/6:
from attila.data.parse import parse_data, get_data
from attila.experiments.do import do_batch_experiments
252/7:
images_path = data_path / config.get('data', 'images')
masks_path = data_path / config.get('data', 'masks')

raw = get_data(images_path, masks_path)
X, y = parse_data(
    raw,
    (config.getint('image', 'width'), config.getint('image', 'height'))
)
252/8:
config.set('training', 'batch size', '4')
config.set('training', 'epochs', '10')
config.set('data', 'aug', 'False')
252/9:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/10:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/11:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/12:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/13:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/14:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
252/15:
models_config = load_json(models_config_path)
do_batch_experiments(models_config, (X, y), config, out_path)
253/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
253/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
254/1: import torch
254/2: import numpy
255/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
255/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
256/1: import torch
256/2: import numpy
257/1:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
257/2: !pip install matplotlib
257/3:
from mingpt.utils import set_seed

set_seed(42)  # make deterministic
257/4:
import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)
257/5:

from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
257/6: !pip install scikit-learn
257/7:

from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
258/1: import sklearn
258/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
258/3:
da-2019b-Python-3.7.4 and 2 dependencies loaded.
(.venv) bash-4.2$ module load
258/4:
from mingpt.utils import set_seed

set_seed(42)  # make deterministic
258/5:
import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)
258/6:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
258/7:
dataset = load_pickle('../minGPT_data.pkl')  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
258/8: ls
258/9: pwd
258/10:
dataset = load_pickle(Path('~/scratch/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
258/11:
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
258/12:
from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
258/13:
# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless

# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()
258/14:
# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)
        
        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])
        
        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()
        
        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters
    
    return c

  
ncluster = 64
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
258/15:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 16
n_cols = 8
n_rows = n_samples // ncol
fig, axis = plt.subplots(n_rows, n_cols, figsize=(30, 10))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    ax.imshow(C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8))
    
# images look good, so now every image is a 1024-long sequence of numbers between 0..63. Time to train a GPT.
258/16:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 16
n_cols = 8
n_rows = n_samples // ncols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(30, 10))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    ax.imshow(C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8))
    
# images look good, so now every image is a 1024-long sequence of numbers between 0..63. Time to train a GPT.
258/17:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 16
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(30, 10))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    ax.imshow(C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8))
    
# images look good, so now every image is a 1024-long sequence of numbers between 0..63. Time to train a GPT.
258/18: C
258/19: t_train_dataset
258/20:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
258/21:
from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=8  # 256
)
model = GPT(mconf)
258/22:
from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_data) * train_dataset.block_size
train_epochs = 20 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=16*8, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
258/23: !pip install tqdm
258/24:
from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_data) * train_dataset.block_size
train_epochs = 20 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=16*8, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
258/25:
from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=16*8, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
258/26:
from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=2, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
258/27:
checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
258/28:
counts = torch.ones(ncluster) # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = 5000 # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item() # index of first token in the sequence
    counts[t] += 1
prob = counts/counts.sum()
258/29:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token
counts = torch.ones(ncluster) # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = 100 # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item() # index of first token in the sequence
    counts[t] += 1
prob = counts/counts.sum()
258/30: prob
258/31:
%%time

from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob)
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=100)
258/32:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token
counts = torch.ones(ncluster) # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = 1007 # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item() # index of first token in the sequence
    counts[t] += 1
prob = counts/counts.sum()
258/33: np.sum(prob)
258/34: prob
258/35: prob.sum()
258/36:
%%time

from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob)
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=100)
258/37: prob
258/38: prob.sum()
258/39:
ff = np.array([0.0121, 0.0009, 0.0037, 0.0037, 0.0009, 0.0047, 0.0093, 0.0009, 0.0028,
        0.0028, 0.0009, 0.0019, 0.0047, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,
        0.0140, 0.0047, 0.0168, 0.0065, 0.0009, 0.0056, 0.0028, 0.0093, 0.0028,
        0.0075, 0.0009, 0.0009, 0.0159, 0.0140, 0.0065, 0.0056, 0.0056, 0.0009,
        0.0084, 0.0028, 0.0009, 0.0047, 0.0056, 0.0093, 0.0065, 0.0009, 0.0065,
        0.0084, 0.0252, 0.0224, 0.0187, 0.0551, 0.0383, 0.0364, 0.0299, 0.0728,
        0.0812, 0.0812, 0.0289, 0.0345, 0.0075, 0.0430, 0.0579, 0.0663, 0.0672,
        0.0037])
258/40: ff.sum()
258/41: ff / ff.sum()
258/42: (ff / ff.sum()).sum()
258/43: prob
258/44: prob.numpy()
258/45: prob.numpy().sum()
258/46:
%%time

from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=100)
258/47:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=10)
258/48:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
nrow = n_samples // n_cols
plt.figure(figsize=(16, 8))
for i in range(n_samples):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    
    plt.subplot(nrow, ncol, i+1)
    plt.imshow(C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8))
    plt.axis('off')
258/49:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
nrow = n_samples // n_cols
plt.figure(figsize=(16, 8))
for i in range(n_samples):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    
    plt.subplot(nrow, n_cols, i+1)
    plt.imshow(C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8))
    plt.axis('off')
258/50:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
nrow = n_samples // n_cols
plt.figure(figsize=(16, 8))
for i in range(n_samples):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    
    plt.subplot(nrow, n_cols, i+1)
    plt.imshow(C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)[..., 0])
    plt.axis('off')
258/51: plt.savefig('wow.png')
258/52:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = 1000  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
258/53:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=100)
258/54:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=90)
258/55:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=80)
258/56:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=50)
258/57:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=60)
258/58:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
nrow = n_samples // n_cols
plt.figure(figsize=(16, 8))
for i in range(n_samples):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    
    plt.subplot(nrow, n_cols, i+1)
    plt.imshow(C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)[..., 0])
    plt.axis('off')
258/59: plt.savefig('samples.png')
258/60:
# visualize some of the learned positional embeddings, maybe they contain structure

plt.figure(figsize=(5, 5))
nsee = 8*8
n_cols = 8
nrow = nsee // n_cols
for i in range(nsee):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    
    plt.subplot(nrow, ncol, i+1)
    plt.imshow(rzci.view(32, 32).numpy())
    plt.axis('off')
258/61:
# visualize some of the learned positional embeddings, maybe they contain structure

plt.figure(figsize=(5, 5))
nsee = 8*8
n_cols = 8
nrow = nsee // n_cols
for i in range(nsee):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    
    plt.subplot(nrow, n_cols, i+1)
    plt.imshow(rzci.view(32, 32).numpy())
    plt.axis('off')
258/62:
# visualize some of the learned positional embeddings, maybe they contain structure

plt.figure(figsize=(5, 5))
nsee = 4 * 4
n_cols = 8
nrow = nsee // n_cols
for i in range(nsee):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    
    plt.subplot(nrow, n_cols, i+1)
    plt.imshow(rzci.view(32, 32).numpy())
    plt.axis('off')
258/63:
# visualize some of the learned positional embeddings, maybe they contain structure

plt.figure(figsize=(5, 5))
nsee = 2 * 4
n_cols = 8
nrow = nsee // n_cols
for i in range(nsee):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    
    plt.subplot(nrow, n_cols, i+1)
    plt.imshow(rzci.view(32, 32).numpy())
    plt.axis('off')
258/64: plt.savefig('learned_positional_embeddings.png')
259/1:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
259/2:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)
259/3:
from mingpt.utils import set_seed

set_seed(42)  # make deterministic
259/4:
import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


# In[72]:


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


# In[73]:


dataset = load_pickle(Path('~/scratch/attila/results/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
259/5:
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


# In[74]:


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
259/6:
def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)
        
        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])
        
        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()
        
        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters
    
    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
259/7:
n_samples = 16
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(64, 16))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    ax.imshow(C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8), cmap='magma')
    ax.axis('off')
    
plt.savefig('clustered.png')
259/8:
n_samples = 16
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(64, 16))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')
    
plt.savefig('clustered.png')
259/9:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


# In[81]:


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


# In[10]:


from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
259/10:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


# In[81]:


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


# In[10]:


from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 60 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-4,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
259/11:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


# In[81]:


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


# In[10]:


from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 60 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=8, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
259/12:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


# In[81]:


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


# In[10]:


from mingpt.trainer import Trainer, TrainerConfig

"""
Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.
If you don't have as many computational resources you have to bring down
the batch_size until the model fits into your memory, and then you may
also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,
you can use an even smaller model up above, bringing down the number of layers,
number of heads, and the embedding size.
"""

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = 'best_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=8, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
259/13:
checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
259/14:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
259/15:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=50)
259/16:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=10)
259/17:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=1)
259/18:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)
259/19:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)
259/20:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    
    ax.imshow(sample[..., 0])  # grayscale -> 2D
    ax.axis('off')

plt.savefig('samples.png')
259/21:
# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd)
    ax.axis('off')


plt.savefig('pos_embd.png')
259/22:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    
    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('samples.png')
259/23:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')
    
plt.savefig('clustered.png')
259/24:

def stuff2pickle(stuff, f_path):
    with open(f_path, 'wb') as fp:
        pickle.dump(stuff, fp)
260/1:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
260/2:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)
260/3:
from mingpt.utils import set_seed

set_seed(42)  # make deterministic
260/4:
import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)
260/5:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
260/6:
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
260/7:
from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
260/8:
# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)
        
        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])
        
        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()
        
        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters
    
    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
260/9: !mkdir results
260/10:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')
    
plt.savefig('results/clustered.png')
260/11:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
260/12:
from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,  # number of head self-attention
    n_embd=256  # d-dimensional embedding for each pixel
)
model = GPT(mconf)
260/13:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
260/14:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
260/15:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
260/16:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU
260/17:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    
    ax.imshow(sample[..., 0])  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')
260/18:
# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd)
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/1:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
261/2:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)
261/3:
import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)
261/4:
from mingpt.utils import set_seed

set_seed(42)  # make deterministic
261/5:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
261/6:
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
261/7:
from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
261/8:
# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)
        
        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])
        
        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()
        
        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters
    
    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
261/9:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')
    
plt.savefig('results/clustered.png')
261/10:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm
        
        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
261/11:
from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,  # number of head self-attention
    n_embd=256  # d-dimensional embedding for each pixel
)
model = GPT(mconf)
261/12:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 3 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
# trainer.train()  # WARNING: this blows CPU
261/13:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 3 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
# trainer.train()  # WARNING: this blows CPU
261/14:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 3 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)trainer.train()  # WARNING: this blows CPU
261/15:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 3 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas = (0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
261/16:
checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=50)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0])  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')
261/17:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0])  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')
261/18:
n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    print(i, embd.shape)
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/19:
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()
    print(i, embd.shape)

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/20:
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()
    print(i, ci.shape, zci.shape, rzci.shape, embd.shape)

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/21:
train_epochs = 50

# initialize a trainer instance and kick off training
checkpoint_path = 'resuts//latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()
    print(i, ci.shape, zci.shape, rzci.shape, embd.shape)

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/22:
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    # embd = rzci.view(pixel_size, pixel_size).numpy()
    embd = rzci.view(256, 4).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/23:
train_epochs = 50

# initialize a trainer instance and kick off training
checkpoint_path = 'resuts/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    # embd = rzci.view(pixel_size, pixel_size).numpy()
    embd = rzci.view(256, 4).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/24:
train_epochs = 50

# initialize a trainer instance and kick off training
checkpoint_path = 'resuts/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/25:
train_epochs = 50

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
261/26:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
261/27:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
261/28:
from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU
261/29:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    
    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')
261/30: model.pos_emb.data.shape()
261/31: model.pos_emb.data
261/32: model.pos_emb.data.cpu()
261/33: model.pos_emb.data.cpu().shape()
261/34: model.pos_emb.data.cpu().numpy()
261/35: model.pos_emb.data.cpu().numpy().shape()
261/36: len(model.pos_emb.data.cpu().numpy())
261/37: model.pos_emb.data.cpu().numpy()[0]
261/38: model.pos_emb.data.cpu().numpy()[0].shape
261/39: model.pos_emb.data.shape
261/40: model.pos_emb.data[0].numpy()
261/41: model.pos_emb.data[0].cpu().numpy()
261/42: model.pos_emb.data[0].cpu().numpy().shape
261/43: plt.imshow(model.pos_emb.data[0].cpu().numpy(), cmap='jet')
261/44: plt.savefig('results/pos_embd.png')
261/45: fig, axis = plt.subplots(1, 1, figsize=(100, 100))
261/46: axis.imshow(model.pos_emb.data[0].cpu().numpy().T, cmap='jet')
261/47: plt.savefig('results/pos_embd.png')
261/48: fig, axis = plt.subplots(1, 1, figsize=(20, 20))
261/49: axis.imshow(model.pos_emb.data[0].cpu().numpy(), cmap='jet')
261/50: plt.savefig('results/pos_embd.png')
261/51:
from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU
261/52:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    
    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')
261/53: model.pos_emb.data[0].cpu().numpy().shape
261/54: model.pos_emb.data
261/55: model.pos_emb.data.shape
261/56: model.pos_emb.data[0, :, :].cpu().shape
261/57: zci = torch.cat((torch.tensor([0.0]), ci))
261/58: zci
261/59: zci.shape
261/60: torch.cat((torch.tensor([0.0] * 256), ci))
261/61: torch.cat((torch.tensor([[0.0] * 256]), ci))
261/62: ci.shape
261/63: ci = model.pos_emb.data[0, :, :].cpu()
261/64: torch.cat((torch.tensor([0.0] * 256), ci))
261/65: ci.shape
261/66: torch.cat((torch.tensor([[0.0] * 256]), ci))
261/67: torch.cat((torch.tensor([ np.zeros(256) ]), ci))
261/68: zci = torch.cat((torch.tensor([ np.zeros(256) ]), ci))  # pre-cat a zero
261/69: zci[iperm]
261/70: rzci = zci[iperm]
262/1:
#!/usr/bin/env python
# coding: utf-8


import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/scratch/attila/results/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel

    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')

plt.savefig('results/clustered.png')


from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 1

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
262/2: !pwd
262/3:
#!/usr/bin/env python
# coding: utf-8


import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel

    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')

plt.savefig('results/clustered.png')


from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 1

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
262/4:
ci = model.pos_emb.data[0, :, :].cpu()
zci = torch.cat((torch.tensor([ np.zeros(256) ]), ci))  # pre-cat a zero
rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
263/1:
#!/usr/bin/env python
# coding: utf-8


import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel

    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')

plt.savefig('results/clustered.png')


from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 1

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 32
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm] # note: undo the encoding permutation
    sample = C[pxi].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)

    ax.imshow(sample[..., 0], cmap='magma')  # grayscale -> 2D
    ax.axis('off')

plt.savefig('results/samples.png')


# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd.png')
263/2: pixels.shape
263/3:
n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)
263/4: from mingpt.utils import sample
263/5:
n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)
263/6: pixels.shape
263/7: iperm = torch.argsort(train_dataset.perm)
263/8: iperm
263/9: train_dataset.perm
263/10: pixels[i][0]
263/11: pixels[0]
263/12: pixels[0] == pixels[0][iperm]
263/13: (pixels[0] == pixels[0][iperm]).all()
263/14: C[pixels[0]]
263/15:
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size, 0).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
263/16:
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
263/17: model.pos_emb.data.shape
263/18: ci = model.pos_emb.data[0, :, 10].cpu()
263/19: ci.shape
263/20: zci = torch.cat((torch.tensor([0.0]), ci))
263/21: zci
263/22: zci.shape
263/23: rzci = zci[iperm]
263/24: rzci.shape
263/25: rzci.numpy()
263/26: rzci.numpy().shape
263/27: np.zeros((3, 5))
263/28: ff =np.zeros((3, 5))
263/29: ff[:, 2] = [1,2,3]
263/30: ff
263/31:
viz_embd = np.zeros((1024, 256))
for dim in range(256):
    ci = model.pos_emb.data[0, :, dim].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    viz_embd[:, dim] = rzci.numpy()
263/32: viz_embd
263/33: viz_embd.shape
263/34: fig, axis = plt.subplots(1, 1, figsize=(20, 20))
264/1:
#!/usr/bin/env python
# coding: utf-8


import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel

    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')

plt.savefig('results/clustered.png')


from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256
)
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 50

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
264/2:
# visualize some of the learned positional embeddings, maybe they contain structure

fig, axis = plt.subplots(32, 8, figsize=(30, 30))  # 256 dimensions in embedding
for dim, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, dim].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.set_title('dim #{}'.format(dim))
    ax.axis('off')


plt.savefig('results/pos_embd.png')
264/3:
# visualize some of the learned positional embeddings, maybe they contain structure

n_see = 8 * 8
n_cols = 8
n_rows = n_see // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))
for i, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, i].cpu()
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.axis('off')


plt.savefig('results/pos_embd_karp.png')
264/4:
fig, axis = plt.subplots(32, 8, figsize=(5, 5))  # 256 dimensions in embedding
for dim, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, dim].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.set_title('dim #{}'.format(dim))
    ax.axis('off')


plt.savefig('results/pos_embd.png')
264/5:
fig, axis = plt.subplots(32, 8, figsize=(100, 100))  # 256 dimensions in embedding
for dim, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, dim].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.set_title('dim #{}'.format(dim))
    ax.axis('off')


plt.savefig('results/pos_embd.png')
264/6:
fig, axis = plt.subplots(32, 8, figsize=(50, 10))  # 256 dimensions in embedding
for dim, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, dim].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.set_title('dim #{}'.format(dim))
    ax.axis('off')


plt.savefig('results/pos_embd.png')
264/7:
fig, axis = plt.subplots(32, 8, figsize=(10, 40))  # 256 dimensions in embedding
for dim, ax in enumerate(axis.ravel()):
    ci = model.pos_emb.data[0, :, dim].cpu()  # 1023 tokens = pixels
    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero => 1024 tokens
    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image
    embd = rzci.view(pixel_size, pixel_size).numpy()

    ax.imshow(embd, cmap='jet')
    ax.set_title('dim #{}'.format(dim))
    ax.axis('off')


plt.savefig('results/pos_embd.png')
264/8: checkpoint = {'model': model, 'pixels': pixels, 'iperm': iperm}
265/1: import tensorflow as tf
265/2:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4,)))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='softmax'))
265/3: model
265/4: model.predict([0,0,0,0])
265/5:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='softmax'))
265/6: model.predict([0,0,0,0])
265/7: model.predict([ [0,0,0,0] ])
265/8:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='softmax'))
265/9: model.predict([ [0,0,0,0] ])
265/10:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.add(tf.keras.layers.Dense(1, activation='softmax'))
265/11: model.predict([ [0,0,0,0] ])
265/12: model.predict([ [0,0,0,0] ])
265/13: model.predict([ [0,1,0,0] ])
265/14:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))

model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.add(tf.keras.layers.Dense(1, activation='softmax'))
265/15: model.predict([ [0, 1, 0, 0] ])
265/16:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 1, 0], [1]),
    ( [1, 0, 0, 1], [2])    
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/17: model.fit(X, y)
265/18:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))

model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.add(tf.keras.layers.Dense(1, activation='softmax'))

model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
265/19: model.fit(X, y)
265/20: model.predict(X)
265/21:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))

model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.add(tf.keras.layers.Dense(1, activation='relu'))

model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
265/22: model.fit(X, y)
265/23: model.predict(X)
265/24:
dataset = [
    ( [0, 0, 0, 0], [0, 0]),
    ( [0, 0, 1, 0], [0, 1]
    ( [1, 0, 0, 1], [0, 2])    
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/25:
dataset = [
    ( [0, 0, 0, 0], [0, 0]),
    ( [0, 0, 1, 0], [0, 1]),
    ( [1, 0, 0, 1], [0, 2])    
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/26:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))

model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.add(tf.keras.layers.Dense(2, activation='relu'))

model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
265/27: model.fit(X, y)
265/28: model.predict(X)
265/29:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))

model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
265/30: model.predict(X)
265/31: model.predict(X)
265/32: model.predict(X)
265/33: model.predict(X)
265/34:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 1, 0], [1]),
    ( [1, 0, 0, 1], [2])    
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/35:
model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(4)))

model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))

model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
265/36: model.predict(X)
265/37:
encoder = tf.keras.models.Sequential()

encoder.add(tf.keras.Input(shape=(4)))

encoder.add(tf.keras.layers.Dense(32, activation='relu'))
encoder.add(tf.keras.layers.Dense(32, activation='relu'))
265/38: encoder.predict(X)
265/39: ideas = encoder.predict(X)
265/40:
decoder = tf.keras.models.Sequential()

decoder.add(tf.keras.Input(shape=(32)))

decoder.add(tf.keras.layers.Dense(32, activation='relu'))
decoder.add(tf.keras.layers.Dense(1))
265/41: decoder.predict(ideas)
265/42:
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
265/43:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Conv2D(32, 3, activation="relu", strides=2, padding="same")(encoder_inputs)
x = layers.Conv2D(64, 3, activation="relu", strides=2, padding="same")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)

z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name="encoder")
265/44:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Conv1D(32, 3, activation="relu", strides=2, padding="same")(encoder_inputs)
x = layers.Conv1D(64, 3, activation="relu", strides=2, padding="same")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)

z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name="encoder")
265/45:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation="relu")(encoder_inputs)
x = layers.Dense(16, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)

z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name="encoder")
265/46: ideas = encoder.predict(X)
265/47: ideas
265/48:
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(64, activation="relu")(latent_inputs)
x = layers.Dense(64, activation="relu")(x)

decoder_outputs = layers.Dense(1, activation="sigmoid")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/49: decoder.predict(ideas)
265/50:
class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(1, 2)))
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/51:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, y, epochs=30)
265/52:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon
      
class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(1, 2)))
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/53:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, y, epochs=30)
265/54:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/55:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            print(z_mean, z_log_var)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(1, 2)))
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/56:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/57:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            print(reconstruction)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/58:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/59:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            print(keras.losses.binary_crossentropy(data, reconstruction))
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/60:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/61:
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(64, activation="relu")(latent_inputs)
x = layers.Dense(64, activation="relu")(x)

decoder_outputs = layers.Dense(4, activation="sigmoid")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/62:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/63:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/64:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/65:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/66:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/67:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/68: vae.predict(X)
265/69:
import matplotlib.pyplot as plt


def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 28
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            print(yi, xi, x_decoded)

#     plt.figure(figsize=(figsize, figsize))
#     start_range = digit_size // 2
#     end_range = n * digit_size + start_range
#     pixel_range = np.arange(start_range, end_range, digit_size)
#     sample_range_x = np.round(grid_x, 1)
#     sample_range_y = np.round(grid_y, 1)
#     plt.xticks(pixel_range, sample_range_x)
#     plt.yticks(pixel_range, sample_range_y)
#     plt.xlabel("z[0]")
#     plt.ylabel("z[1]")
#     plt.axis("off")
#     plt.imshow(figure, cmap="Greys_r")
#     plt.savefig('vae_grid.png', dpi=300)


plot_latent_space(vae)
265/70:
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
265/71:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 28
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            print(yi, xi, x_decoded)

#     plt.figure(figsize=(figsize, figsize))
#     start_range = digit_size // 2
#     end_range = n * digit_size + start_range
#     pixel_range = np.arange(start_range, end_range, digit_size)
#     sample_range_x = np.round(grid_x, 1)
#     sample_range_y = np.round(grid_y, 1)
#     plt.xticks(pixel_range, sample_range_x)
#     plt.yticks(pixel_range, sample_range_y)
#     plt.xlabel("z[0]")
#     plt.ylabel("z[1]")
#     plt.axis("off")
#     plt.imshow(figure, cmap="Greys_r")
#     plt.savefig('vae_grid.png', dpi=300)


plot_latent_space(vae)
265/72:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            print(yi, xi, x_decoded)

#     plt.figure(figsize=(figsize, figsize))
#     start_range = digit_size // 2
#     end_range = n * digit_size + start_range
#     pixel_range = np.arange(start_range, end_range, digit_size)
#     sample_range_x = np.round(grid_x, 1)
#     sample_range_y = np.round(grid_y, 1)
#     plt.xticks(pixel_range, sample_range_x)
#     plt.yticks(pixel_range, sample_range_y)
#     plt.xlabel("z[0]")
#     plt.ylabel("z[1]")
#     plt.axis("off")
#     plt.imshow(figure, cmap="Greys_r")
#     plt.savefig('vae_grid.png', dpi=300)


plot_latent_space(vae)
265/73:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            print(yi, xi, x_decoded)

#     plt.figure(figsize=(figsize, figsize))
#     start_range = digit_size // 2
#     end_range = n * digit_size + start_range
#     pixel_range = np.arange(start_range, end_range, digit_size)
#     sample_range_x = np.round(grid_x, 1)
#     sample_range_y = np.round(grid_y, 1)
#     plt.xticks(pixel_range, sample_range_x)
#     plt.yticks(pixel_range, sample_range_y)
#     plt.xlabel("z[0]")
#     plt.ylabel("z[1]")
#     plt.axis("off")
#     plt.imshow(figure, cmap="Greys_r")
#     plt.savefig('vae_grid.png', dpi=300)


plot_latent_space(vae)
265/74: vae.decoder.predict(np.array([[1, 2]]))
265/75: vae.decoder.predict(np.array([[1, 2, 3, 4]]))
265/76:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]
    
    print(grid_x)

#     for i, yi in enumerate(grid_y):
#         for j, xi in enumerate(grid_x):
#             z_sample = np.array([[xi, yi]])
#             x_decoded = vae.decoder.predict(z_sample)
#             print(yi, xi, x_decoded)

#     plt.figure(figsize=(figsize, figsize))
#     start_range = digit_size // 2
#     end_range = n * digit_size + start_range
#     pixel_range = np.arange(start_range, end_range, digit_size)
#     sample_range_x = np.round(grid_x, 1)
#     sample_range_y = np.round(grid_y, 1)
#     plt.xticks(pixel_range, sample_range_x)
#     plt.yticks(pixel_range, sample_range_y)
#     plt.xlabel("z[0]")
#     plt.ylabel("z[1]")
#     plt.axis("off")
#     plt.imshow(figure, cmap="Greys_r")
#     plt.savefig('vae_grid.png', dpi=300)


plot_latent_space(vae)
265/77:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

#     for i, yi in enumerate(grid_y):
#         for j, xi in enumerate(grid_x):
#             z_sample = np.array([[xi, yi]])
#             x_decoded = vae.decoder.predict(z_sample)
#             print(yi, xi, x_decoded)

#     plt.figure(figsize=(figsize, figsize))
#     start_range = digit_size // 2
#     end_range = n * digit_size + start_range
#     pixel_range = np.arange(start_range, end_range, digit_size)
#     sample_range_x = np.round(grid_x, 1)
#     sample_range_y = np.round(grid_y, 1)
#     plt.xticks(pixel_range, sample_range_x)
#     plt.yticks(pixel_range, sample_range_y)
#     plt.xlabel("z[0]")
#     plt.ylabel("z[1]")
#     plt.axis("off")
#     plt.imshow(figure, cmap="Greys_r")
#     plt.savefig('vae_grid.png', dpi=300)


plot_latent_space(vae, n=5)
265/78: vae.decoder.predict([[1,2]])
265/79:
def count(x):
    return len([
        _ for _ in x
        if x > 0
    ])
265/80: count(X[0])
265/81:
def count(x):
    return len([
        _ for _ in x
        if _ > 0
    ])
265/82: count(X[0])
265/83: count(X[1])
265/84: count(X[2])
265/85:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            digit = count(x_decoded)
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.axis("off")
    plt.imshow(figure, cmap="Greys_r")


plot_latent_space(vae, n=5)
265/86:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            print(x_decoded)
            digit = count(x_decoded)
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.axis("off")
    plt.imshow(figure, cmap="Greys_r")


plot_latent_space(vae, n=5)
265/87:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            digit = count(x_decoded[0])
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.axis("off")
    plt.imshow(figure, cmap="Greys_r")


plot_latent_space(vae, n=5)
265/88:
def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            digit = count(x_decoded[0])
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.axis("off")
    plt.imshow(figure, cmap="Greys_r")


plot_latent_space(vae, n=5)

plt.show()
265/89:
%matplotlib inline

def plot_latent_space(vae, n=30, figsize=15):
    # Display a n*n 2D manifold of digits.
    digit_size = 1
    scale = 1
    figure = np.zeros((digit_size * n, digit_size * n))
    # Linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space.
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            digit = count(x_decoded[0])
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.axis("off")
    plt.imshow(figure, cmap="Greys_r")


plot_latent_space(vae, n=5)
265/90: vae.decoder.predict(X)
265/91: vae.encoder.predict(X)
265/92:
ee = vae.encoder.predict(X)
vae.decoder.predict(ee)
265/93:
dataset = [
    ( [0, 0, 0, 0], [0] * 4),
    ( [0, 0, 1, 0], [1] * 4),
    ( [1, 0, 0, 1], [2] * 4)    
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/94:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation="relu")(encoder_inputs)
x = layers.Dense(16, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)

z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name="encoder")
265/95:
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(64, activation="relu")(latent_inputs)
x = layers.Dense(64, activation="relu")(x)

decoder_outputs = layers.Dense(4, activation="sigmoid")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/96:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/97:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/98:
class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size, z_size = tf.shape(z_mean)[0], tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch_size, z_size))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.ae_loss_tracker = keras.metrics.Mean(name='ae_loss')
        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            ae_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = ae_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.ae_loss_tracker.update_state(ae_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "total_loss": self.total_loss_tracker.result(),
            "ae_loss": self.ae_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
265/99:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(X, epochs=30)
265/100:
ee = vae.encoder.predict(X)
vae.decoder.predict(ee)
265/101:
dataset = [
    ( [0, 0, 0, 0], [0] * 4),
    ( [0, 0, 0.1, 0], [1] * 4),
    ( [0.1, 0, 0, 1], [2] * 4)    
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/102:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0.1, 0, 0, 1], [2]),
    ( [5, 4, 0, 1], [3])
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/103:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation="relu")(encoder_inputs)
x = layers.Dense(16, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)

encoder = keras.Model(encoder_inputs, x, name="encoder")
265/104: encoder.predict(X)
265/105:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation="relu")(encoder_inputs)
x = layers.Dense(16, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(4, activation="relu")(x)

encoder = keras.Model(encoder_inputs, x, name="encoder")
265/106: encoder.predict(X)
265/107:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0.1, 0, 0, 1], [2]),
    ( [5, 4, 0, 1], [3])
]
X = [
    data[0] for data in dataset
]
y = [
    data[1] for data in dataset
]
265/108:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation="relu")(encoder_inputs)
x = layers.Dense(16, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(4, activation="relu")(x)

encoder = keras.Model(encoder_inputs, x, name="encoder")
265/109: encoder.predict(X)
265/110:
latent_dim = 2

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation="relu")(encoder_inputs)
x = layers.Dense(16, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(latent_dim, activation="relu")(x)

encoder = keras.Model(encoder_inputs, x, name="encoder")
265/111: encoder.predict(X)
265/112:
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(64, activation="relu")(latent_inputs)
x = layers.Dense(64, activation="relu")(x)

decoder_outputs = layers.Dense(1, activation="sigmoid")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/113: decoder.predict(encoder.predict(X))
265/114:
class NN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(NN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X, y = data  # unpack

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': ,
            'decoder_loss': 
        }
265/115:
class NN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(NN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X, y = data  # unpack

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': None,
            'decoder_loss': 
        }
265/116:
class NN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(NN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X, y = data  # unpack

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': None,
            'decoder_loss': None
        }
265/117:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit((X, y), epochs=30)
265/118:
class NN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(NN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X, y = data  # unpack

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/119:
vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit((X, y), epochs=30)
265/120:
vae = NN(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit((X, y), epochs=30)
265/121:
class NN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(NN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X, y = data  # unpack
        
        print('woow')

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/122:
vae = NN(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit((X, y), epochs=30)
265/123:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X, y = data  # unpack

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/124:
vae = CountNN(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit((X, y), epochs=30)
265/125:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit((X, y), epochs=30)
265/126:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.ae_loss_tracker, self.kl_loss_tracker]

    def train_step(self, data):
        X = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/127:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, epochs=30)
265/128:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/129:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, epochs=30)
265/130:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea.numpy())
            print('rec', reconstruction.numpy())

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/131:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, epochs=30)
265/132:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/133:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, epochs=30)
265/134:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print('idea', idea)
            print('rec', reconstruction[0])

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/135:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=30)
265/136:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction[0])
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/137:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=30)
265/138:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=5)
265/139: X
265/140: y
265/141:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0.1, 0, 0, 1], [2]),
    ( [5, 4, 0, 1], [3])
]
X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
265/142:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=5)
265/143:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/144:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=5)
265/145:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print(idea)
            print(reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/146:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=5)
265/147:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print(idea)
            print(reconstruction)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(y, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/148:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=5)
265/149:
ee = vae.encoder.predict(X)
vae.decoder.predict(ee)
265/150:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=50)
265/151:
ee = vae.encoder.predict(X)
vae.decoder.predict(ee)
265/152:
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(64, activation="relu")(latent_inputs)
x = layers.Dense(64, activation="relu")(x)

decoder_outputs = layers.Dense(1, activation="relu")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/153:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=10)
265/154:
ee = vae.encoder.predict(X)
vae.decoder.predict(ee)
265/155:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=3)
265/156:
ee = vae.encoder.predict(X)
vae.decoder.predict(ee)
265/157:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')
        self.encoder_loss_tracker = keras.metrics.Mean(name='encoder_loss')
        self.decoder_loss_tracker = keras.metrics.Mean(name='decoder_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker, self.encoder_loss_tracker, self.decoder_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            reconstruction = decoder(idea)
            
            print(y)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(y, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
            'encoder_loss': 0,
            'decoder_loss': 0
        }
265/158:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=3)
265/159: vae.encoder.predict(X)
265/160: y
265/161: vae.encoder.predict(X) * 5
265/162: vae.encoder.predict(X)
265/163:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            
            n = np.random.randint(0, 10)
            idea = idea * n
            
            reconstruction = decoder(idea)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(y, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
        }
265/164:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=3)
265/165:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=30)
265/166:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=100)
265/167: vae.encoder.predict(X)
265/168: model.encoder.predict(X)
265/169: model.decoder.predict(model.encoder.predict(X))
265/170: model.encoder.predict(X)
265/171:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            
            n = np.random.randint(0, 20)
            
            reconstruction = decoder(idea) * n

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(y, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
        }
265/172:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=100)
265/173: model.encoder.predict(X)
265/174: model.decoder.predict(model.encoder.predict(X))
265/175:
act_f = 'sigmoid'
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(16, activation=act_f)(latent_inputs)
x = layers.Dense(16, activation=act_f)(x)

decoder_outputs = layers.Dense(1, activation="relu")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/176:
latent_dim = 2
act_f = 'sigmoid'

encoder_inputs = keras.Input(shape=(4))

x = layers.Dense(16, activation=act_f)(encoder_inputs)
x = layers.Dense(16, activation=act_f)(x)
x = layers.Flatten()(x)
x = layers.Dense(latent_dim, activation="relu")(x)

encoder = keras.Model(encoder_inputs, x, name="encoder")
265/177:
act_f = 'sigmoid'
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(16, activation=act_f)(latent_inputs)
x = layers.Dense(16, activation=act_f)(x)

decoder_outputs = layers.Dense(1, activation="relu")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/178:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=100)
265/179: model.encoder.predict(X)
265/180: model.decoder.predict(model.encoder.predict(X))
265/181:
# dataset = [
#     ( [0, 0, 0, 0], [0]),
#     ( [0, 0, 0.1, 0], [1]),
#     ( [0, 99, 0, 0], [1]),
#     ( [0.1, 0, 0, 1], [2]),
#     ( [5, 4, 0, 1], [3])
# ]  # counts

dataset = [
    ( [0, 0], [0]),
    ( [0, 1], [1]),
    ( [1, 0], [1]),
    ( [1, 1], [0])
]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
265/182:
latent_dim = 2
act_f = 'sigmoid'

encoder_inputs = keras.Input(shape=(len(X[0])))

x = layers.Dense(16, activation=act_f)(encoder_inputs)
x = layers.Dense(16, activation=act_f)(x)
x = layers.Flatten()(x)
x = layers.Dense(latent_dim, activation="relu")(x)

encoder = keras.Model(encoder_inputs, x, name="encoder")
265/183:
act_f = 'sigmoid'
latent_inputs = keras.Input(shape=(latent_dim,))

x = layers.Dense(16, activation=act_f)(latent_inputs)
x = layers.Dense(16, activation=act_f)(x)

decoder_outputs = layers.Dense(len(y[0]), activation="relu")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
265/184:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            
            n = np.random.randint(0, 20)
            
            reconstruction = decoder(idea) * n

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(y, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
        }
265/185:
class CountNN(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(CountNN, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')

    @property
    def metrics(self):
      return [self.total_loss_tracker]

    def train_step(self, data):
        X, y = data

        with tf.GradientTape() as tape:
            idea = self.encoder(X)
            
            # n = np.random.randint(0, 20)
            
            reconstruction = decoder(idea)

            total_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(y, reconstruction)
                )
            )
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        
        return {
            'total_loss': self.total_loss_tracker.result(),
        }
265/186:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=100)
265/187: model.encoder.predict(X)
265/188: model.decoder.predict(model.encoder.predict(X))
265/189:
model = CountNN(encoder, decoder)
model.compile(optimizer=keras.optimizers.Adam())
model.fit(X, y, epochs=1000)
265/190:
model = layers.Sequential()
model.add(layers.Dense(8, input_dim=2))
model.add(layers.Activation('tanh'))
model.add(layers.Dense(1))
model.add(layers.Activation('sigmoid'))
265/191:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, input_dim=2)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
265/192: model.fit(X, y, show_accuracy=True, batch_size=1, nb_epoch=100)
265/193: model.fit(X, y, batch_size=1, nb_epoch=100)
265/194: model.fit(X, y, batch_size=1, epochs100)
265/195: model.fit(X, y, batch_size=1, epochs=00)
265/196: model.fit(X, y, batch_size=1, epochs=100)
265/197:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, input_dim=2)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer
model.compile(optimizer=keras.optimizers.Adam(lr=3e-4))
265/198:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, input_dim=2)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(optimizer=keras.optimizers.Adam(lr=3e-4))
265/199: model.fit(X, y, batch_size=1, epochs=100)
265/200:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, input_dim=2, activation='tanh')(inp)
x = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(optimizer=keras.optimizers.Adam(lr=3e-4))
265/201: model.fit(X, y, batch_size=1, epochs=100)
265/202:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, activation='tanh')(inp)
x = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(optimizer=keras.optimizers.Adam(lr=3e-4))
265/203: model.fit(X, y, batch_size=1, epochs=100)
265/204:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, activation='tanh')(inp)
x = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=3e-4),
    loss='binary_crossentropy'
)
265/205: model.fit(X, y, batch_size=1, epochs=100)
265/206: model.predict(X)
265/207: model.fit(X, y, batch_size=1, epochs=1000)
265/208: model.predict(X)
265/209:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8, activation='tanh')(inp)
x = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/210: model.fit(X, y, batch_size=1, epochs=100)
265/211: model.predict(X)
265/212:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/213: model.fit(X, y, batch_size=1, epochs=100)
265/214: model.predict(X)
265/215:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/216: model.fit(X, y, batch_size=1, epochs=100)
265/217: model.predict(X)
265/218:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='categorical_crossentropy'
)
265/219: model.fit(X, y, batch_size=1, epochs=100)
265/220: model.predict(X)
265/221:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/222: model.predict_proba(X)
265/223:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/224: model.fit(X, y, batch_size=1, epochs=100)
265/225: model.fit(X, y, batch_size=1, epochs=1000)
265/226: model.predict(X)
265/227:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Dropout(0.3)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/228: model.fit(X, y, batch_size=1, epochs=1000)
265/229: model.predict(X)
265/230:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Dropout(0.1)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/231: model.fit(X, y, batch_size=1, epochs=1000)
265/232: model.predict(X)
265/233:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dropout(0.1)(inp)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/234: model.fit(X, y, batch_size=1, epochs=1000)
265/235: model.predict(X)
265/236:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/237: model.fit(X, y, batch_size=1, epochs=1000)
265/238: model.predict(X)
265/239:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(8)(x)
x = layers.Activation('tanh')(x)
x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/240: model.fit(X, y, batch_size=1, epochs=1000)
265/241: model.predict(X)
265/242:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(8)(x)
x = layers.Activation('sigmoid')(x)

x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/243:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(8)(inp)
x = layers.Activation('sigmoid')(x)
x = layers.Dense(8)(x)
x = layers.Activation('sigmoid')(x)

x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/244: model.fit(X, y, batch_size=1, epochs=1000)
265/245:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(),
    loss='binary_crossentropy'
)
265/246: model.fit(X, y, batch_size=1, epochs=1000)
265/247: model.predict(X)
265/248:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(2)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(2)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=3e-4),
    loss='binary_crossentropy'
)
265/249: model.fit(X, y, batch_size=1, epochs=1000)
265/250:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=3e-4),
    loss='binary_crossentropy'
)
265/251: model.fit(X, y, batch_size=1, epochs=1000)
265/252: model.predict(X)
265/253:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(1)(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='binary_crossentropy'
)
265/254: model.fit(X, y, batch_size=1, epochs=1000)
265/255: model.predict(X)
265/256:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0.1, 0, 0, 1], [2]),
    ( [5, 4, 0, 1], [3])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
265/257:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='binary_crossentropy'
)
265/258: model.fit(X, y, batch_size=1, epochs=1000)
265/259:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0, 0, 0, 0], [1]),
    ( [5, 4, 0, 1], [1])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
265/260:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='binary_crossentropy'
)
265/261: model.fit(X, y, batch_size=1, epochs=1000)
265/262: model.predict(X)
265/263: y
265/264:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0, 0, 0, 0], [0]),
    ( [5, 4, 0, 1], [1])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
265/265: model.fit(X, y, batch_size=1, epochs=1000)
265/266: y
265/267: model.predict(X)
265/268: model.predict(X)[0]
265/269: model.predict(X)[1]
266/1:
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
266/2:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0, 0, 0, 0], [0]),
    ( [5, 4, 0, 1], [1])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
266/3:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x, name="xorrer")
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/4: model.fit(X, y, batch_size=1, epochs=1000)
266/5:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='binary_crossentropy'
)
266/6: model.fit(X, y, batch_size=1, epochs=1000)
266/7: model.predict(X)
266/8: y
266/9:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0, 0, 0.1, 4], [2]),
    ( [5, 4, 0, 1], [2])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
266/10:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('sigmoid')(x)

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/11: model.fit(X, y, batch_size=1, epochs=1000)
266/12: model.predict(X)
266/13:
dataset = [
    ( [0, 0, 0, 0], [0]),
    ( [0, 0, 0.1, 0], [1]),
    ( [0, 99, 0, 0], [1]),
    ( [0, 0, 0.1, 4], [2]),
    ( [0, 4, 0, 1], [2])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
266/14: model.fit(X, y, batch_size=1, epochs=1000)
266/15:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('relu')(x)

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/16:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('tanh')(x)
x = layers.Dense(4)(x)
x = layers.Activation('tanh')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/17: model.fit(X, y, batch_size=1, epochs=1000)
266/18: model.predict(X)
266/19:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('sigmoid')(x)
x = layers.Dense(4)(x)
x = layers.Activation('sigmoid')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/20: model.fit(X, y, batch_size=1, epochs=1000)
266/21: model.predict(X)
266/22:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('sigmoid')(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

# x = layers.Dense(len(y[0]))(x)
# x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/23: model.predict(X)
266/24:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('relu')(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

# x = layers.Dense(len(y[0]))(x)
# x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/25: model.predict(X)
266/26:
def sigmoid_in_origin(x):
    return ( K.sigmoid(x) - 0.5) * 2
266/27:
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from keras import backend as K
from tensorflow.keras import layers
266/28:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

# x = layers.Dense(len(y[0]))(x)
# x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/29: model.predict(X)
266/30:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation('sigmoid')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/31:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(len(y[0]))(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/32: model.fit(X, y, batch_size=1, epochs=1000)
266/33: model.fit(X, y, batch_size=1, epochs=100)
266/34: model.predict(X)
266/35:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

# x = layers.Dense(len(y[0]))(x)
# x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/36: model.fit(X, y, batch_size=1, epochs=100)
266/37:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(len(y[0]))(x)
# x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss='categorical_crossentropy'
)
266/38: # model.fit(X, y, batch_size=1, epochs=100)
266/39: model.fit(X, y, batch_size=1, epochs=100)
266/40: # model.predict(X)
266/41: model.predict(X)
266/42:
l = np.linspace(-10, 10, 100)
plt.plot(l, sigmoid_in_origin(l))
266/43:
l = np.linspace(-10, 10, 100)
plt.plot(l, sigmoid_in_origin(l))
plt.show()
266/44:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import tensorflow as tf
from tensorflow import keras
from keras import backend as K
from tensorflow.keras import layers
266/45:
l = np.linspace(-10, 10, 100)
plt.plot(l, sigmoid_in_origin(l))
plt.show()
266/46:
def loss(y_true, y_pred):
    # clip to prevent NaN's and Inf's
    y_pred = K.clip(y_pred, K.epsilon(), 2)

    loss = y_true * tf.math.log(y_pred)
    loss = -K.sum(loss, -1)
    return loss
266/47:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(1)(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/48: model.fit(X, y, batch_size=1, epochs=100)
266/49: model.predict(X)
266/50:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('sigmoid')(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(1)(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/51: model.fit(X, y, batch_size=1, epochs=100)
266/52: model.predict(X)
266/53:
def loss(y_true, y_pred):
    # clip to prevent NaN's and Inf's
    y_pred = K.clip(y_pred, 0, 2)
    return np.abs(y_true - y_pred)
266/54:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('sigmoid')(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(1)(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/55: model.fit(X, y, batch_size=1, epochs=100)
266/56:
def loss(y_true, y_pred):
    # clip to prevent NaN's and Inf's
    y_pred = K.clip(y_pred, 0, 2)
    return K.abs(y_true - y_pred)
266/57:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('sigmoid')(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(1)(x)
x = layers.Activation('relu')(x)  # 'sigmoid' for there are non-zero or not

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/58: model.fit(X, y, batch_size=1, epochs=100)
266/59: model.predict(X)
266/60:
dataset = [
    ( [0, 0, 0, 0], [0, 0, 1]),
    ( [0, 0, 0.1, 0], [0, 1, 0]),
    ( [0, 99, 0, 0], [0, 1, 0]),
    ( [0, 0, 0.1, 4], [1, 0, 0]),
    ( [0, 4, 0, 1], [1, 0, 0])
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
266/61:
def sigmoid_in_origin(x):
    return ( K.sigmoid(x) - 0.5) * 2
266/62:
def loss(y_true, y_pred):
    # clip to prevent NaN's and Inf's
    y_pred = K.clip(y_pred, 0, 2)

    loss = y_true * tf.math.log(y_pred)
    loss = -K.sum(loss, -1)
    return loss
266/63:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/64: model.fit(X, y, batch_size=1, epochs=100)
266/65: model.predict(X)
266/66:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation('sigmoid')(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/67: model.fit(X, y, batch_size=1, epochs=100)
266/68: model.predict(X)
266/69:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
# x = layers.Dense(4)(x)
# x = layers.Activation('sigmoid')(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/70: model.fit(X, y, batch_size=1, epochs=100)
266/71: model.predict(X)
266/72: model.fit(X, y, batch_size=1, epochs=1000)
266/73: model.predict(X)
266/74:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation('sigmoid')(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/75: model.fit(X, y, batch_size=1, epochs=1000)
266/76:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/77: model.fit(X, y, batch_size=1, epochs=1000)
266/78: model.predict(X)
266/79: model.fit(X, y, batch_size=1, epochs=100)
266/80: model.fit(X, y, batch_size=1, epochs=100)
266/81: model.predict(X)
266/82:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/83: model.fit(X, y, batch_size=1, epochs=100)
266/84: model.fit(X, y, batch_size=1, epochs=200)
266/85:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/86: model.fit(X, y, batch_size=1, epochs=200)
266/87: model.predict(X)
266/88: model.fit(X, y, batch_size=1, epochs=500)
266/89: model.fit(X, y, batch_size=1, epochs=100)
266/90:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/91: model.fit(X, y, batch_size=1, epochs=100)
266/92:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/93: model.fit(X, y, batch_size=1, epochs=100)
266/94:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/95: model.fit(X, y, batch_size=1, epochs=1000)
266/96: model.predict(X)
266/97:
model.predict(
    [
        [0, 0, 0, 0],
        [1, 0, 0, 1],
        [100, 100, 0, 0]
    ]
)
266/98:
model.predict(
    [
        [0, 0, 0, 0],
        [0, 0, 0, 100],
        [100, 100, 0, 0]
    ]
)
266/99:
dataset = [
    ( [0, 0, 0, 0], [0, 0, 1] ),
    ( [0, 0, 0.1, 0], [0, 1, 0] ),
    ( [0, 99, 0, 0], [0, 1, 0] ),
    ( [0, 0, 0, 100], [0, 1, 0] ),
    ( [0, 0, 0.1, 4], [1, 0, 0] ),
    ( [0, 4, 0, 1], [1, 0, 0] )
]  # counts

# dataset = [
#     ( [0, 0], [0]),
#     ( [0, 1], [1]),
#     ( [1, 0], [1]),
#     ( [1, 1], [0])
# ]  # XOR

X = np.array([
    data[0] for data in dataset
], dtype='float32')
y = np.array([
    data[1] for data in dataset
], dtype='float32')
266/100:
inp = keras.Input(shape=(len(X[0])))

x = layers.Dense(4)(inp)
x = layers.Activation(sigmoid_in_origin)(x)
x = layers.Dense(4)(x)
x = layers.Activation(sigmoid_in_origin)(x)

x = layers.Dense(3)(x)
x = layers.Activation('softmax')(x)  # 'sigmoid' for 'there are non-zero or not'

model = keras.Model(inp, x)
model.compile(
    optimizer=keras.optimizers.Adam(lr=2e-3),
    loss=loss
)
266/101: model.fit(X, y, batch_size=1, epochs=1000)
266/102: model.predict(X)
266/103:
model.predict(
    [
        [0, 0, 0, 0],
        [1000, 0, 0, 0],
        [100, 100, 0, 0]
    ]
)
267/1:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
267/2:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless
267/3:

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 8  # 8-color = 3-bit image
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
267/4:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
267/5:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
267/6:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/7:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/8:
, gradient, retain_graph, create_graph)
    186
267/9:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
267/10:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/11:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
267/12:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
267/13: trainer.train()
267/14: trainer.train()
267/15:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/16:
test_dataset = ImageDataset(train_dataset, C)


from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/17:
test_dataset = ImageDataset(t_train_dataset, C)


from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/18: test_dataset = ImageDataset(t_test_dataset, C)
267/19: 6.837760 * 1e6
267/20:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=10,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
267/21:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=256
)  # S size
model = GPT(mconf)
267/22:
ncluster = 256  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally
267/23:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=256
)  # S size
model = GPT(mconf)
267/24:
train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
267/25:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=256
)  # S size
model = GPT(mconf)
267/26:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
267/27:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
267/28:
t_train_dataset = TensorDataset(tensor_X_train, tensor_X_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
267/29:
train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
267/30:
t_train_dataset = TensorDataset(tensor_X_train, tensor_X_train)  # tensor_y_train
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
267/31:
train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
267/32:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
267/33:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/34:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/35:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/36:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/37:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/38:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/39:
checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
267/40:
counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
267/41:
n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)
267/42:
from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
267/43:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
267/44:
tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 15

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/45:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
267/46:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/47:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/48:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/49:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/50:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/51:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/52:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/53:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/54:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/55:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/56:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/57:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
267/58:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/1:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_X_train)  # tensor_y_train
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 256  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
268/2:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
268/3:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/4:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/5:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/6:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
268/7:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/8:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/9:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/10:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)
268/11:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/12:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/13:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/14:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/15:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/16:
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/17:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/18:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/19:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/20:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/21:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/22:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/23:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/24: ls
268/25:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/26:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/27:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/28:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/29:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/30:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/31:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/32:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
268/33:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 5

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
269/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
269/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_X_train)  # tensor_y_train
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 256  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally
269/3:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
270/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)  # tensor_y_train
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 6  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 32
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel

    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')

plt.savefig('results/clustered.png')


from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
270/3:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/4:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/5:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/6:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/7:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/8:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/9:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/10:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/11:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/12:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/13:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/14:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/15:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path


import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test



dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)


from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...
# but do it anyway to trim some data nonetheless


# run kmeans

def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c
270/16:
ncluster = 30  # 256  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)


# encode the training examples with our codebook to visualize how much we've lost in the discretization
270/17:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,  # 24
    n_head=8,
    n_embd=10  # 512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/18:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=2,  # 24
    n_head=8,
    n_embd=16  # 512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 100

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/19:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,  # 24
    n_head=8,
    n_embd=16  # 512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/20:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,  # 24
    n_head=8,
    n_embd=16  # 512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/21:
mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,  # 24
    n_head=8,
    n_embd=16  # 512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()
270/22:
checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample
270/23:
n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
270/24:
from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
270/25:
from mingpt.model import GPT, GPTConfig

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,  # 24
    n_head=8,
    n_embd=16  # 512
)  # S size
model = GPT(mconf)


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 20

# initialize a trainer instance and kick off training
checkpoint_path = 'results/latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs,
    batch_size=4,
    learning_rate=3e-3,
    betas = (0.9, 0.95),
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs*tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()


checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
270/26:

checkpoint = torch.load(checkpoint_path)  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=2)


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # note: undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
271/1: import tensorflow.compat.v1 as tf
271/2:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
271/3:
%matplotlib inline

import numpy as np
from matplotlib import pyplot as plt
from pathlib import Path
271/4:
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
271/5:
from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model
from src.utils import AttrDict, load_pickle
from src.model import model
271/6: !ls
271/7: !cd image-gpt/
271/8:
from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model
from src.utils import AttrDict, load_pickle
from src.model import model
271/9: !ls
271/10: cd image-gpt/
271/11: ls
271/12:
from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model
from src.utils import AttrDict, load_pickle
from src.model import model
271/13:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)[:16, ...]  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
271/14:
import numpy as np
from matplotlib import pyplot as plt
from pathlib import Path
271/15:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)[:16, ...]  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
271/16:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)[:16, ...]  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
271/17:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
271/18: from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model, set_seed
271/19:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
271/20:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
# trainable_params = tf.trainable_variables()

loss = tf.reduce_mean(results['gen_loss'])  # if needed, when there are many GPUs

optimizer = tf.train.AdamOptimizer(learning_rate=2e-5)
train_op = optimizer.minimize(loss)
271/21:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

metrics = []
for x_batch in iter_data(X_train, n_batch=n_batch, verbose=True):
    print(x_batch.shape)
  
    metrics.append(sess.run([ train_op, gen_loss[0] ], feed_dict={x: x_batch}))
        
# with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
#     sess.run(tf.global_variables_initializer())
271/22: from src.utils import AttrDict, load_pickle, iter_data
271/23:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

metrics = []
for x_batch in iter_data(X_train, n_batch=n_batch, verbose=True):
    print(x_batch.shape)
  
    metrics.append(sess.run([ train_op, gen_loss[0] ], feed_dict={x: x_batch}))
        
# with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
#     sess.run(tf.global_variables_initializer())
271/24:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

metrics = []
for x_batch in iter_data(X_train, n_batch=n_batch, verbose=True):
    print(x_batch.shape)
  
    metrics.append(sess.run([ train_op, loss ], feed_dict={x: x_batch}))
        
# with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
#     sess.run(tf.global_variables_initializer())
271/25:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 8,  # 512,
        'n_head': 8,
        'n_layer': 2,  # 24,
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}
271/26:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
271/27:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
# trainable_params = tf.trainable_variables()

loss = tf.reduce_mean(results['gen_loss'])  # if needed, when there are many GPUs

optimizer = tf.train.AdamOptimizer(learning_rate=2e-5)
train_op = optimizer.minimize(loss)
271/28:
H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 4,
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
271/29:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
271/30:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
# trainable_params = tf.trainable_variables()

loss = tf.reduce_mean(results['gen_loss'])  # if needed, when there are many GPUs

optimizer = tf.train.AdamOptimizer(learning_rate=2e-5)
train_op = optimizer.minimize(loss)
271/31:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

metrics = []
for x_batch in iter_data(X_train, n_batch=n_batch, verbose=True):
    metrics.append(sess.run([ train_op, loss ], feed_dict={x: x_batch}))
        
# with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
#     sess.run(tf.global_variables_initializer())
271/32:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

metrics = []
for x_batch in iter_data(X_train, n_batch=n_batch, verbose=True):
    print(x_batch)
    metrics.append(sess.run([ train_op, loss ], feed_dict={x: x_batch}))
271/33: metrics
271/34:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())

metrics = []
for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
    _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
    metrics.append(l)
    
    print('Step %i, Loss: %f' % (i, l))
271/35:
n_batch = args.n_sub_batch * args.n_gpu
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())

    metrics = []
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        metrics.append(l)

        print('Step %i, Loss: %f' % (i, l))
272/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
272/2:
import numpy as np
from matplotlib import pyplot as plt
from pathlib import Path


# In[ ]:


import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
272/3:
from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model, set_seed
from src.utils import AttrDict, load_pickle, iter_data
from src.model import model


# In[ ]:


_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)[:96, ...]  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)


# In[ ]:


args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)


# In[ ]:


tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
# trainable_params = tf.trainable_variables()

loss = tf.reduce_mean(results['gen_loss'])  # if needed, when there are many GPUs

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/4:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())
    
    for epoch in range(n_epochs):
        metrics = []
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
            metrics.append(l)

            print('epoch {} / {} batch {} loss {:.4f}'.format(epoch, n_epochs, i, l))
272/5:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 8,  # 512,
        'n_head': 8,
        'n_layer': 2,  # 24,
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 4,
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
272/6:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)


# In[ ]:


tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
# trainable_params = tf.trainable_variables()

loss = tf.reduce_mean(results['gen_loss'])  # if needed, when there are many GPUs

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)


# In[ ]:


n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())
    
    for epoch in range(n_epochs):
        metrics = []
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
            metrics.append(l)

            print('epoch {} / {} batch {} loss {:.4f}'.format(epoch, n_epochs, i, l))
272/7: X = np.expand_dims(dataset, axis=-1)  # grayscale images => 1 channel
272/8:
X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:16, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]
272/9: len(tf.trainable_variables())
272/10: results = model(hparams, X_test, reuse=False)
272/11: X_test
272/12:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)

logits = results['gen_logits']  # tf.reduce_mean(results['gen_logits'])
prediction = tf.nn.softmax(logits)
loss = tf.reduce_mean(results['gen_loss'])

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)

correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
272/13:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)

logits = results['gen_logits']  # tf.reduce_mean(results['gen_logits'])
prediction = tf.nn.softmax(logits)
loss = tf.reduce_mean(results['gen_loss'])

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)

# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
272/14:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            l = sess.run([ loss ], feed_dict={x: x_batch})
            print('epoch {} / {} batch {} train loss {:.4f}'.format(epoch, n_epochs, i, l))
    
    # test
    l = sess.run([ loss ], feed_dict={x: x_batch})
    print('train loss {:.4f}'.format(l))
272/15:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            l = sess.run([ loss ], feed_dict={x: x_batch})
            print(l)
            print('epoch {} / {} batch {} train loss {:.4f}'.format(epoch, n_epochs, i, l))
    
    # test
    l = sess.run([ loss ], feed_dict={x: x_batch})
    print('train loss {:.4f}'.format(l))
272/16:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            l, ... = sess.run([ loss ], feed_dict={x: x_batch})
            print('epoch {} / {} batch {} train loss {:.4f}'.format(epoch, n_epochs, i, l))
    
    # test
    l, ... = sess.run([ loss ], feed_dict={x: x_batch})
    print('train loss {:.4f}'.format(l))
272/17:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            results = sess.run([ loss ], feed_dict={x: x_batch})
            l = results[0]
            print('epoch {} / {} batch {} train loss {:.4f}'.format(epoch, n_epochs, i, l))
    
    # test
    results = sess.run([ loss ], feed_dict={x: x_batch})
    l = results[0]
    print('train loss {:.4f}'.format(l))
272/18:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 512,
        'n_head': 8,
        'n_layer': 2,  # 24,
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 4,
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
272/19:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
272/20:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)

logits = results['gen_logits']  # tf.reduce_mean(results['gen_logits'])
prediction = tf.nn.softmax(logits)
loss = tf.reduce_mean(results['gen_loss'])

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)

# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
272/21:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            results = sess.run([ loss ], feed_dict={x: x_batch})
            l = results[0]
            print('epoch {} / {} batch {} train loss {:.4f}'.format(epoch, n_epochs, i, l))
    
    # test
    results = sess.run([ loss ], feed_dict={x: x_batch})
    l = results[0]
    print('test loss {:.4f}'.format(l))
272/22:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 512,
        'n_head': 8,
        'n_layer': 12,
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 4,
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
272/23:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
272/24:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = tf.reduce_mean(results['gen_loss'])

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/25:
def count_parameters():
    total_parameters = 0
    for variable in tf.trainable_variables():
        shape = variable.get_shape()
        variable_parameters = 1
        for dim in shape:
            variable_parameters *= dim.value
        total_parameters += variable_parameters
    return total_parameters
272/26:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = tf.reduce_mean(results['gen_loss'])

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/27:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/attila/results/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:1000, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
272/28:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:1000, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
272/29:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
272/30:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = tf.reduce_mean(results['gen_loss'])

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/31:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            _results = sess.run([ loss ], feed_dict={x: x_batch})
            l = _results[0]
            print('epoch {} / {} batch {} train loss {:.4f}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
272/32:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            _results = sess.run([ loss ], feed_dict={x: x_batch})
            l = _results[0]
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
272/33:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/34:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            _results = sess.run([ loss ], feed_dict={x: x_batch})
            l = _results[0]
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
272/35:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 256,  # 512
        'n_head': 8,
        'n_layer': 12,  # 24
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 4,
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
272/36:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
272/37:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/38:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            # backprop
            sess.run([ train_op ], feed_dict={x: x_batch})
            
            # metrics
            _results = sess.run([ loss ], feed_dict={x: x_batch})
            l = _results[0]
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
272/39:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
272/40:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            print(x_batch.shape)
            _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
272/41:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:1024, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
272/42:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 256,  # 512
        'n_head': 8,
        'n_layer': 12,  # 24
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 128,
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
272/43:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
272/44:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
272/45:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
273/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
273/2:
import numpy as np
from matplotlib import pyplot as plt
from pathlib import Path


# In[ ]:


import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()


# In[ ]:


from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model, set_seed
from src.utils import AttrDict, load_pickle, iter_data
from src.model import model


# In[ ]:
273/3:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:1024, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
273/4:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 256,  # 512
        'n_head': 8,
        'n_layer': 12,  # 24
        'n_vocab': 256,  # grayscale image
        'bert': True,
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 16,  # 128
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
273/5:
_here = Path('.').resolve()
dataset = load_pickle(Path('~/scratch/minGPT_brain_data.pkl').expanduser())
X = np.expand_dims(dataset, axis=-1)  # grayscale images => 1 channel

X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:1024, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
273/6:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
n_class = 0  # NOT fine-tuning (for the moment)
273/7:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
273/8:
from src.run import H_CONFIG, IMAGE_GPT_CONFIGS, set_hparams, create_model, set_seed
from src.utils import AttrDict, load_pickle, iter_data, count_parameters
from src.model import model
273/9:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
273/10:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10
# saver = tf.train.Saver(var_list=trainable_params)

with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
    sess.run(tf.global_variables_initializer())  # init
    
    # train
    for epoch in range(n_epochs):
        for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
            _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
            print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
    
    # test
    _results = sess.run([ loss ], feed_dict={x: x_batch})
    l = _results[0]
    print('test loss {:.4f}'.format(l))
273/11:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 5

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
273/12:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
trainable_params = tf.trainable_variables()
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']

# logits = tf.reduce_mean(results['gen_logits'])
# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
273/13:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 5

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))

# test
_results = sess.run([ loss ], feed_dict={x: x_batch})
l = _results[0]
print('test loss {:.4f}'.format(l))
273/14: logits = results['gen_logits']
273/15: logits
273/16: from scipy.special import softmax
273/17:
samples = np.zeros([n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})

    for j in range(args.n_gpu):
        p = softmax(np_gen_logits[j][:, i, :], axis=-1)  # logits to probas
        
        for k in range(args.n_sub_batch):
            c = np.random.choice(n_vocab, p=p[k])  # choose based on probas
            samples[j * n_sub_batch + k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/18:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})

    for j in range(args.n_gpu):
        p = softmax(np_gen_logits[j][:, i, :], axis=-1)  # logits to probas
        
        for k in range(args.n_sub_batch):
            c = np.random.choice(n_vocab, p=p[k])  # choose based on probas
            samples[j * n_sub_batch + k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/19: np_gen_logits
273/20: np_gen_logits.shape
273/21:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})

    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits to probas

    for k in range(args.n_sub_batch):
        c = np.random.choice(n_vocab, p=p[k])  # choose based on probas
        samples[args.n_sub_batch + k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/22:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})

    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits to probas

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        samples[args.n_sub_batch + k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/23: np_gen_logits.shape
273/24: c
273/25: samples.shap
273/26: samples.shape
273/27:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        samples[k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/28: samples
273/29: samples.shape
273/30: samples.mean(axis=0)
273/31: samples.mean(axis=1)
273/32: samples.sum(axis=1)
273/33:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas, i.e the P distribution over the vocabs
    print('p', p)

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        print(c)
        samples[k, i] = c
273/34:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas, i.e the P distribution over the vocabs
    print('p', p, p.shape, p.sum(axis=1))

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        print(c)
        samples[k, i] = c
273/35: args.n_vocab
273/36: p
273/37: p.shape
273/38: p[k]
273/39: p[k].shape
273/40: np.random.choice(5, [0.1, 0.1, 0.4, 0.3, 0.1])
273/41: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/42: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/43: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/44: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/45: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/46: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/47: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/48: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/49: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/50: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/51: np.random.choice(5, p=[0.1, 0.1, 0.4, 0.3, 0.1])
273/52:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas, i.e the P distribution over the vocabs

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        samples[k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (s + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/53:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas, i.e the P distribution over the vocabs

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        samples[k, i] = c

# dequantize
samples = [np.reshape(np.rint(127.5 * (s + 1.0)), [args.n_px, args.n_px, 1]).astype(np.uint8) for s in samples]
273/54:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas, i.e the P distribution over the vocabs

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        samples[k, i] = c
273/55: samples.shape
273/56:
fig, axis = plt.subplots(4, 4, figsize=(5, 5))
for i, ax in enumerate(axis.ravel()):
    pxi = samples[i].view(args.n_px, args.n_px).numpy().astype(np.uint8)  # grayscale -> 2D

    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
273/57: samples[0]
273/58: samples[0].view(32, 32)
273/59: samples
273/60:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
trainable_params = tf.trainable_variables()
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']
logits = results['gen_logits']

# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
273/61:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 5

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
273/62:
samples = np.zeros([args.n_gpu * args.n_sub_batch, args.n_px * args.n_px], dtype=np.int32)

for i in range(args.n_px * args.n_px):
    np_gen_logits = sess.run(logits, feed_dict={x: samples})
    p = softmax(np_gen_logits[:, i, :], axis=-1)  # logits -> probas, i.e the P distribution over the vocabs

    for k in range(args.n_sub_batch):
        c = np.random.choice(args.n_vocab, p=p[k])  # choose based on probas
        samples[k, i] = c
273/63: samples[0].shape
273/64: samples[0].reshape(32, 32)
273/65:
fig, axis = plt.subplots(4, 4, figsize=(5, 5))
for i, ax in enumerate(axis.ravel()):
    pxi = samples[i].reshape(args.n_px, args.n_px)
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
273/66:
fig, axis = plt.subplots(4, 4, figsize=(5, 5))
for i, ax in enumerate(axis.ravel()):
    pxi = samples[i].reshape(args.n_px, args.n_px)
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('samples.png')
273/67:
IMAGE_GPT_CONFIGS = {
    's': {
        'n_ctx': 32 * 32,  # 32-pixel square image
        'n_embd': 256,  # 512
        'n_head': 8,
        'n_layer': 12,  # 24
        'n_vocab': 8,  # 256
        'bert': False,  # True
        'bert_mask_prob': 0.15,
        'clf': False,  # no classification fine-tuning
    }
}

H_CONFIG = {
    'data_path': './data/',
    'ckpt_path': './ckpt/',
    'color_cluster_path': './quants/',
    'save_dir': './results/',
    'n_sub_batch': 16,  # 128
    'n_gpu': 1,  # we are poor
    'n_px': 32,  # square image size in pixels
    'eval': False,  # not needed (for now)
    'sample': False,  # not needed (for now)
    'seed': 42,
    'train_epochs': 30
}
273/68:
args = AttrDict({ **H_CONFIG, **IMAGE_GPT_CONFIGS['s'] })
hparams = set_hparams(args)

set_seed(args.seed)
n_batch = args.n_sub_batch * args.n_gpu
273/69:
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])

results = model(hparams, x, reuse=False)
trainable_params = tf.trainable_variables()
print('trainable parameters: {}'.format(count_parameters()))

loss = results['gen_loss']
logits = results['gen_logits']

# prediction = tf.nn.softmax(logits)
# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(x, 1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

optimizer = tf.train.AdamOptimizer(learning_rate=3e-3)
train_op = optimizer.minimize(loss)
273/70:
X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:512, ...][..., 0]
X_test = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[-16:, ...][..., 0]

print('X ~', X.shape)
print('X feeded ~', X_train.shape)
273/71:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
273/72: X_train
273/73: X_train * 256
273/74: np.rint(X_train * 256)
273/75: X_train.shape
273/76:
X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:512, ...][..., 0]
X_train = np.rint(X_train * 256)
273/77:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
273/78:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
273/79: X_train = X.flatten().reshape(X.shape[0], X.shape[1] * X.shape[2], X.shape[-1])[:512, ...][..., 0]
273/80:
n_batch = args.n_sub_batch * args.n_gpu
n_epochs = 10

saver = tf.train.Saver(var_list=trainable_params)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))

sess.run(tf.global_variables_initializer())  # init

# train
for epoch in range(n_epochs):
    for i, x_batch in enumerate(iter_data(X_train, n_batch=n_batch, verbose=True)):
        _, l = sess.run([ train_op, loss ], feed_dict={x: x_batch})
        print('epoch {} / {} batch {} train loss {}'.format(epoch, n_epochs, i, l))
274/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
274/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
274/3:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)
274/4:
from mingpt.utils import set_seed

set_seed(42)  # make deterministic
274/5:
import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)
274/6:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
274/7:
dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
274/8:
from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
274/9:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """
    
    def __init__(self, pt_dataset, perm=None):
        self.pt_dataset = pt_dataset
        self.perm = torch.arange(flattened_image_size) if perm is None else perm  # raster image
        
        self.vocab_size = 256  # grayscale images
        self.block_size = flattened_image_size - 1
        
    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        return x[:-1], x[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset)
test_dataset = ImageDataset(t_test_dataset)
274/10:
from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,  # number of head self-attention
    n_embd=256  # d-dimensional embedding for each pixel
)
model = GPT(mconf)
274/11:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/12:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/13:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/14:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/15:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/16:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/17:
from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)
274/18:
def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 256  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
274/19:
# encode the training examples with our codebook to visualize how much we've lost in the discretization
# these images should look normal ideally

n_samples = 55
n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
    # encode and decode random data
    x, y = t_train_dataset[i]
    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel
    
    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
    ax.imshow(sample[..., 0], cmap='magma')
    ax.axis('off')
    
plt.savefig('results/clustered.png')
274/20:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = clusters.size(0)
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
274/21:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)
274/22:
from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,  # number of head self-attention
    n_embd=256  # d-dimensional embedding for each pixel
)
model = GPT(mconf)
274/23:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/24:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/25:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/26:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/27:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/28:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/29:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/30:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 30 # todo run a bigger model and longer, this is tiny

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
274/31:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
274/32:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
274/33:
from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU
274/34:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size, 0).numpy().astype(np.uint8)  # grayscale -> 2D
    
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
275/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
275/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
276/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
276/2:
import numpy as np
import torchvision
import torch
import matplotlib.pyplot as plt
from pathlib import Path
276/3:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


# In[5]:


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


# In[6]:


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


# In[7]:


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


# In[11]:


dataset = load_pickle(Path('~/scratch/attila/results/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
276/4:
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)


# In[5]:


from mingpt.utils import set_seed

set_seed(42)  # make deterministic


# In[6]:


import pickle

def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


# In[7]:


from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


# In[11]:


dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)
X = dataset[0]  # list of images
y = dataset[1]  # list of corresponding mask

pixel_size = X.shape[1]  # should be = X.shape[2] = 32
image_channels = X.shape[-1]  # should be = 1
flattened_image_size = pixel_size * pixel_size

# convert pixels to [0, 255] range
X = np.array(np.ceil(X * 255), dtype='float32')
y = np.array(np.ceil(y * 255), dtype='float32')

X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
276/5:
from torch.utils.data import TensorDataset, DataLoader

tensor_X_train = torch.Tensor(X_train)  # tensors
tensor_y_train = torch.Tensor(y_train)
tensor_X_test = torch.Tensor(X_test)
tensor_y_test = torch.Tensor(y_test)

t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)


# In[32]:


def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c


# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
n_pixels = 5
pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()

ncluster = 256  # grayscale images
with torch.no_grad():
    C = kmeans(px, ncluster, niter=8)
276/6:
from torch.utils.data import Dataset

class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)


# In[126]:


from mingpt.model import GPT, GPTConfig, GPT1Config

mconf = GPTConfig(
    train_dataset.vocab_size,
    train_dataset.block_size,
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,  # number of head self-attention
    n_embd=256  # d-dimensional embedding for each pixel
)
model = GPT(mconf)


# In[130]:


from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 1

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
276/7:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# In[128]:


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


# In[ ]:


from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU


# In[ ]:


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size, 0).numpy().astype(np.uint8)  # grayscale -> 2D
    
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
276/8:
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D
    
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
276/9: l
276/10: ls
276/11:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D
    
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
276/12:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 10

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
276/13:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
276/14:
# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1
276/15:
from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU
276/16:
# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D
    
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
276/17:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 10

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
276/18:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 10

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
276/19:
from mingpt.trainer import Trainer, TrainerConfig

tokens_per_epoch = len(train_dataset) * train_dataset.block_size
train_epochs = 10

# initialize a trainer instance and kick off training
checkpoint_path = './latest_model.pt'
tconf = TrainerConfig(
    max_epochs=train_epochs, 
    batch_size=4, 
    learning_rate=3e-3,
    betas=(0.9, 0.95), 
    weight_decay=0,
    lr_decay=True,
    warmup_tokens=tokens_per_epoch,
    final_tokens=train_epochs * tokens_per_epoch,
    ckpt_path=checkpoint_path,
    num_workers=1
)
trainer = Trainer(model, train_dataset, test_dataset, tconf)
trainer.train()  # WARNING: this blows CPU
276/20:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)


# In[128]:


# to sample we also have to technically "train" a separate model for the first token in the sequence
# we are going to do so below simply by calculating and normalizing the histogram of the first token

counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
rp = torch.randperm(len(train_dataset))
nest = X_train.shape[0] // 2  # how many images to use for the estimation
for i in range(nest):
    a, _ = train_dataset[int(rp[i])]
    t = a[0].item()  # index of first token in the sequence
    counts[t] += 1

prob = counts / counts.sum()  # normalize to have sum (prob) = 1


# In[ ]:


from mingpt.utils import sample

n_samples = 40
start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU


# In[ ]:


# for visualization we have to invert the permutation used to produce the pixels
iperm = torch.argsort(train_dataset.perm)

n_cols = 8
n_rows = n_samples // n_cols
fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
for i, ax in enumerate(axis.ravel()):
    pxi = pixels[i][iperm]  # undo the encoding permutation
    pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D
    
    ax.imshow(pxi, cmap='magma')
    ax.axis('off')

plt.savefig('results/samples.png')
276/21:
import numpy as np
import torchvision
import torch

# %matplotlib inline
import matplotlib.pyplot as plt

from pathlib import Path
import logging

logging.basicConfig(
  format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
  datefmt="%Y-%d-%d %H:%M:%S",
  level=logging.INFO,
)

import pickle
from sklearn.model_selection import train_test_split


# In[ ]:


from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset


# In[ ]:


from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

set_seed(42)  # make deterministic


# In[ ]:


def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


# In[ ]:


def get_data(file_path):
    load_pickle(Path(file_path).expanduser())  # list of (image, mask)
    X = dataset[0]  # list of images
    y = dataset[1]  # list of corresponding mask

    pixel_size = X.shape[1]  # should be = X.shape[2] = 32
    image_channels = X.shape[-1]  # should be = 1
    flattened_image_size = pixel_size * pixel_size

    # convert pixels to [0, 255] range
    X = np.array(np.ceil(X * 255), dtype='float32')
    y = np.array(np.ceil(y * 255), dtype='float32')

    X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)
    
    tensor_X_train = torch.Tensor(X_train)  # tensors
    tensor_y_train = torch.Tensor(y_train)
    tensor_X_test = torch.Tensor(X_test)
    tensor_y_test = torch.Tensor(y_test)

    t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
    t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)

    return t_train_dataset, t_test_dataset


# In[ ]:


def kmeans(x, ncluster, niter=10):
    N, D = x.size()
    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random
    for i in range(niter):
        # assign all pixels to the closest codebook element
        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)

        # move each codebook element to be the mean of the pixels that assigned to it
        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])

        # re-assign any poorly positioned codebook elements
        nanix = torch.any(torch.isnan(c), dim=1)
        ndead = nanix.sum().item()

        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))
        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters

    return c
  

def get_quantization(dataset, n_clusters=256, do_plot=False):
    # get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels
    n_pixels = 5
    pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]
    px = torch.cat([pluck_rgb(x) for x, y in dataset], dim=0).float()

    with torch.no_grad():
        C = kmeans(px, n_clusters, niter=8)
        
    if do_plot:  # to visualize how much we've lost in the discretization
        n_samples = 32
        n_cols = 8
        n_rows = n_samples // n_cols
        fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
        for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):
            # encode and decode random data
            x, y = t_train_dataset[i]
            xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)
            ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel

            sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)
            ax.imshow(sample[..., 0], cmap='magma')
            ax.axis('off')

        plt.savefig('results/clustered.png')
    
    return C


# In[ ]:


class ImageDataset(Dataset):
    """
    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers
    """

    def __init__(self, pt_dataset, clusters, perm=None):
        self.pt_dataset = pt_dataset
        self.clusters = clusters
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


# In[ ]:


def get_model():
    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=12,
        n_head=8,  # number of head self-attention
        n_embd=256  # d-dimensional embedding for each pixel
    )
    return GPT(mconf)
  

def train(model, n_epochs, train_dataset, test_dataset, checkpoint_path='./latest_model.pt'):
    tokens_per_epoch = len(train_dataset) * train_dataset.block_size
  
    # initialize a trainer instance and kick off training
    tconf = TrainerConfig(
        max_epochs=n_epochs, 
        batch_size=4, 
        learning_rate=3e-3,
        betas=(0.9, 0.95), 
        weight_decay=0,
        lr_decay=True,
        warmup_tokens=tokens_per_epoch,
        final_tokens=train_epochs * tokens_per_epoch,
        ckpt_path=checkpoint_path,
        num_workers=1
    )
    trainer = Trainer(model, train_dataset, test_dataset, tconf)
    trainer.train()  # WARNING: this blows CPU
    

def load(model, checkpoint_path='./results/latest_model.pt'):
    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
    model.load_state_dict(checkpoint)
    return model

    
def sample(model, n_samples=40, out_path='./results/samples.png'):
    # to sample we also have to technically "train" a separate model for the first token in the sequence
    # we are going to do so below simply by calculating and normalizing the histogram of the first token

    counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(train_dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation
    for i in range(nest):
        a, _ = train_dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[t] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    
    start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU
    
    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(train_dataset.perm)

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
276/22:
t_train_dataset, t_test_dataset = get_data('~/martin/minGPT_data.pkl')
C = get_quantization(t_train_dataset)
276/23:
train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)

model = get_model()
276/24: train(model, 30, train_dataset, test_dataset)
276/25:
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping
model.load_state_dict(checkpoint)
276/26: sample(model)
276/27: from mingpt.utils import set_seed, sample
276/28:
def sample_some(model, n_samples=40, out_path='./results/samples.png'):
    # to sample we also have to technically "train" a separate model for the first token in the sequence
    # we are going to do so below simply by calculating and normalizing the histogram of the first token

    counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(train_dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation
    for i in range(nest):
        a, _ = train_dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[t] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    
    start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU
    
    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(train_dataset.perm)

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
276/29: sample_some(model)
276/30: sample_some(model)
276/31:
def get_model():
    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_XS
        bert=True,
    )
    return GPT(mconf)
  

def train(model, n_epochs, train_dataset, test_dataset, checkpoint_path):
    tokens_per_epoch = len(train_dataset) * train_dataset.block_size
  
    # initialize a trainer instance and kick off training
    tconf = TrainerConfig(
        max_epochs=n_epochs, 
        batch_size=4, 
        learning_rate=3e-3,
        betas=(0.9, 0.95), 
        weight_decay=0,
        lr_decay=True,
        warmup_tokens=tokens_per_epoch,
        final_tokens=train_epochs * tokens_per_epoch,
        ckpt_path=checkpoint_path,
        num_workers=1
    )
    trainer = Trainer(model, train_dataset, test_dataset, tconf)
    trainer.train()  # WARNING: this blows CPU

    
def sample_some(model, n_samples=40, out_path='./results/samples.png'):
    # to sample we also have to technically "train" a separate model for the first token in the sequence
    # we are going to do so below simply by calculating and normalizing the histogram of the first token

    counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(train_dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation
    for i in range(nest):
        a, _ = train_dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[t] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    
    start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU
    
    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(train_dataset.perm)

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
276/32:
GPT_XS = dict(
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=12,
    n_head=8,
    n_embd=256  
)

GPT_S = dict(
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512   
)


def get_model():
    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_XS,
        bert=True,
    )
    return GPT(mconf)
  

def train(model, n_epochs, train_dataset, test_dataset, checkpoint_path):
    tokens_per_epoch = len(train_dataset) * train_dataset.block_size
  
    # initialize a trainer instance and kick off training
    tconf = TrainerConfig(
        max_epochs=n_epochs, 
        batch_size=4, 
        learning_rate=3e-3,
        betas=(0.9, 0.95), 
        weight_decay=0,
        lr_decay=True,
        warmup_tokens=tokens_per_epoch,
        final_tokens=train_epochs * tokens_per_epoch,
        ckpt_path=checkpoint_path,
        num_workers=1
    )
    trainer = Trainer(model, train_dataset, test_dataset, tconf)
    trainer.train()  # WARNING: this blows CPU

    
def sample_some(model, n_samples=40, out_path='./results/samples.png'):
    # to sample we also have to technically "train" a separate model for the first token in the sequence
    # we are going to do so below simply by calculating and normalizing the histogram of the first token

    counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(train_dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation
    for i in range(nest):
        a, _ = train_dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[t] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    
    start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU
    
    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(train_dataset.perm)

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = C[pxi].view(pixel_size, pixel_size).numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
276/33:
t_train_dataset, t_test_dataset = get_data('~/martin/minGPT_data.pkl')
C = get_quantization(t_train_dataset)

train_dataset = ImageDataset(t_train_dataset, C)
test_dataset = ImageDataset(t_test_dataset, C)

model = get_model()

checkpoint_path = './latest_model.pt'
train(model, 10, train_dataset, test_dataset, checkpoint_path)
276/34:
checkpoint_path = './latest_model.pt'
train(model, 30, train_dataset, test_dataset, checkpoint_path)
277/1:
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    BatchNormalization,
    Conv2D,
    Conv2DTranspose,
    MaxPooling2D,
    Dropout,
    SpatialDropout2D,
    UpSampling2D,
    Input,
    concatenate,
    multiply,
    add,
    Activation,
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
277/2:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
277/3:
from pathlib import Path
from PIL import Image
import cv2 as cv
import numpy as np
import pickle
277/4:
import numpy as np
from nd2reader import ND2Reader
import h5py
277/5:
import numpy as np
import pickle
277/6:
def load_pickle(f_path):
    with open(f_path, 'rb') as fp: 
        return pickle.load(fp)
      
def stuff2pickle(stuff, f_path):
    with open(f_path, 'wb') as fp: 
        pickle.dump(stuff, fp)
277/7:
# from https://github.com/karolzak/keras-unet

def upsample_conv(filters, kernel_size, strides, padding):
    return Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)


def upsample_simple(filters, kernel_size, strides, padding):
    return UpSampling2D(strides)


def attention_gate(inp_1, inp_2, n_intermediate_filters):
    """Attention gate. Compresses both inputs to n_intermediate_filters filters before processing.
       Implemented as proposed by Oktay et al. in their Attention U-net, see: https://arxiv.org/abs/1804.03999.
    """
    inp_1_conv = Conv2D(
        n_intermediate_filters,
        kernel_size=1,
        strides=1,
        padding="same",
        kernel_initializer="he_normal",
    )(inp_1)
    inp_2_conv = Conv2D(
        n_intermediate_filters,
        kernel_size=1,
        strides=1,
        padding="same",
        kernel_initializer="he_normal",
    )(inp_2)

    f = Activation("relu")(add([inp_1_conv, inp_2_conv]))
    g = Conv2D(
        filters=1,
        kernel_size=1,
        strides=1,
        padding="same",
        kernel_initializer="he_normal",
    )(f)
    h = Activation("sigmoid")(g)
    return multiply([inp_1, h])


def attention_concat(conv_below, skip_connection):
    """Performs concatenation of upsampled conv_below with attention gated version of skip-connection
    """
    below_filters = conv_below.get_shape().as_list()[-1]
    attention_across = attention_gate(skip_connection, conv_below, below_filters)
    return concatenate([conv_below, attention_across])


def conv2d_block(
    inputs,
    use_batch_norm=True,
    dropout=0.3,
    dropout_type="spatial",
    filters=16,
    kernel_size=(3, 3),
    activation="relu",
    kernel_initializer="he_normal",
    padding="same",
):

    if dropout_type == "spatial":
        DO = SpatialDropout2D
    elif dropout_type == "standard":
        DO = Dropout
    else:
        raise ValueError(
            f"dropout_type must be one of ['spatial', 'standard'], got {dropout_type}"
        )

    c = Conv2D(
        filters,
        kernel_size,
        activation=activation,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=not use_batch_norm,
    )(inputs)
    if use_batch_norm:
        c = BatchNormalization()(c)
    if dropout > 0.0:
        c = DO(dropout)(c)
    c = Conv2D(
        filters,
        kernel_size,
        activation=activation,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=not use_batch_norm,
    )(c)
    if use_batch_norm:
        c = BatchNormalization()(c)
    return c


def custom_unet(
    input_shape,
    num_classes=1,
    activation="relu",
    use_batch_norm=True,
    upsample_mode="deconv",  # 'deconv' or 'simple'
    dropout=0.3,
    dropout_change_per_layer=0.0,
    dropout_type="spatial",
    use_dropout_on_upsampling=False,
    use_attention=False,
    filters=16,
    num_layers=4,
    output_activation="sigmoid",
):
    if upsample_mode == "deconv":
        upsample = upsample_conv
    else:
        upsample = upsample_simple

    # Build U-Net model
    inputs = Input(input_shape)
    x = inputs

    down_layers = []
    for l in range(num_layers):
        x = conv2d_block(
            inputs=x,
            filters=filters,
            use_batch_norm=use_batch_norm,
            dropout=dropout,
            dropout_type=dropout_type,
            activation=activation,
        )
        down_layers.append(x)
        x = MaxPooling2D((2, 2))(x)
        dropout += dropout_change_per_layer
        filters = filters * 2  # double the number of filters with each layer

    x = conv2d_block(
        inputs=x,
        filters=filters,
        use_batch_norm=use_batch_norm,
        dropout=dropout,
        dropout_type=dropout_type,
        activation=activation,
    )

    if not use_dropout_on_upsampling:
        dropout = 0.0
        dropout_change_per_layer = 0.0

    for conv in reversed(down_layers):
        filters //= 2  # decreasing number of filters with each layer
        dropout -= dropout_change_per_layer
        x = upsample(filters, (2, 2), strides=(2, 2), padding="same")(x)
        if use_attention:
            x = attention_concat(conv_below=x, skip_connection=conv)
        else:
            x = concatenate([x, conv])
        x = conv2d_block(
            inputs=x,
            filters=filters,
            use_batch_norm=use_batch_norm,
            dropout=dropout,
            dropout_type=dropout_type,
            activation=activation,
        )

    outputs = Conv2D(num_classes, (1, 1), activation=output_activation)(x)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model
277/8: X, y = load_pickle('/home/stfo194b/scratch/wow.pkl')
277/9: X
277/10: X.shape
277/11: y.shape
277/12:
from sklearn.model_selection import train_test_split

def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )   

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
277/13: import elasticdeform
277/14: !pip install elasticdeform
277/15: import elasticdeform
277/16: X_train, X_test, y_train, y_test = get_train_test_split(X, y, test_size=0.1, verbose=True)
277/17: from skimage.exposure import match_histograms
277/18:
some = np.random.randint(0, len(X_train), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

points = 4
sigma = 10
displacement = np.random.randn(2, points, points) * sigma

  
for ax, i in zip(axis.ravel(), some):
    deform = elastic_deform(displacement)
  
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    masked = deform(masked)

    ax.imshow(worm, cmap='magma')
    ax.contour(masked, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('rfd.png')
277/19:
def get_figsize(n_rows, n_cols):
    row_size = 8  # heigth
    column_size = 5  # width

    return (n_cols * column_size, n_rows * row_size)


def get_figa(n_rows, n_cols):
    fig, ax = plt.subplots(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols))
    return fig, ax
277/20:
some = np.random.randint(0, len(X_train), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

points = 4
sigma = 10
displacement = np.random.randn(2, points, points) * sigma

  
for ax, i in zip(axis.ravel(), some):
    deform = elastic_deform(displacement)
  
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    masked = deform(masked)

    ax.imshow(worm, cmap='magma')
    ax.contour(masked, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('rfd.png')
277/21:
def get_figsize(n_rows, n_cols, row_size=4, column_size=10):
    row_size = row_size  # heigth
    column_size = column_size  # width

    return (n_cols * column_size, n_rows * row_size)


def get_figa(n_rows, n_cols, figsize=None):
    if not figsize:
        figsize = get_figsize(n_rows, n_cols)
    
    fig, ax = plt.subplots(n_rows, n_cols, figsize=figsize)
    return fig, ax
277/22:
some = np.random.randint(0, len(X_train), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

points = 4
sigma = 10
displacement = np.random.randn(2, points, points) * sigma

  
for ax, i in zip(axis.ravel(), some):
    deform = elastic_deform(displacement)
  
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    masked = deform(masked)

    ax.imshow(worm, cmap='magma')
    ax.contour(masked, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('rfd.png')
277/23: import matplotlib.pyplot as plt
277/24:
some = np.random.randint(0, len(X_train), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

points = 4
sigma = 10
displacement = np.random.randn(2, points, points) * sigma

  
for ax, i in zip(axis.ravel(), some):
    deform = elastic_deform(displacement)
  
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    masked = deform(masked)

    ax.imshow(worm, cmap='magma')
    ax.contour(masked, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('rfd.png')
277/25:
def elastic_deform(displacement):

    def _f(img):
        out = elasticdeform.deform_grid(img, displacement)
        out[out < 0] = 0
        return out
    
    return _f
277/26:
some = np.random.randint(0, len(X_train), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

points = 4
sigma = 10
displacement = np.random.randn(2, points, points) * sigma

  
for ax, i in zip(axis.ravel(), some):
    deform = elastic_deform(displacement)
  
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    masked = deform(masked)

    ax.imshow(worm, cmap='magma')
    ax.contour(masked, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('rfd.png')
277/27:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid')
277/28:
model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', 'iou']
)
277/29:
n_epochs = 10
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=8,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
277/30:
model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/31:
n_epochs = 10
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=8,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
277/32: y_pred = model.predict(X_test)
277/33: y_pred.shape
277/34:
some = np.random.randint(0, len(y_pred), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))
  
for ax, i in zip(axis.ravel(), some):
    pred = y_pred[i]
    true = y_test[i]

    ax.imshow(pred, cmap='magma')
    ax.contour(true, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('pred.png')
277/35: y_pred.shape
277/36:
some = np.random.randint(0, len(y_pred), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))
  
for ax, i in zip(axis.ravel(), some):
    pred = y_pred[i][..., 0]
    true = y_test[i]

    ax.imshow(pred, cmap='magma')
    ax.contour(true, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('pred.png')
277/37:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/38:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=2,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy]
)
277/39:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=2,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/40:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/41:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/42:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/43:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/44:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/45:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/46:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    upsample_mode='simple',
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-6),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/47:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/48:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-7),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/49:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/50:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    upsample_mode='simple',
    num_classes=1,
    filters=16,
    use_attention=False,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/51:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/52:
some = np.random.randint(0, len(y_pred), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))
  
for ax, i in zip(axis.ravel(), some):
    pred = y_pred[i][..., 0]
    true = y_test[i]

    ax.imshow(pred, cmap='magma')
    ax.contour(true, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('pred.png')
277/53:
some = np.random.randint(0, len(y_pred), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))
  
for ax, i in zip(axis.ravel(), some):
    pred = y_pred[i][..., 0]
    true = y_test[i]

    ax.imshow(pred, cmap='magma')
    ax.contour(true, colors='blue', levels=[0.5])
    ax.axis('off')

plt.savefig('pred.png')
277/54:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=16,
    use_attention=True,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/55:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/56:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=16,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/57:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/58:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=32,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/59:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/60:
some = np.random.randint(0, len(y_pred), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))
  
for ax, i in zip(axis.ravel(), some):
    pred = y_pred[i][..., 0]
    true = y_test[i]

    ax.imshow(pred, cmap='magma')
    ax.contour(true, colors='blue', levels=[0.5])
    ax.axis('off')

plt.savefig('pred.png')
277/61:
model = custom_unet(
    input_shape=(112, 112, 1),
    use_batch_norm=True,
    num_classes=1,
    filters=32,
    dropout=0.2,
    output_activation='sigmoid'
)


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)
277/62:
n_epochs = 20
weights_file = 'best_model.keras'

model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
y_pred = model.predict(X_test)
277/63:
def build_model()
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=True,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
277/64:
def build_model():
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=True,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
277/65:
def build_model():
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=True,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
  

def train(n_epochs):
    weights_file = 'best_model.keras'

    model.fit(
        X_train, y_train,
        batch_size=16,
        epochs=n_epochs,
        verbose=True,
        callbacks = [ 
            EarlyStopping(
                monitor='loss',
                patience=int(n_epochs / 2),  # run at least half epochs
                verbose=True
            ),  
            ReduceLROnPlateau(
                factor=1e-1, 
                patience=5,  # no time to waste
                min_lr=1e-5,
                verbose=True
            ),
            ModelCheckpoint(
                weights_file,
                monitor='loss',
                verbose=True,
                save_best_only=True,
                save_weights_only=True
            )
        ]
    )
    y_pred = model.predict(X_test)
    return y_pred
  

def test():
    some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='blue', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
277/66:
model = build_model()
train(20)
test()
277/67:
def train(n_epochs, batch_size):
    weights_file = 'best_model.keras'

    model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=n_epochs,
        verbose=True,
        callbacks = [ 
            EarlyStopping(
                monitor='loss',
                patience=int(n_epochs / 2),  # run at least half epochs
                verbose=True
            ),  
            ReduceLROnPlateau(
                factor=1e-1, 
                patience=5,  # no time to waste
                min_lr=1e-5,
                verbose=True
            ),
            ModelCheckpoint(
                weights_file,
                monitor='loss',
                verbose=True,
                save_best_only=True,
                save_weights_only=True
            )
        ]
    )
    y_pred = model.predict(X_test)
    return y_pred
277/68:
model = build_model()
train(20, 4)
test()
277/69:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
277/70:
build_model(False)
train(50, 16)
test()
277/71: y_pred = model.predict(X_test)
277/72:
some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='blue', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
277/73: test()
277/74:
def test():
    some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='red', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
277/75: test()
277/76:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
  

def train(n_epochs, batch_size):
    weights_file = 'best_model.keras'

    model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=n_epochs,
        verbose=True,
        callbacks = [ 
            EarlyStopping(
                monitor='loss',
                patience=int(n_epochs / 2),  # run at least half epochs
                verbose=True
            ),  
            ReduceLROnPlateau(
                factor=1e-1, 
                patience=5,  # no time to waste
                min_lr=1e-5,
                verbose=True
            ),
            ModelCheckpoint(
                weights_file,
                monitor='loss',
                verbose=True,
                save_best_only=True,
                save_weights_only=True
            )
        ]
    )
    y_pred = model.predict(X_test)
  

def test():
    some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='red', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
277/77:
points = 4
sigma = 10
displacement = np.random.randn(2, points, points) * sigma

X_def = X_train.copy()
y_def = y_train.copy()

for i in range(len(X_train)):
    deform = elastic_deform(displacement)
    
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    
    masked = deform(masked)
    
    X_def[i] = worm
    y_def[i] = masked
277/78: X_def.shape
277/79: X_train.shape
277/80:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
  

def train(X_train, y_train, n_epochs, batch_size):
    weights_file = 'best_model.keras'

    model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=n_epochs,
        verbose=True,
        callbacks = [ 
            EarlyStopping(
                monitor='loss',
                patience=int(n_epochs / 2),  # run at least half epochs
                verbose=True
            ),  
            ReduceLROnPlateau(
                factor=1e-1, 
                patience=5,  # no time to waste
                min_lr=1e-5,
                verbose=True
            ),
            ModelCheckpoint(
                weights_file,
                monitor='loss',
                verbose=True,
                save_best_only=True,
                save_weights_only=True
            )
        ]
    )
    y_pred = model.predict(X_test)
  

def test(y_test):
    some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='red', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
277/81:
build_model()
train(X_def, y_def, 50, 16)
test(y_test)
277/82:
build_model(False)
train(X_def, y_def, 50, 16)
test(y_test)
277/83: y_pred = model.predict(X_test)
277/84: test()
277/85: test(y_test)
277/86:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
  

def train(X_train, y_train, n_epochs, batch_size):
    weights_file = 'best_model.keras'

    model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=n_epochs,
        verbose=True,
        callbacks = [ 
            EarlyStopping(
                monitor='loss',
                patience=int(n_epochs / 2),  # run at least half epochs
                verbose=True
            ),  
            ReduceLROnPlateau(
                factor=1e-1, 
                patience=5,  # no time to waste
                min_lr=1e-5,
                verbose=True
            ),
            ModelCheckpoint(
                weights_file,
                monitor='loss',
                verbose=True,
                save_best_only=True,
                save_weights_only=True
            )
        ]
    )
    y_pred = model.predict(X_test)
    return y_pred
  

def test(y_test):
    some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='red', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
277/87:
points = 4
sigma = 100
displacement = np.random.randn(2, points, points) * sigma

X_def = X_train.copy()
y_def = y_train.copy()

for i in range(len(X_train)):
    deform = elastic_deform(displacement)
    
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    
    masked = deform(masked)
    
    X_def[i] = worm
    y_def[i] = masked
277/88:
model = build_model(False)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/89:
some = np.random.randint(0, len(X_train), 32)
n_cols = 8
n_rows = len(some) // n_cols
fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

points = 4
sigma = 100
displacement = np.random.randn(2, points, points) * sigma

# X_def = X_train.copy()
# y_def = y_train.copy()

# for i in range(len(X_train)):
#     deform = elastic_deform(displacement)
    
#     worm = X_train[i]
#     masked = y_train[i]
    
#     worm = deform(worm)
#     worm = match_histograms(worm, X_train[i], multichannel=False)
    
#     masked = deform(masked)
    
#     X_def[i] = worm
#     y_def[i] = masked
    
  
for ax, i in zip(axis.ravel(), some):
    deform = elastic_deform(displacement)
  
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    masked = deform(masked)

    ax.imshow(worm, cmap='magma')
    ax.contour(masked, colors='white', levels=[0.5])
    ax.axis('off')

plt.savefig('rfd.png')
277/90:
points = 3
sigma = 9

X_def = X_train.copy()
y_def = y_train.copy()

for i in range(len(X_train)):
    displacement = np.random.randn(2, points, points) * sigma
    deform = elastic_deform(displacement)
    
    worm = X_train[i]
    masked = y_train[i]
    
    worm = deform(worm)
    worm = match_histograms(worm, X_train[i], multichannel=False)
    
    masked = deform(masked)
    
    X_def[i] = worm
    y_def[i] = masked
277/91:
model = build_model(False)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/92:
model = build_model(False)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/93:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=24,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
277/94:
model = build_model(False)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/95:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=24,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
277/96:
model = build_model(True)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/97:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=False,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
277/98:
model = build_model(True)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/99:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=True,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
277/100:
model = build_model(False)
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/101:
model = build_model(False)
y_pred = train(X_def, y_def, 50, 4)
test(y_test)
277/102:
model = build_model(False)
y_pred = train(X_def, y_def, 200, 4)
test(y_test)
277/103:
y_pred = train(X_def, y_def, 50, 16)
test(y_test)
277/104: test(y_test)
277/105:
model = build_model(True)
y_pred = train(X_def, y_def, 50, 32)
test(y_test)
277/106:
def build_model(use_batch_norm):
    model = custom_unet(
        input_shape=(112, 112, 1),
        use_batch_norm=use_batch_norm,
        num_classes=1,
        filters=32,
        use_attention=True,
        dropout=0.2,
        output_activation='sigmoid'
    )


    model.compile(
        optimizer=Adam(learning_rate=2e-5),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
  

def train(X_train, y_train, n_epochs, batch_size):
    weights_file = 'best_model.keras'

    model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=n_epochs,
        verbose=True,
        callbacks = [ 
            EarlyStopping(
                monitor='loss',
                patience=int(n_epochs / 2),  # run at least half epochs
                verbose=True
            ),  
            ReduceLROnPlateau(
                monitor='accuracy',
                factor=1e-1, 
                patience=5,  # no time to waste
                min_lr=1e-5,
                verbose=True
            ),
            ModelCheckpoint(
                weights_file,
                monitor='loss',
                verbose=True,
                save_best_only=True,
                save_weights_only=True
            )
        ]
    )
    y_pred = model.predict(X_test)
    return y_pred
  

def test(y_test):
    some = np.random.randint(0, len(y_pred), 32)
    n_cols = 8
    n_rows = len(some) // n_cols
    fig, axis = get_figa(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols, column_size=5))

    for ax, i in zip(axis.ravel(), some):
        pred = y_pred[i][..., 0]
        true = y_test[i]

        ax.imshow(pred, cmap='magma')
        ax.contour(true, colors='red', levels=[0.5])
        ax.axis('off')

    plt.savefig('pred.png')
278/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
278/2:
import numpy as np
import pickle

%matplotlib inline
from matplotlib import pyplot as plt
278/3:
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Flatten, BatchNormalization, Activation, Dropout, multiply, concatenate, Dense

from tensorflow.keras.layers import MaxPooling2D, Conv2D, UpSampling2D, Cropping2D, GlobalAveragePooling2D
from tensorflow.keras.layers import MaxPooling1D, Conv1D, UpSampling1D, Cropping1D, GlobalAveragePooling1D

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
278/4:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )   

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
  
  
def build_dataset(time_ints, size):
    starts = np.random.randint(100, 300, size=size)
    X = np.zeros((size, time_ints))
    y = np.zeros((size, 1))
    
    for i, start in enumerate(starts):
        diff = time_ints + 1
        sign = np.random.choice([+1, -1])
        end = start + sign * diff
      
        interval = np.array(list(range(start, end, sign)))
        full = interval + 10.0 * np.sin(interval) + [ np.random.normal(0, 3) for _ in range(len(interval)) ]

        X[i] = full[:-1]
        y[i] = full[-1]
        
    X = X.reshape([size, time_ints, 1])
    y = y.reshape([size, 1, 1])
    
    return get_train_test_split(X, y, 0.3, verbose=True)


X_train, X_test, y_train, y_test = build_dataset(32, 52)
278/5:
conv = Conv1D
avg_pool = GlobalAveragePooling1D
max_pool = MaxPooling1D
up_sampling = UpSampling1D
crop = Cropping1D

n_dim = 1

inp_shape = lambda x: x.shape[1:] if n_dim == 1 else x.shape
278/6:
def conv_block(n_filters, kernel_shape, padding, use_se_block, dropout=0.0, batchnorm=True, inner_layers=1):
    activation = 'relu'

    def _f(x):
        for _ in range(inner_layers):
            if batchnorm:
                x = BatchNormalization()(x)

            x = conv(
                n_filters,
                kernel_shape,
                padding=padding,
                activation=activation,
                input_shape=inp_shape(x)
            )(x)

            if dropout > 0:
                x = Dropout(dropout)(x)

        if use_se_block:
            x = se_block()(x)

        return x

    return _f


def se_block(r=16.0):
    def squeeze(x):
        return avg_pool()(x)

    def fc(n_filters, activation):
        def _f(x):
            return Dense(n_filters, activation=activation, use_bias=False)(x)

        return _f

    def excite(x, n_channels, r):
        x = fc(n_channels // r, 'relu')(x)
        x = fc(n_channels, 'sigmoid')(x)
        return x

    def _f(x):
        n_channels = x.shape[-1]

        inp = x  # save for later
        x = squeeze(x)
        x = excite(x, n_channels, r)
        return multiply([inp, x])

    return _f
278/7:
def contracting_block(n_filters, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm, conv_inner_layers):
    pooling = max_pool(pool_shape)

    def _f(x):
        x = conv_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm, inner_layers=conv_inner_layers)(x)
        skip_conn = x  # save for expanding path
        x = pooling(x)  # ready for next block
        return x, skip_conn

    return _f


def contracting_path(n_filters, n_layers, kernel_shape, pool_shape, use_skip_conn, padding, use_se_block, dropout, batchnorm, conv_inner_layers, filter_mult):
    def _f(x):
        skip_conns = []
        current_n_filters = n_filters

        for _ in range(n_layers):
            x, s = contracting_block(
                current_n_filters,
                kernel_shape,
                pool_shape,
                padding,
                use_se_block,
                dropout,
                batchnorm,
                conv_inner_layers
            )(x)
            current_n_filters = int(current_n_filters * filter_mult)

            if not use_skip_conn:
                s = None  # not to be used

            skip_conns.append(s)

        return x, skip_conns

    return _f
278/8:
def middle_block(kernel_shape, padding, dropout, batchnorm, conv_inner_layers, filter_mult):
    use_se_block = False

    def _f(x):
        n_filters = int(x.shape[-1] * filter_mult)
        x = conv_block(n_filters, kernel_shape, padding, use_se_block, dropout, batchnorm, inner_layers=conv_inner_layers)(x)
        return x

    return _f
278/9:
def g(n):
    if n <= 1:
        return 2

    return g(n - 1) * 2 + 4  # very MAGIC formula, aka 2^(n-1) + 2^(n-2) -1


def calc_crop_size(layer, conv_layers, conv_size, padding):
    if padding == 'valid':
        conv_crop = conv_layers * (conv_size - 1)
        return int(conv_crop * g(layer))

    return 0

  
def up_conv(pool_shape, conv_args, using_skip_conn):
    if n_dim == 1:
        upsampling = up_sampling(pool_shape[0])
    else:
        upsampling = up_sampling(pool_shape)

    def _f(x):
        x = upsampling(x)

        if using_skip_conn:
            x = conv_block(**conv_args)(x)

        return x

    return _f
  

def expanding_block(n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm, conv_inner_layers):

    def _f(x):
        if use_se_block:
            x = se_block()(x)

        using_skip_conn = not (skip_conn is None)
        x = up_conv(
            pool_shape,
            dict(
                n_filters=n_filters,
                kernel_shape=kernel_shape,
                padding='same',
                use_se_block=use_se_block,
                dropout=dropout,
                batchnorm=batchnorm,
                inner_layers=conv_inner_layers
            ),
            using_skip_conn=using_skip_conn
        )(x)

        if using_skip_conn:
            x = concatenate([x, skip_conn])

        x = conv_block(
            n_filters,
            kernel_shape,
            padding,
            use_se_block,
            dropout,
            batchnorm,
            inner_layers=conv_inner_layers
        )(x)

        return x

    return _f


def expanding_path(n_filters, skip_conns, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm, conv_inner_layers, filter_mult):
    def _f(x):
        current_n_filters = n_filters

        for i, skip_conn in enumerate(reversed(skip_conns)):
            using_skip_conn = not (skip_conn is None)
            if using_skip_conn:
                crop_size = calc_crop_size(i + 1, 2, kernel_shape[0], padding)
                crop_size = int(crop_size / 2)  # side by side
                skip_conn = crop(crop_size)(skip_conn)

            x = expanding_block(current_n_filters, skip_conn, kernel_shape, pool_shape, padding, use_se_block, dropout, batchnorm, conv_inner_layers)(x)
            current_n_filters = int(current_n_filters / filter_mult)

        return x

    return _f
278/10:
def final_path(n_classes, activation, padding, use_se_block):
    n_channel_out = n_classes

    def _f(x):
        if use_se_block:
            x = se_block()(x)

        x = conv(
            n_channel_out,
            (1, ) * n_dim,
            padding=padding,
            activation=activation
        )(x)
        
        x = Flatten()(x)
        x = Dense(units=100)(x)
        x = Dense(units=1)(x)

        return x

    return _f
278/11:
def unet_block(n_filters, n_layers, kernel_shape, pool_shape, n_classes, final_activation, padding, use_skip_conn, use_se_block, dropout, batchnorm, conv_inner_layers, filter_mult):
    def _f(x):
        x, skip_conns = contracting_path(
            n_filters,
            n_layers,
            kernel_shape,
            pool_shape,
            use_skip_conn,
            padding,
            use_se_block,
            dropout,
            batchnorm,
            conv_inner_layers,
            filter_mult
        )(x)
        
        x = middle_block(
            kernel_shape,
            padding,
            dropout,
            batchnorm,
            conv_inner_layers,
            filter_mult
        )(x)

        current_n_filters = n_filters * filter_mult ** (n_layers - 1)

        x = expanding_path(
            current_n_filters,
            skip_conns,
            kernel_shape,
            pool_shape,
            padding,
            use_se_block,
            dropout,
            batchnorm,
            conv_inner_layers,
            filter_mult
        )(x)

        x = final_path(n_classes, final_activation, padding, use_se_block)(x)
        return x

    return _f


def build_unet(inp_shape, n_filters, n_layers, kernel_size, pool_size, n_classes, final_activation, padding='same', use_skip_conn=True, use_se_block=False, dropout=0.0, batchnorm=False, conv_inner_layers=2, filter_mult=2):
    kernel_shape = (kernel_size, ) * n_dim
    pool_shape = (pool_size, ) * n_dim

    inp = Input(inp_shape)
    out = unet_block(
        n_filters,
        n_layers,
        kernel_shape,
        pool_shape,
        n_classes,
        final_activation,
        padding,
        use_skip_conn,
        use_se_block,
        dropout,
        batchnorm,
        conv_inner_layers,
        filter_mult
    )(inp)

    model = Model(inputs=inp, outputs=out)
    return model
278/12:
n_timesteps = 32

model_args = dict(
    inp_shape=(n_timesteps, 1),
    n_filters=16,
    n_layers=2,
    kernel_size=3,
    pool_size=2,
    n_classes=50,
    final_activation='linear',
    padding='same',
    use_skip_conn=True,
    use_se_block=True,
    dropout=0.0,  # todo try with higher n epochs
    batchnorm=False,  # todo try with higher n epochs
    conv_inner_layers=4,
    filter_mult=3,
)
  
model = build_unet(**model_args)
model.compile(
    optimizer='adam',
    loss='mse',  # todo penalize up/down shifts
)

# model.summary()
278/13: model.summary()
278/14: model.summary()
278/15:
n_timesteps = 32

model_args = dict(
    inp_shape=(n_timesteps, 1),
    n_filters=16,
    n_layers=4,
    kernel_size=3,
    pool_size=2,
    n_classes=50,
    final_activation='linear',
    padding='same',
    use_skip_conn=True,
    use_se_block=True,
    dropout=0.0,  # todo try with higher n epochs
    batchnorm=False,  # todo try with higher n epochs
    conv_inner_layers=4,
    filter_mult=3,
)
  
model = build_unet(**model_args)
model.compile(
    optimizer='adam',
    loss='mse',  # todo penalize up/down shifts
)

# model.summary()
278/16:
model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=200
)
278/17:
y_pred = model.predict(X_test)

for p, x, y in zip(y_pred.ravel(), X_test, y_test.ravel()):
    x = x.ravel()
  
    delta = abs(p - y)
    rel_delta = abs(delta / y) if t != 0 else 0
    perc_delta = 100.0 * rel_delta
    std = np.std(x)
    Dstd = delta / std
    
    print('{:.3f} (VS {:.3f}, std = {:.3f}) ~ {:.3f} ({:.3f}, {:.3f} %)'.format(p, y, std, delta, Dstd, perc_delta))
278/18:
y_pred = model.predict(X_test)

for p, x, y in zip(y_pred.ravel(), X_test, y_test.ravel()):
    x = x.ravel()
  
    delta = abs(p - y)
    rel_delta = abs(delta / y) if y != 0 else 0
    perc_delta = 100.0 * rel_delta
    std = np.std(x)
    Dstd = delta / std
    
    print('{:.3f} (VS {:.3f}, std = {:.3f}) ~ {:.3f} ({:.3f}, {:.3f} %)'.format(p, y, std, delta, Dstd, perc_delta))
278/19:
n_timesteps = 32

model_args = dict(
    inp_shape=(n_timesteps, 1),
    n_filters=32,
    n_layers=4,
    kernel_size=3,
    pool_size=2,
    n_classes=100,
    final_activation='linear',
    padding='same',
    use_skip_conn=True,
    use_se_block=True,
    dropout=0.0,  # todo try with higher n epochs
    batchnorm=False,  # todo try with higher n epochs
    conv_inner_layers=4,
    filter_mult=3,
)
  
model = build_unet(**model_args)
model.compile(
    optimizer='adam',
    loss='mse',  # todo penalize up/down shifts
)

# model.summary()
278/20:
model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=200
)
278/21:
y_pred = model.predict(X_test)

for p, x, y in zip(y_pred.ravel(), X_test, y_test.ravel()):
    x = x.ravel()
  
    delta = abs(p - y)
    rel_delta = abs(delta / y) if y != 0 else 0
    perc_delta = 100.0 * rel_delta
    std = np.std(x)
    Dstd = delta / std
    
    print('{:.3f} (VS {:.3f}, std = {:.3f}) ~ {:.3f} ({:.3f}, {:.3f} %)'.format(p, y, std, delta, Dstd, perc_delta))
278/22:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )   

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
  
  
def build_dataset(time_ints, size):
    starts = np.random.randint(100, 300, size=size)
    X = np.zeros((size, time_ints))
    y = np.zeros((size, 1))
    
    for i, start in enumerate(starts):
        diff = time_ints + 1
        sign = np.random.choice([+1, -1])
        end = start + sign * diff
      
        interval = np.array(list(range(start, end, sign)))
        full = interval + 10.0 * np.sin(interval) + [ np.random.normal(0, 5) for _ in range(len(interval)) ]

        X[i] = full[:-1]
        y[i] = full[-1]
        
    X = X.reshape([size, time_ints, 1])
    y = y.reshape([size, 1, 1])
    
    return get_train_test_split(X, y, 0.3, verbose=True)


X_train, X_test, y_train, y_test = build_dataset(32, 52)
278/23:
for x, y in zip(X_train, y_train):
    x = x[..., 0]
    y = y[..., 0]
    
    full = list(x)
    full.append(y[0])
    
    interval = list(np.arange(0, len(full)))
    plt.plot(interval, full)
    
plt.savefig('wow.png')
278/24:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )   

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
  
  
def build_dataset(time_ints, size):
    starts = np.random.randint(100, 1000, size=size)
    X = np.zeros((size, time_ints))
    y = np.zeros((size, 1))
    
    for i, start in enumerate(starts):
        diff = time_ints + 1
        sign = np.random.choice([+1, -1])
        end = start + sign * diff
      
        interval = np.array(list(range(start, end, sign)))
        full = interval + 10.0 * np.sin(interval) + [ np.random.normal(0, 5) for _ in range(len(interval)) ]

        X[i] = full[:-1]
        y[i] = full[-1]
        
    X = X.reshape([size, time_ints, 1])
    y = y.reshape([size, 1, 1])
    
    return get_train_test_split(X, y, 0.3, verbose=True)


X_train, X_test, y_train, y_test = build_dataset(64, 100)
278/25:
for x, y in zip(X_train, y_train):
    x = x[..., 0]
    y = y[..., 0]
    
    full = list(x)
    full.append(y[0])
    
    interval = list(np.arange(0, len(full)))
    plt.plot(interval, full)
    
plt.show()
278/26:
for x, y in zip(X_train, y_train):
    x = x[..., 0]
    y = y[..., 0]
    
    full = list(x)
    full.append(y[0])
    
    interval = list(np.arange(0, len(full)))
    plt.plot(interval, full)
    
plt.savefig('wow.png')
278/27:
n_timesteps = 64

model_args = dict(
    inp_shape=(n_timesteps, 1),
    n_filters=32,
    n_layers=4,
    kernel_size=3,
    pool_size=2,
    n_classes=64,
    final_activation='linear',
    padding='same',
    use_skip_conn=True,
    use_se_block=True,
    dropout=0.0,  # todo try with higher n epochs
    batchnorm=False,  # todo try with higher n epochs
    conv_inner_layers=4,
    filter_mult=3,
)
  
model = build_unet(**model_args)
model.compile(
    optimizer='adam',
    loss='mse',  # todo penalize up/down shifts
)

# model.summary()
278/28:
model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=200
)
278/29:
model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=200
)
278/30:
y_pred = model.predict(X_test)

for p, x, y in zip(y_pred.ravel(), X_test, y_test.ravel()):
    x = x.ravel()
  
    delta = abs(p - y)
    rel_delta = abs(delta / y) if y != 0 else 0
    perc_delta = 100.0 * rel_delta
    std = np.std(x)
    Dstd = delta / std
    
    print('{:.3f} (VS {:.3f}, std = {:.3f}) ~ {:.3f} ({:.3f}, {:.3f} %)'.format(p, y, std, delta, Dstd, perc_delta))
278/31:
from sklearn.model_selection import train_test_split


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )   

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
  
  
def build_dataset(time_ints, size):
    starts = np.random.randint(100, 10000, size=size)
    X = np.zeros((size, time_ints))
    y = np.zeros((size, 1))
    
    for i, start in enumerate(starts):
        diff = time_ints + 1
        sign = np.random.choice([+1, -1])
        end = start + sign * diff
      
        interval = np.array(list(range(start, end, sign)))
        full = interval + 10.0 * np.sin(interval) + [ np.random.normal(0, 5) for _ in range(len(interval)) ]

        X[i] = full[:-1]
        y[i] = full[-1]
        
    X = X.reshape([size, time_ints, 1])
    y = y.reshape([size, 1, 1])
    
    return get_train_test_split(X, y, 0.3, verbose=True)


X_train, X_test, y_train, y_test = build_dataset(64, 1000)
278/32:
n_timesteps = 64

model_args = dict(
    inp_shape=(n_timesteps, 1),
    n_filters=32,
    n_layers=4,
    kernel_size=3,
    pool_size=2,
    n_classes=64,
    final_activation='linear',
    padding='same',
    use_skip_conn=True,
    use_se_block=True,
    dropout=0.0,  # todo try with higher n epochs
    batchnorm=False,  # todo try with higher n epochs
    conv_inner_layers=4,
    filter_mult=3,
)
  
model = build_unet(**model_args)
model.compile(
    optimizer='adam',
    loss='mse',  # todo penalize up/down shifts
)

# model.summary()
278/33:
model.fit(
    X_train, y_train,
    batch_size=16,
    epochs=500
)
279/1:
%load_ext autoreload
%reload_ext autoreload
%autoreload 2
279/2:
import numpy as np
import torchvision
import torch

# %matplotlib inline
import matplotlib.pyplot as plt

from pathlib import Path
279/3:
import pickle
from sklearn.model_selection import train_test_split

from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset

from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

set_seed(42)  # make deterministic
279/4:
def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


def get_data(file_path, max_imgs=2000):  # todo more images
    dataset = load_pickle(Path(file_path).expanduser())

    if len(dataset) == 2:  # (images, masks)
        X = dataset[0]  # list of images
        y = dataset[1]  # list of corresponding mask
    else:  # unsupervised list of images
        X = np.array(dataset, dtype='float32')[:max_imgs]
        y = np.zeros(len(X))

    pixel_size = X.shape[1]  # should be == X.shape[2] == 32
    X = np.array(np.ceil(X * 255), dtype='float32')  # convert pixels to [0, 255] range
    y = np.array(np.ceil(y * 255), dtype='float32')

    X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)

    tensor_X_train = torch.Tensor(X_train)  # tensors
    tensor_y_train = torch.Tensor(y_train)
    tensor_X_test = torch.Tensor(X_test)
    tensor_y_test = torch.Tensor(y_test)

    t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
    t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)

    return t_train_dataset, t_test_dataset, X_train


class ImageDataset(Dataset):
    def __init__(self, pt_dataset, perm=None):
        self.pt_dataset = pt_dataset

        flattened_image_size = 32 * 32
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256  # possible values for pixels
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        image_channels = 1  # grayscale

        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = x  # ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


def get_model(train_dataset):
    GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=16,  # should be 24
        n_head=8,
        n_embd=32  # because of grayscale, should be 512
    )

    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_S,
        bert=False,
    )

    return GPT(mconf)


def train(model, n_epochs, train_dataset, test_dataset, checkpoint_path):
    tokens_per_epoch = len(train_dataset) * train_dataset.block_size

    # initialize a trainer instance and kick off training
    tconf = TrainerConfig(
        max_epochs=n_epochs,
        batch_size=4,
        learning_rate=3e-3,
        betas=(0.9, 0.95),
        weight_decay=0,
        lr_decay=True,
        warmup_tokens=tokens_per_epoch,
        final_tokens=n_epochs * tokens_per_epoch,
        ckpt_path=checkpoint_path,
        num_workers=1
    )
    trainer = Trainer(model, train_dataset, test_dataset, tconf)
    trainer.train()

    return trainer


def model_first_token(dataset, X_train, n_clusters=256):
    counts = torch.ones(n_clusters)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation

    for i in range(nest):
        a, _ = dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[t] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    return prob


def sample_some(trainer, model, dataset, X_train, n_samples=40, out_path='./results/samples.png'):
    prob = model_first_token(dataset, X_train)

    start_pixel = np.random.choice(np.arange(dataset.vocab_size), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    flattened_image_size = 32 * 32
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU

    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(dataset.perm)

    pixel_size = 32

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = pxi.view(pixel_size, pixel_size).cpu().numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
279/5:
    t_train_dataset, t_test_dataset, X_train = get_data('./data/brain.pkl')  # raw data
    train_dataset = ImageDataset(t_train_dataset)  # build dataset
    test_dataset = ImageDataset(t_test_dataset)

    model = get_model(train_dataset)
279/6: x, y = train_dataset[0]
279/7: x.shape
279/8: y.shape
279/9: model(x, y)
279/10: x.long()
280/1:
#!/usr/bin/env python
# coding: utf-8

import numpy as np
import torchvision
import torch

import matplotlib.pyplot as plt

from pathlib import Path
280/2:
import pickle
from sklearn.model_selection import train_test_split

from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset

from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

set_seed(42)  # make deterministic


def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


def get_data(file_path, max_imgs=2000):  # todo more images
    dataset = load_pickle(Path(file_path).expanduser())

    if len(dataset) == 2:  # (images, masks)
        X = dataset[0]  # list of images
        y = dataset[1]  # list of corresponding mask
    else:  # unsupervised list of images
        X = np.array(dataset, dtype='float32')[:max_imgs]
        y = np.zeros(len(X))

    pixel_size = X.shape[1]  # should be == X.shape[2] == 32
    X = np.array(np.ceil(X * 255), dtype='float32')  # convert pixels to [0, 255] range
    y = np.array(np.ceil(y * 255), dtype='float32')

    X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)

    tensor_X_train = torch.Tensor(X_train)  # tensors
    tensor_y_train = torch.Tensor(y_train)
    tensor_X_test = torch.Tensor(X_test)
    tensor_y_test = torch.Tensor(y_test)

    t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
    t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)

    return t_train_dataset, t_test_dataset, X_train


class ImageDataset(Dataset):
    def __init__(self, pt_dataset, perm=None):
        self.pt_dataset = pt_dataset

        flattened_image_size = 32 * 32
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256  # possible values for pixels
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        image_channels = 1  # grayscale

        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = x  # ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence


def get_model(train_dataset):
    GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=16,  # should be 24
        n_head=8,
        n_embd=128  # because of grayscale, should be 512
    )

    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_S,
        bert=False,
    )

    return GPT(mconf)


def train(model, n_epochs, train_dataset, test_dataset, checkpoint_path):
    tokens_per_epoch = len(train_dataset) * train_dataset.block_size

    # initialize a trainer instance and kick off training
    tconf = TrainerConfig(
        max_epochs=n_epochs,
        batch_size=4,
        learning_rate=3e-3,
        betas=(0.9, 0.95),
        weight_decay=0,
        lr_decay=True,
        warmup_tokens=tokens_per_epoch,
        final_tokens=n_epochs * tokens_per_epoch,
        ckpt_path=checkpoint_path,
        num_workers=1
    )
    trainer = Trainer(model, train_dataset, test_dataset, tconf)
    trainer.train()

    return trainer


def model_first_token(dataset, X_train, n_clusters=256):
    counts = torch.ones(n_clusters)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation

    for i in range(nest):
        a, _ = dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[t] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    return prob


def sample_some(trainer, model, dataset, X_train, n_samples=40, out_path='./results/samples.png'):
    prob = model_first_token(dataset, X_train)

    start_pixel = np.random.choice(np.arange(dataset.vocab_size), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    flattened_image_size = 32 * 32
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU

    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(dataset.perm)

    pixel_size = 32

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = pxi.view(pixel_size, pixel_size).cpu().numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
280/3:
    t_train_dataset, t_test_dataset, X_train = get_data('./data/brain.pkl')  # raw data
    train_dataset = ImageDataset(t_train_dataset)  # build dataset
    test_dataset = ImageDataset(t_test_dataset)

    model = get_model(train_dataset)
280/4: x, y = train_dataset[0]
280/5: x = x.to(torch.cuda.current_device())
280/6: y = y.to(torch.cuda.current_device())
280/7: model(x, y)
280/8: model(x.long(), y.long())
280/9: model = model.to(torch.cuda.current_device())
280/10: model(x.long(), y.long())
280/11: model = get_model(train_dataset).to(torch.cuda.current_device())
280/12: model(x.long(), y.long())
280/13:
GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=16,  # should be 24
        n_head=8,
        n_embd=128  # because of grayscale, should be 512
    )

    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_S,
        bert=False,
    )
280/14:
    GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=16,  # should be 24
        n_head=8,
        n_embd=128  # because of grayscale, should be 512
    )

    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_S,
        bert=False,
    )
280/15:
class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            M = torch.rand((b, t)).to('cuda')
            M = ( M > 0.15 ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)

        # forward the GPT model
        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector
        print(token_embeddings.shape)

        # batch x 1023 x 256

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/16:
import math
import logging

import torch
import torch.nn as nn
from torch.nn import functional as F
280/17:
class GPTConfig:
    """ base GPT config, params common to all GPT versions """
    embd_pdrop = 0.1
    resid_pdrop = 0.1
    attn_pdrop = 0.1
    bert = False

    def __init__(self, vocab_size, block_size, **kwargs):
        self.vocab_size = vocab_size
        self.block_size = block_size
        for k,v in kwargs.items():
            setattr(self, k, v)


class CausalSelfAttention(nn.Module):
    """
    A vanilla multi-head masked self-attention layer with a projection at the end.
    It is possible to use torch.nn.MultiheadAttention here but I am including an
    explicit implementation here to show that there is nothing too scary here.
    """

    def __init__(self, config):
        super().__init__()
        assert config.n_embd % config.n_head == 0
        # key, query, value projections for all heads
        self.key = nn.Linear(config.n_embd, config.n_embd)
        self.query = nn.Linear(config.n_embd, config.n_embd)
        self.value = nn.Linear(config.n_embd, config.n_embd)
        # regularization
        self.attn_drop = nn.Dropout(config.attn_pdrop)
        self.resid_drop = nn.Dropout(config.resid_pdrop)
        # output projection
        self.proj = nn.Linear(config.n_embd, config.n_embd)
        # causal mask to ensure that attention is only applied to the left in the input sequence
        self.register_buffer("mask", torch.tril(torch.ones(config.block_size, config.block_size))
                                     .view(1, 1, config.block_size, config.block_size))
        self.n_head = config.n_head

    def forward(self, x, layer_past=None):
        B, T, C = x.size()

        # calculate query, key, values for all heads in batch and move head forward to be the batch dim
        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)

        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)
        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))
        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))
        att = F.softmax(att, dim=-1)
        att = self.attn_drop(att)
        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)
        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side

        # output projection
        y = self.resid_drop(self.proj(y))
        return y


class Block(nn.Module):
    """ an unassuming Transformer block """

    def __init__(self, config):
        super().__init__()
        self.ln1 = nn.LayerNorm(config.n_embd)
        self.ln2 = nn.LayerNorm(config.n_embd)
        self.attn = CausalSelfAttention(config)
        self.mlp = nn.Sequential(
            nn.Linear(config.n_embd, 4 * config.n_embd),
            nn.GELU(),
            nn.Linear(4 * config.n_embd, config.n_embd),
            nn.Dropout(config.resid_pdrop),
        )

    def forward(self, x):
        x = x + self.attn(self.ln1(x))
        x = x + self.mlp(self.ln2(x))
        return x


class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            M = torch.rand((b, t)).to('cuda')
            M = ( M > 0.15 ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)

        # forward the GPT model
        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector
        print(token_embeddings.shape)

        # batch x 1023 x 256

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/18:
class GPTConfig:
    """ base GPT config, params common to all GPT versions """
    embd_pdrop = 0.1
    resid_pdrop = 0.1
    attn_pdrop = 0.1
    bert = False

    def __init__(self, vocab_size, block_size, **kwargs):
        self.vocab_size = vocab_size
        self.block_size = block_size
        for k,v in kwargs.items():
            setattr(self, k, v)


class CausalSelfAttention(nn.Module):
    """
    A vanilla multi-head masked self-attention layer with a projection at the end.
    It is possible to use torch.nn.MultiheadAttention here but I am including an
    explicit implementation here to show that there is nothing too scary here.
    """

    def __init__(self, config):
        super().__init__()
        assert config.n_embd % config.n_head == 0
        # key, query, value projections for all heads
        self.key = nn.Linear(config.n_embd, config.n_embd)
        self.query = nn.Linear(config.n_embd, config.n_embd)
        self.value = nn.Linear(config.n_embd, config.n_embd)
        # regularization
        self.attn_drop = nn.Dropout(config.attn_pdrop)
        self.resid_drop = nn.Dropout(config.resid_pdrop)
        # output projection
        self.proj = nn.Linear(config.n_embd, config.n_embd)
        # causal mask to ensure that attention is only applied to the left in the input sequence
        self.register_buffer("mask", torch.tril(torch.ones(config.block_size, config.block_size))
                                     .view(1, 1, config.block_size, config.block_size))
        self.n_head = config.n_head

    def forward(self, x, layer_past=None):
        B, T, C = x.size()

        # calculate query, key, values for all heads in batch and move head forward to be the batch dim
        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)

        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)
        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))
        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))
        att = F.softmax(att, dim=-1)
        att = self.attn_drop(att)
        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)
        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side

        # output projection
        y = self.resid_drop(self.proj(y))
        return y


class Block(nn.Module):
    """ an unassuming Transformer block """

    def __init__(self, config):
        super().__init__()
        self.ln1 = nn.LayerNorm(config.n_embd)
        self.ln2 = nn.LayerNorm(config.n_embd)
        self.attn = CausalSelfAttention(config)
        self.mlp = nn.Sequential(
            nn.Linear(config.n_embd, 4 * config.n_embd),
            nn.GELU(),
            nn.Linear(4 * config.n_embd, config.n_embd),
            nn.Dropout(config.resid_pdrop),
        )

    def forward(self, x):
        x = x + self.attn(self.ln1(x))
        x = x + self.mlp(self.ln2(x))
        return x


class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        # logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            M = torch.rand((b, t)).to('cuda')
            M = ( M > 0.15 ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)

        # forward the GPT model
        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector
        print(token_embeddings.shape)

        # batch x 1023 x 256

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/19: model = GPT(mconf).to(torch.cuda.current_device())
280/20: model(x.long(), y.long())
280/21:
class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        # logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            M = torch.rand((b, t)).to('cuda')
            M = ( M > 0.15 ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)

        # forward the GPT model
        print(idx.shape)
        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector, batch x 1023 x 1 x n_embeddings

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/22: model = GPT(mconf).to(torch.cuda.current_device())
280/23: model(x.long(), y.long())
280/24:
class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        # logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            prob = 0.15

            M = torch.rand((b, t)).to('cuda')
            M = ( M > prob ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)  # todo change 256

        # forward the GPT model
        # idx ~ 1023 x 1
        j = nn.Linear(1, 128, bias=False)
        print(j.shape)

        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector, batch x 1023 x 1 x n_embeddings
        print(token_embeddings.shape)

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/25: model = GPT(mconf).to(torch.cuda.current_device())
280/26: model(x.long(), y.long())
280/27:
class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        # logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            prob = 0.15

            M = torch.rand((b, t)).to('cuda')
            M = ( M > prob ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)  # todo change 256

        # forward the GPT model
        # idx ~ 1023 x 1
        j = nn.Linear(1, 128, bias=False)(idx)
        print(j.shape)

        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector, batch x 1023 x 1 x n_embeddings
        print(token_embeddings.shape)

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/28: model = GPT(mconf).to(torch.cuda.current_device())
280/29: model(x.long(), y.long())
280/30:
class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        # logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            prob = 0.15

            M = torch.rand((b, t)).to('cuda')
            M = ( M > prob ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)  # todo change 256

        # forward the GPT model
        # idx ~ 1023 x 1
        j = nn.Linear(1, 128, bias=False)(idx.float())
        print(j.shape)

        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector, batch x 1023 x 1 x n_embeddings
        print(token_embeddings.shape)

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
280/31: model = GPT(mconf).to(torch.cuda.current_device())
280/32: model(x.long(), y.long())
281/1:
import numpy as np
import torchvision
import torch

import matplotlib.pyplot as plt

from pathlib import Path
281/2:
import pickle
from sklearn.model_selection import train_test_split

from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset

from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

set_seed(42)  # make deterministic


def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


def get_data(file_path, max_imgs=2000):  # todo more images
    dataset = load_pickle(Path(file_path).expanduser())

    if len(dataset) == 2:  # (images, masks)
        X = dataset[0]  # list of images
        y = dataset[1]  # list of corresponding mask
    else:  # unsupervised list of images
        X = np.array(dataset, dtype='float32')[:max_imgs]
        y = np.zeros(len(X))

    pixel_size = X.shape[1]  # should be == X.shape[2] == 32
    X = np.array(np.ceil(X * 255), dtype='float32')  # convert pixels to [0, 255] range
    y = np.array(np.ceil(y * 255), dtype='float32')

    X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)

    tensor_X_train = torch.Tensor(X_train)  # tensors
    tensor_y_train = torch.Tensor(y_train)
    tensor_X_test = torch.Tensor(X_test)
    tensor_y_test = torch.Tensor(y_test)

    t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
    t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)

    return t_train_dataset, t_test_dataset, X_train


class ImageDataset(Dataset):
    def __init__(self, pt_dataset, perm=None):
        self.pt_dataset = pt_dataset

        flattened_image_size = 32 * 32
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256  # possible values for pixels
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        image_channels = 1  # grayscale

        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = x  # ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence
281/3:
    t_train_dataset, t_test_dataset, X_train = get_data('./data/brain.pkl')  # raw data
    train_dataset = ImageDataset(t_train_dataset)  # build dataset
    test_dataset = ImageDataset(t_test_dataset)
281/4: from torch.utils.data.dataloader import DataLoader
282/1:
import numpy as np
import torchvision
import torch

import matplotlib.pyplot as plt

from pathlib import Path
282/2:
import pickle
from sklearn.model_selection import train_test_split

from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset

from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

set_seed(42)  # make deterministic


def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


def get_data(file_path, max_imgs=2000):  # todo more images
    dataset = load_pickle(Path(file_path).expanduser())

    if len(dataset) == 2:  # (images, masks)
        X = dataset[0]  # list of images
        y = dataset[1]  # list of corresponding mask
    else:  # unsupervised list of images
        X = np.array(dataset, dtype='float32')[:max_imgs]
        y = np.zeros(len(X))

    pixel_size = X.shape[1]  # should be == X.shape[2] == 32
    X = np.array(np.ceil(X * 255), dtype='float32')  # convert pixels to [0, 255] range
    y = np.array(np.ceil(y * 255), dtype='float32')

    X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)

    tensor_X_train = torch.Tensor(X_train)  # tensors
    tensor_y_train = torch.Tensor(y_train)
    tensor_X_test = torch.Tensor(X_test)
    tensor_y_test = torch.Tensor(y_test)

    t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
    t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)

    return t_train_dataset, t_test_dataset, X_train


class ImageDataset(Dataset):
    def __init__(self, pt_dataset, perm=None):
        self.pt_dataset = pt_dataset

        flattened_image_size = 32 * 32
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256  # possible values for pixels
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        image_channels = 1  # grayscale

        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = x  # ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments
        return a[:-1], a[1:]  # always just predict the next one in the sequence
282/3:
    t_train_dataset, t_test_dataset, X_train = get_data('./data/brain.pkl')  # raw data
    train_dataset = ImageDataset(t_train_dataset)  # build dataset
    test_dataset = ImageDataset(t_test_dataset)
282/4:
import torch
import torch.nn as nn
from torch.nn import functional as F

# logger = logging.getLogger(__name__)


class GPTConfig:
    """ base GPT config, params common to all GPT versions """
    embd_pdrop = 0.1
    resid_pdrop = 0.1
    attn_pdrop = 0.1
    bert = False

    def __init__(self, vocab_size, block_size, **kwargs):
        self.vocab_size = vocab_size
        self.block_size = block_size
        for k,v in kwargs.items():
            setattr(self, k, v)


class CausalSelfAttention(nn.Module):
    """
    A vanilla multi-head masked self-attention layer with a projection at the end.
    It is possible to use torch.nn.MultiheadAttention here but I am including an
    explicit implementation here to show that there is nothing too scary here.
    """

    def __init__(self, config):
        super().__init__()
        assert config.n_embd % config.n_head == 0
        # key, query, value projections for all heads
        self.key = nn.Linear(config.n_embd, config.n_embd)
        self.query = nn.Linear(config.n_embd, config.n_embd)
        self.value = nn.Linear(config.n_embd, config.n_embd)
        # regularization
        self.attn_drop = nn.Dropout(config.attn_pdrop)
        self.resid_drop = nn.Dropout(config.resid_pdrop)
        # output projection
        self.proj = nn.Linear(config.n_embd, config.n_embd)
        # causal mask to ensure that attention is only applied to the left in the input sequence
        self.register_buffer("mask", torch.tril(torch.ones(config.block_size, config.block_size))
                                     .view(1, 1, config.block_size, config.block_size))
        self.n_head = config.n_head

    def forward(self, x, layer_past=None):
        B, T, C = x.size()

        # calculate query, key, values for all heads in batch and move head forward to be the batch dim
        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)

        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)
        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))
        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))
        att = F.softmax(att, dim=-1)
        att = self.attn_drop(att)
        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)
        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side

        # output projection
        y = self.resid_drop(self.proj(y))
        return y


class Block(nn.Module):
    """ an unassuming Transformer block """

    def __init__(self, config):
        super().__init__()
        self.ln1 = nn.LayerNorm(config.n_embd)
        self.ln2 = nn.LayerNorm(config.n_embd)
        self.attn = CausalSelfAttention(config)
        self.mlp = nn.Sequential(
            nn.Linear(config.n_embd, 4 * config.n_embd),
            nn.GELU(),
            nn.Linear(4 * config.n_embd, config.n_embd),
            nn.Dropout(config.resid_pdrop),
        )

    def forward(self, x):
        x = x + self.attn(self.ln1(x))
        x = x + self.mlp(self.ln2(x))
        return x
282/5: train_dataset[0]
282/6: train_dataset[0:5]
282/7: train_dataset[0:5][0]
282/8: train_dataset[0:5][0].shape
282/9: train_dataset[1][0]
282/10: train_dataset[0][0]
282/11: train_dataset[0].shape
282/12: train_dataset[0][0].shape
282/13: train_dataset[1][0].shape
282/14: torch.cat(train_dataset[0][0], train_dataset[1][0])
282/15: torch.cat((train_dataset[0][0], train_dataset[1][0]))
282/16: torch.cat((train_dataset[0][0], train_dataset[1][0])).shape
282/17: torch.cat((train_dataset[0][0], train_dataset[1][0]), dim=-1).shape
282/18: torch.cat((train_dataset[0][0], train_dataset[1][0]), dim=2).shape
282/19:  train_dataset[0][0].unsqueeze_(0)
282/20:  train_dataset[0][0].unsqueeze_(0).shape
282/21: torch.cat((train_dataset[0][0].unsqueeze_(0), train_dataset[1][0].unsqueeze_(0)), dim=0).shape
282/22: x = torch.cat((train_dataset[0][0].unsqueeze_(0), train_dataset[1][0].unsqueeze_(0)), dim=0)
282/23: x = torch.cat((train_dataset[0][0].unsqueeze_(0), train_dataset[1][0].unsqueeze_(0)), dim=0).to(torch.cuda.current_device())
282/24: y = torch.cat((train_dataset[0][1].unsqueeze_(0), train_dataset[1][1].unsqueeze_(0)), dim=0).to(torch.cuda.current_device())
282/25:
class GPT(nn.Module):
    """  the full GPT language model, with a context size of block_size """

    def __init__(self, config):
        super().__init__()

        # input embedding stem
        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)  # 256 x 512
        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))  # 1023 x 256
        self.drop = nn.Dropout(config.embd_pdrop)
        # transformer
        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
        # decoder head
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        self.block_size = config.block_size
        self.apply(self._init_weights)

        self.bert = config.bert

        # logger.info("number of parameters: %e", sum(p.numel() for p in self.parameters()))

    def get_block_size(self):
        return self.block_size

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=0.02)
            if isinstance(module, nn.Linear) and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def configure_optimizers(self, train_config):
        """
        This long function is unfortunately doing something very simple and is being very defensive:
        We are separating out all parameters of the model into two buckets: those that will experience
        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).
        We are then returning the PyTorch optimizer object.
        """

        # separate out all parameters to those that will and won't experience regularizing weight decay
        decay = set()
        no_decay = set()
        whitelist_weight_modules = (torch.nn.Linear, )
        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)
        for mn, m in self.named_modules():
            for pn, p in m.named_parameters():
                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name

                if pn.endswith('bias'):
                    # all biases will not be decayed
                    no_decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):
                    # weights of whitelist modules will be weight decayed
                    decay.add(fpn)
                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):
                    # weights of blacklist modules will NOT be weight decayed
                    no_decay.add(fpn)

        # special case the position embedding parameter in the root GPT module as not decayed
        no_decay.add('pos_emb')

        # validate that we considered every parameter
        param_dict = {pn: p for pn, p in self.named_parameters()}
        inter_params = decay & no_decay
        union_params = decay | no_decay
        assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
        assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                    % (str(param_dict.keys() - union_params), )

        # create the pytorch optimizer object
        optim_groups = [
            {"params": [param_dict[pn] for pn in sorted(list(decay))], "weight_decay": train_config.weight_decay},
            {"params": [param_dict[pn] for pn in sorted(list(no_decay))], "weight_decay": 0.0},
        ]
        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)
        return optimizer

    def forward(self, idx, targets=None):
        b, t = idx.size()
        assert t <= self.block_size, "Cannot forward, model block size is exhausted."

        if self.bert:
            prob = 0.15

            M = torch.rand((b, t)).to('cuda')
            M = ( M > prob ).float()
            M = M.unsqueeze_(-1)
            M = M.repeat(1, 1, 256)  # todo change 256

        # forward the GPT model
        # idx ~ 1023 x 1
        j = nn.Linear(1, 128, bias=False)(idx.float())
        print(j.shape)

        token_embeddings = self.tok_emb(idx.long()) # each index maps to a (learnable) vector, batch x 1023 x 1 x n_embeddings
        print(token_embeddings.shape)

        x = token_embeddings
        if self.bert:
            x = x * M

        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector
        x = x + position_embeddings

        x = self.drop(x)
        x = self.blocks(x)  # transf
        x = self.ln_f(x)  # layer normal
        logits = self.head(x)  # batch x 1023 x 256

        # if we are given some desired targets also calculate the loss
        loss = None
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))

            if self.bert:
                IM = 1.0 - M
                loss = loss * IM

        return logits, loss
282/26: model = GPT(mconf).to(torch.cuda.current_device())
282/27:
    GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=16,  # should be 24
        n_head=8,
        n_embd=128  # because of grayscale, should be 512
    )

    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_S,
        bert=False,
    )
282/28: model = GPT(mconf).to(torch.cuda.current_device())
282/29: model(x.long(), y.long())
282/30: model(x, y)
282/31: x.shape
283/1:
import numpy as np
import torchvision
import torch

import matplotlib.pyplot as plt

from pathlib import Path
283/2:
import pickle
from sklearn.model_selection import train_test_split

from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset

from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

set_seed(42)  # make deterministic


def load_pickle(f_path):
    with open(f_path, 'rb') as fp:
        return pickle.load(fp)


def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test


def get_data(file_path, max_imgs=2000):
    dataset = load_pickle(Path(file_path).expanduser())

    if len(dataset) == 2:  # (images, masks)
        X = dataset[0]  # list of images
        y = dataset[1]  # list of corresponding mask
    else:  # unsupervised list of images
        X = np.array(dataset, dtype='float32')[:max_imgs]
        y = np.zeros(len(X))

    pixel_size = X.shape[1]  # should be == X.shape[2] == 32
    X = np.array(np.ceil(X * 255), dtype='float32')  # convert pixels to [0, 255] range
    y = np.array(np.ceil(y * 255), dtype='float32')

    X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)

    tensor_X_train = torch.Tensor(X_train)  # tensors
    tensor_y_train = torch.Tensor(y_train)
    tensor_X_test = torch.Tensor(X_test)
    tensor_y_test = torch.Tensor(y_test)

    t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)
    t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)

    return t_train_dataset, t_test_dataset, X_train


class ImageDataset(Dataset):
    def __init__(self, pt_dataset, perm=None):
        self.pt_dataset = pt_dataset

        flattened_image_size = 32 * 32
        self.perm = torch.arange(flattened_image_size) if perm is None else perm

        self.vocab_size = 256  # possible values for pixels
        self.block_size = flattened_image_size - 1

    def __len__(self):
        return len(self.pt_dataset)

    def __getitem__(self, idx):
        image_channels = 1  # grayscale

        x, y = self.pt_dataset[idx]
        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels
        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float
        a = x[:, 0]
        return a[:-1], a[1:]  # always just predict the next one in the sequence


def get_model(train_dataset):
    GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=16,  # should be 24
        n_head=8,
        n_embd=256  # because of grayscale, should be 512
    )

    mconf = GPTConfig(
        train_dataset.vocab_size,
        train_dataset.block_size,
        **GPT_S,
        bert=False,
    )

    return GPT(mconf)


def train(model, n_epochs, train_dataset, test_dataset, checkpoint_path):
    tokens_per_epoch = len(train_dataset) * train_dataset.block_size

    # initialize a trainer instance and kick off training
    tconf = TrainerConfig(
        max_epochs=n_epochs,
        batch_size=4,
        learning_rate=3e-3,
        betas=(0.9, 0.95),
        weight_decay=0,
        lr_decay=True,
        warmup_tokens=tokens_per_epoch,
        final_tokens=n_epochs * tokens_per_epoch,
        ckpt_path=checkpoint_path,
        num_workers=1
    )
    trainer = Trainer(model, train_dataset, test_dataset, tconf)
    # trainer.train()

    return trainer


def model_first_token(dataset, X_train, n_clusters=256):
    counts = torch.ones(n_clusters)  # start counts as 1 not zero, this is called "smoothing"
    rp = torch.randperm(len(dataset))
    nest = X_train.shape[0] // 2  # how many images to use for the estimation

    for i in range(nest):
        a, _ = dataset[int(rp[i])]
        t = a[0].item()  # index of first token in the sequence
        counts[int(t)] += 1

    prob = counts / counts.sum()  # normalize to have sum (prob) = 1
    return prob


def sample_some(trainer, model, dataset, X_train, n_samples=40, out_path='./results/samples.png'):
    prob = model_first_token(dataset, X_train)

    start_pixel = np.random.choice(np.arange(dataset.vocab_size), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    flattened_image_size = 32 * 32
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)  # WARNING: this blows CPU

    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(dataset.perm)

    pixel_size = 32

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = pxi.view(pixel_size, pixel_size).cpu().numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)


def fine_tune(model):
    pass
283/3:
    t_train_dataset, t_test_dataset, X_train = get_data('./data/brain.pkl')  # raw data
    train_dataset = ImageDataset(t_train_dataset)  # build dataset
    test_dataset = ImageDataset(t_test_dataset)

    model = get_model(train_dataset)
283/4:
    checkpoint_path = './results/latest_model.pt'
    trainer = train(model, 20, train_dataset, test_dataset, checkpoint_path)
283/5:
    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cuda:0'))  # load the state of the best model we've seen based on early stopping
    model.load_state_dict(checkpoint)
283/6: sample_some(trainer, model, train_dataset, X_train)
283/7:
@torch.no_grad()
def sample(model, x, steps, temperature=1.0, sample=False, top_k=None):
    """
    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in
    the sequence, feeding the predictions back into the model each time. Clearly the sampling
    has quadratic complexity unlike an RNN that is only linear, and has a finite context window
    of block_size, unlike an RNN that has an infinite context window.
    """
    print(x.shape)


    block_size = model.get_block_size()
    model.eval()
    for k in range(steps):
        print(k, steps)
        x_cond = x if x.size(1) <= block_size else x[:, -block_size:]  # crop context if needed
        logits, _ = model(x_cond.detach().clone())  # n_samples x step x n_embd

        # pluck the logits at the final step and scale by temperature
        logits = logits[:, -1, :] / temperature  # just the last pixel: n_samples x n_embd

        # optionally crop probabilities to only the top k options
        if top_k is not None:
            logits = top_k_logits(logits, top_k)

        # apply softmax to convert to probabilities
        probs = F.softmax(logits, dim=-1)

        # sample from the distribution or take the most likely
        if sample:
            ix = torch.multinomial(probs, num_samples=1)
        else:
            _, ix = torch.topk(probs, k=1, dim=-1)

        # append to the sequence and continue
        x = torch.cat((x, ix), dim=1)
    1/0
    return x
283/8:
def sample_some(trainer, model, dataset, X_train, n_samples=40, out_path='./results/samples.png'):
    prob = model_first_token(dataset, X_train)

    start_pixel = np.random.choice(np.arange(dataset.vocab_size), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    flattened_image_size = 32 * 32
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)

    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(dataset.perm)

    pixel_size = 32

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = pxi.view(pixel_size, pixel_size).cpu().numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
283/9:     sample_some(trainer, model, train_dataset, X_train)
283/10:
import random
import numpy as np
import torch
import torch.nn as nn
from torch.nn import functional as F


def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def top_k_logits(logits, k):
    v, ix = torch.topk(logits, k)
    out = logits.clone()
    out[out < v[:, [-1]]] = -float('Inf')
    return out
283/11: sample_some(trainer, model, train_dataset, X_train)
283/12:
@torch.no_grad()
def sample(model, x, steps, temperature=1.0, sample=False, top_k=None):
    """
    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in
    the sequence, feeding the predictions back into the model each time. Clearly the sampling
    has quadratic complexity unlike an RNN that is only linear, and has a finite context window
    of block_size, unlike an RNN that has an infinite context window.
    """
    print(x.shape)


    block_size = model.get_block_size()
    model.eval()
    for k in range(steps):
        print(k, steps)
        x_cond = x if x.size(1) <= block_size else x[:, -block_size:]  # crop context if needed
        logits, _ = model(x_cond.detach().clone())  # n_samples x step x n_embd

        # pluck the logits at the final step and scale by temperature
        logits = logits[:, -1, :] / temperature  # just the last pixel: n_samples x n_embd

        # optionally crop probabilities to only the top k options
        if top_k is not None:
            logits = top_k_logits(logits, top_k)

        # apply softmax to convert to probabilities
        probs = F.softmax(logits, dim=-1)

        # sample from the distribution or take the most likely
        if sample:
            ix = torch.multinomial(probs, num_samples=1)
        else:
            _, ix = torch.topk(probs, k=1, dim=-1)

        # append to the sequence and continue
        x = torch.cat((x, ix), dim=1)
    return x
283/13:
def sample_some(trainer, model, dataset, X_train, n_samples=40, out_path='./results/samples.png'):
    prob = model_first_token(dataset, X_train)

    start_pixel = np.random.choice(np.arange(dataset.vocab_size), size=(n_samples, 1), replace=True, p=prob.numpy())
    start_pixel = torch.from_numpy(start_pixel).to(trainer.device)
    flattened_image_size = 32 * 32
    pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=40)

    # for visualization we have to invert the permutation used to produce the pixels
    iperm = torch.argsort(dataset.perm)

    pixel_size = 32

    n_cols = 8
    n_rows = n_samples // n_cols
    fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))
    for i, ax in enumerate(axis.ravel()):
        pxi = pixels[i][iperm]  # undo the encoding permutation
        pxi = pxi.view(pixel_size, pixel_size).cpu().numpy().astype(np.uint8)  # grayscale -> 2D

        ax.imshow(pxi, cmap='magma')
        ax.axis('off')

    plt.savefig(out_path)
283/14:     sample_some(trainer, model, train_dataset, X_train)
283/15:
    GPT_S = dict(
        embd_pdrop=0.0,
        resid_pdrop=0.0,
        attn_pdrop=0.0,
        n_layer=24,
        n_head=8,
        n_embd=512,
    )

    MY_GPT = dict(
        n_layer=16,
        n_embd=256  # because of grayscale
    )
    MY_GPT = {**GPT_S, **MY_GPT}
284/1: import numpy as np
284/2:
from pathlib import Path
from PIL import Image
import cv2 as cv
import numpy as np
import pickle
284/3:
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    BatchNormalization,
    Conv2D,
    Conv2DTranspose,
    MaxPooling2D,
    Dropout,
    SpatialDropout2D,
    UpSampling2D,
    Input,
    concatenate,
    multiply,
    add,
    Activation,
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
284/4:
# from https://github.com/karolzak/keras-unet

def upsample_conv(filters, kernel_size, strides, padding):
    return Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)


def upsample_simple(filters, kernel_size, strides, padding):
    return UpSampling2D(strides)


def attention_gate(inp_1, inp_2, n_intermediate_filters):
    """Attention gate. Compresses both inputs to n_intermediate_filters filters before processing.
       Implemented as proposed by Oktay et al. in their Attention U-net, see: https://arxiv.org/abs/1804.03999.
    """
    inp_1_conv = Conv2D(
        n_intermediate_filters,
        kernel_size=1,
        strides=1,
        padding="same",
        kernel_initializer="he_normal",
    )(inp_1)
    inp_2_conv = Conv2D(
        n_intermediate_filters,
        kernel_size=1,
        strides=1,
        padding="same",
        kernel_initializer="he_normal",
    )(inp_2)

    f = Activation("relu")(add([inp_1_conv, inp_2_conv]))
    g = Conv2D(
        filters=1,
        kernel_size=1,
        strides=1,
        padding="same",
        kernel_initializer="he_normal",
    )(f)
    h = Activation("sigmoid")(g)
    return multiply([inp_1, h])


def attention_concat(conv_below, skip_connection):
    """Performs concatenation of upsampled conv_below with attention gated version of skip-connection
    """
    below_filters = conv_below.get_shape().as_list()[-1]
    attention_across = attention_gate(skip_connection, conv_below, below_filters)
    return concatenate([conv_below, attention_across])


def conv2d_block(
    inputs,
    use_batch_norm=True,
    dropout=0.3,
    dropout_type="spatial",
    filters=16,
    kernel_size=(3, 3),
    activation="relu",
    kernel_initializer="he_normal",
    padding="same",
):

    if dropout_type == "spatial":
        DO = SpatialDropout2D
    elif dropout_type == "standard":
        DO = Dropout
    else:
        raise ValueError(
            f"dropout_type must be one of ['spatial', 'standard'], got {dropout_type}"
        )

    c = Conv2D(
        filters,
        kernel_size,
        activation=activation,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=not use_batch_norm,
    )(inputs)
    if use_batch_norm:
        c = BatchNormalization()(c)
    if dropout > 0.0:
        c = DO(dropout)(c)
    c = Conv2D(
        filters,
        kernel_size,
        activation=activation,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=not use_batch_norm,
    )(c)
    if use_batch_norm:
        c = BatchNormalization()(c)
    return c


def custom_unet(
    input_shape,
    num_classes=1,
    activation="relu",
    use_batch_norm=True,
    upsample_mode="deconv",  # 'deconv' or 'simple'
    dropout=0.3,
    dropout_change_per_layer=0.0,
    dropout_type="spatial",
    use_dropout_on_upsampling=False,
    use_attention=False,
    filters=16,
    num_layers=4,
    output_activation="sigmoid",
):
    if upsample_mode == "deconv":
        upsample = upsample_conv
    else:
        upsample = upsample_simple

    # Build U-Net model
    inputs = Input(input_shape)
    x = inputs

    down_layers = []
    for l in range(num_layers):
        x = conv2d_block(
            inputs=x,
            filters=filters,
            use_batch_norm=use_batch_norm,
            dropout=dropout,
            dropout_type=dropout_type,
            activation=activation,
        )
        down_layers.append(x)
        x = MaxPooling2D((2, 2))(x)
        dropout += dropout_change_per_layer
        filters = filters * 2  # double the number of filters with each layer

    x = conv2d_block(
        inputs=x,
        filters=filters,
        use_batch_norm=use_batch_norm,
        dropout=dropout,
        dropout_type=dropout_type,
        activation=activation,
    )

    if not use_dropout_on_upsampling:
        dropout = 0.0
        dropout_change_per_layer = 0.0

    for conv in reversed(down_layers):
        filters //= 2  # decreasing number of filters with each layer
        dropout -= dropout_change_per_layer
        x = upsample(filters, (2, 2), strides=(2, 2), padding="same")(x)
        if use_attention:
            x = attention_concat(conv_below=x, skip_connection=conv)
        else:
            x = concatenate([x, conv])
        x = conv2d_block(
            inputs=x,
            filters=filters,
            use_batch_norm=use_batch_norm,
            dropout=dropout,
            dropout_type=dropout_type,
            activation=activation,
        )

    outputs = Conv2D(num_classes, (1, 1), activation=output_activation)(x)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model
284/5:
model = custom_unet(
    input_shape=(80, 80, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid')
284/6:
model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', 'iou']
)
284/7:
from sklearn.model_selection import train_test_split

def get_train_test_split(X, y, test_size, random_state=42, verbose=False):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state  # reproducible results
    )   

    if verbose:
        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))
        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))


    return X_train, X_test, y_train, y_test
284/8: X = np.load('/home/stfo194b/scratch/Xu.npy')
284/9: Y = np.load('/home/stfo194b/scratch/Yu.npy')
284/10: y = Y
284/11: X_train, X_test, y_train, y_test = get_train_test_split(X, y, test_size=0.1, verbose=True)
284/12:
n_epochs = 10
weights_file = 'best_model.keras'

model.fit(
    X, y,
    batch_size=8,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
284/13: from tensorflow.keras.metrix import MeanIoU
284/14: from tensorflow.keras.metrics import MeanIoU
284/15:
model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', MeanIoU]
)
284/16:
model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', MeanIoU()]
)
284/17:
model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', MeanIoU(2)]
)
284/18:
model = custom_unet(
    input_shape=(80, 80, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid')


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', MeanIoU]
)
284/19:
model = custom_unet(
    input_shape=(80, 80, 1),
    use_batch_norm=False,
    num_classes=1,
    filters=64,
    dropout=0.2,
    output_activation='sigmoid')


model.compile(
    optimizer=Adam(learning_rate=2e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', MeanIoU(2)]
)
284/20:
n_epochs = 10
weights_file = 'best_model.keras'

model.fit(
    X, y,
    batch_size=8,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
284/21: y_pred = model.predict(X_test)
284/22: np.save('pred.npy', y_pred)
284/23: np.save('test.npy', y_test)
284/24:
n_epochs = 100
weights_file = 'best_model.keras'

model.fit(
    X, y,
    batch_size=4,
    epochs=n_epochs,
    verbose=True,
    callbacks = [ 
        EarlyStopping(
            monitor='loss',
            patience=int(n_epochs / 2),  # run at least half epochs
            verbose=True
        ),  
        ReduceLROnPlateau(
            factor=1e-1, 
            patience=5,  # no time to waste
            min_lr=1e-5,
            verbose=True
        ),
        ModelCheckpoint(
            weights_file,
            monitor='loss',
            verbose=True,
            save_best_only=True,
            save_weights_only=True
        )
    ]
)
284/25: y_pred = model.predict(X_test)
284/26: np.save('test.npy', y_test)
284/27: np.save('pred.npy', y_pred)
284/28: ls
285/1: import jedi
285/2: print(jedi.__version__)
285/3: !pip install —user jedi=0.17.2
285/4:
#!/usr/bin/env python
# coding: utf-8

import numpy as np
import torchvision
import torch

import matplotlib.pyplot as plt

from pathlib import Path
import logging

import time

import pickle
from sklearn.model_selection import train_test_split

from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data import Dataset

from mingpt.utils import set_seed, sample
from mingpt.model import GPT, GPTConfig
from mingpt.trainer import Trainer, TrainerConfig

import os
285/5:
set_seed(42)  # make deterministic

GPT_S = dict(
    embd_pdrop=0.0,
    resid_pdrop=0.0,
    attn_pdrop=0.0,
    n_layer=24,
    n_head=8,
    n_embd=512,
)
285/6:     MY_GPT = {**GPT_S, **MY_GPT}  # inherit all other params
285/7:
    MY_GPT = dict(
        n_layer=16,
        n_embd=n_embd
    )
    MY_GPT = {**GPT_S, **MY_GPT}  # inherit all other params
285/8:
    MY_GPT = dict(
        n_layer=16,
        n_embd=256
        )
    MY_GPT = {**GPT_S, **MY_GPT}  # inherit all other params
285/9:
    mconf = GPTConfig(
        256,
        1023,
        **MY_GPT,
        bert=False,
        use_embd=use_embd,
    )

    model = get_model(mconf)
285/10:
    mconf = GPTConfig(
        256,
        1023,
        **MY_GPT,
        bert=False,
        use_embd=False,
    )

    model = get_model(mconf)
285/11:
def get_model(mconf):
    return GPT(mconf)
285/12:
    mconf = GPTConfig(
        256,
        1023,
        **MY_GPT,
        bert=False,
        use_embd=False,
    )

    model = get_model(mconf)
285/13: x = torch.rand(4, 1023)
285/14: y = torch.rand(4, 1023)
286/1: import jedi
286/2: print(jedi.__version__)
286/3: !pip install —user jedi=0.17.2
286/4: !pip install --user jedi=0.17.2
286/5: !pip install --user jedi==0.17.2
286/6: !pip install jedi==0.17.2
   1: import jedi
   2: print(jedi.__version__)
   3: %history -g 10
   4: %history -g -f out.py
