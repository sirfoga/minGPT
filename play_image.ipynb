{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "  format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "  datefmt=\"%Y-%d-%d %H:%M:%S\",\n",
    "  level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.utils import set_seed\n",
    "\n",
    "set_seed(42)  # make deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_pickle(f_path):\n",
    "    with open(f_path, 'rb') as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_train_test_split(X, y, test_size, random_state=42, verbose=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state  # reproducible results\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print('train data: X ~ {}, y ~ {}'.format(X_train.shape, y_train.shape))\n",
    "        print('test data: X ~ {}, y ~ {}'.format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: X ~ (1008, 32, 32, 1), y ~ (1008, 32, 32, 1)\n",
      "test data: X ~ (432, 32, 32, 1), y ~ (432, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_pickle(Path('~/martin/minGPT_data.pkl').expanduser())  # list of (image, mask)\n",
    "X = dataset[0]  # list of images\n",
    "y = dataset[1]  # list of corresponding mask\n",
    "\n",
    "pixel_size = X.shape[1]  # should be = X.shape[2] = 32\n",
    "image_channels = X.shape[-1]  # should be = 1\n",
    "flattened_image_size = pixel_size * pixel_size\n",
    "\n",
    "# convert pixels to [0, 255] range\n",
    "X = np.array(np.ceil(X * 255), dtype='float32')\n",
    "y = np.array(np.ceil(y * 255), dtype='float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(X, y, 0.3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensor_X_train = torch.Tensor(X_train)  # tensors\n",
    "tensor_y_train = torch.Tensor(y_train)\n",
    "tensor_X_test = torch.Tensor(X_test)\n",
    "tensor_y_test = torch.Tensor(y_test)\n",
    "\n",
    "t_train_dataset = TensorDataset(tensor_X_train, tensor_y_train)\n",
    "t_test_dataset = TensorDataset(tensor_X_test, tensor_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip k-means codebook strategy, since flattened image is 32 * 32-long sequence with pixels in [0, 255] ...\n",
    "# but do it anyway to trim some data nonetheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1/8, re-initialized 1 dead clusters\n",
      "done step 2/8, re-initialized 0 dead clusters\n",
      "done step 3/8, re-initialized 0 dead clusters\n",
      "done step 4/8, re-initialized 0 dead clusters\n",
      "done step 5/8, re-initialized 0 dead clusters\n",
      "done step 6/8, re-initialized 0 dead clusters\n",
      "done step 7/8, re-initialized 0 dead clusters\n",
      "done step 8/8, re-initialized 0 dead clusters\n"
     ]
    }
   ],
   "source": [
    "# run kmeans\n",
    "\n",
    "def kmeans(x, ncluster, niter=10):\n",
    "    N, D = x.size()\n",
    "    c = x[torch.randperm(N)[:ncluster]]  # init clusters at random\n",
    "    for i in range(niter):\n",
    "        # assign all pixels to the closest codebook element\n",
    "        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)\n",
    "        \n",
    "        # move each codebook element to be the mean of the pixels that assigned to it\n",
    "        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])\n",
    "        \n",
    "        # re-assign any poorly positioned codebook elements\n",
    "        nanix = torch.any(torch.isnan(c), dim=1)\n",
    "        ndead = nanix.sum().item()\n",
    "        \n",
    "        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))\n",
    "        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels\n",
    "n_pixels = 5\n",
    "pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(flattened_image_size, image_channels)[torch.randperm(flattened_image_size)[:n_pixels], :]\n",
    "px = torch.cat([pluck_rgb(x) for x, y in t_train_dataset], dim=0).float()\n",
    "\n",
    "ncluster = 8  # 8-color = 3-bit image\n",
    "with torch.no_grad():\n",
    "    C = kmeans(px, ncluster, niter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the training examples with our codebook to visualize how much we've lost in the discretization\n",
    "# these images should look normal ideally\n",
    "\n",
    "n_samples = 32\n",
    "n_cols = 8\n",
    "n_rows = n_samples // n_cols\n",
    "fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))\n",
    "for ax, i in zip(axis.ravel(), np.random.randint(0, len(t_train_dataset), size=n_samples)):\n",
    "    # encode and decode random data\n",
    "    x, y = t_train_dataset[i]\n",
    "    xpt = torch.from_numpy(np.array(x)).float().view(flattened_image_size, image_channels)\n",
    "    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments for each pixel\n",
    "    \n",
    "    sample = C[ix].view(pixel_size, pixel_size, image_channels).numpy().astype(np.uint8)\n",
    "    ax.imshow(sample[..., 0], cmap='magma')\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.savefig('results/clustered.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pt_dataset, clusters, perm=None):\n",
    "        self.pt_dataset = pt_dataset\n",
    "        self.clusters = clusters\n",
    "        self.perm = torch.arange(flattened_image_size) if perm is None else perm\n",
    "        \n",
    "        self.vocab_size = clusters.size(0)\n",
    "        self.block_size = flattened_image_size - 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pt_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.pt_dataset[idx]\n",
    "        x = torch.from_numpy(np.array(x)).view(-1, image_channels)  # flatten out all pixels\n",
    "        x = x[self.perm].float()  # reshuffle pixels with any fixed permutation and -> float\n",
    "        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1)  # cluster assignments\n",
    "        return a[:-1], a[1:]  # always just predict the next one in the sequence\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(t_train_dataset, C)\n",
    "test_dataset = ImageDataset(t_test_dataset, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.model import GPT, GPTConfig, GPT1Config\n",
    "\n",
    "mconf = GPTConfig(\n",
    "    train_dataset.vocab_size,\n",
    "    train_dataset.block_size,\n",
    "    embd_pdrop=0.0,\n",
    "    resid_pdrop=0.0,\n",
    "    attn_pdrop=0.0,\n",
    "    n_layer=12,\n",
    "    n_head=8,  # number of head self-attention\n",
    "    n_embd=256  # d-dimensional embedding for each pixel\n",
    ")\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "tokens_per_epoch = len(train_dataset) * train_dataset.block_size\n",
    "train_epochs = 30 # todo run a bigger model and longer, this is tiny\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "checkpoint_path = './latest_model.pt'\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=train_epochs, \n",
    "    batch_size=4, \n",
    "    learning_rate=3e-3,\n",
    "    betas=(0.9, 0.95), \n",
    "    weight_decay=0,\n",
    "    lr_decay=True,\n",
    "    warmup_tokens=tokens_per_epoch,\n",
    "    final_tokens=train_epochs * tokens_per_epoch,\n",
    "    ckpt_path=checkpoint_path,\n",
    "    num_workers=1\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train()  # WARNING: this blows CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # load the state of the best model we've seen based on early stopping\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to sample we also have to technically \"train\" a separate model for the first token in the sequence\n",
    "# we are going to do so below simply by calculating and normalizing the histogram of the first token\n",
    "\n",
    "counts = torch.ones(ncluster)  # start counts as 1 not zero, this is called \"smoothing\"\n",
    "rp = torch.randperm(len(train_dataset))\n",
    "nest = X_train.shape[0] // 2  # how many images to use for the estimation\n",
    "for i in range(nest):\n",
    "    a, _ = train_dataset[int(rp[i])]\n",
    "    t = a[0].item()  # index of first token in the sequence\n",
    "    counts[t] += 1\n",
    "\n",
    "prob = counts / counts.sum()  # normalize to have sum (prob) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.utils import sample\n",
    "\n",
    "n_samples = 40\n",
    "start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob.numpy())\n",
    "start_pixel = torch.from_numpy(start_pixel).to(trainer.device)\n",
    "pixels = sample(model, start_pixel, flattened_image_size - 1, temperature=1.0, sample=True, top_k=4)  # WARNING: this blows CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization we have to invert the permutation used to produce the pixels\n",
    "iperm = torch.argsort(train_dataset.perm)\n",
    "\n",
    "n_cols = 8\n",
    "n_rows = n_samples // n_cols\n",
    "fig, axis = plt.subplots(n_rows, n_cols, figsize=(16, 8))\n",
    "for i, ax in enumerate(axis.ravel()):\n",
    "    pxi = pixels[i][iperm]  # undo the encoding permutation\n",
    "    pxi = C[pxi].view(pixel_size, pixel_size, 0).numpy().astype(np.uint8)  # grayscale -> 2D\n",
    "    \n",
    "    ax.imshow(pxi, cmap='magma')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.savefig('results/samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some of the learned positional embeddings, maybe they contain structure\n",
    "\n",
    "n_see = 8 * 8\n",
    "n_cols = 8\n",
    "n_rows = n_see // n_cols\n",
    "fig, axis = plt.subplots(n_rows, n_cols, figsize=(4, 4))\n",
    "for i, ax in enumerate(axis.ravel()):\n",
    "    ci = model.pos_emb.data[0, :, i].cpu()\n",
    "    zci = torch.cat((torch.tensor([0.0]), ci))  # pre-cat a zero\n",
    "    rzci = zci[iperm]  # undo the permutation to recover the pixel space of the image\n",
    "    embd = rzci.view(pixel_size, pixel_size).numpy()\n",
    "\n",
    "    ax.imshow(embd, cmap='jet')\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "plt.savefig('results/pos_embd_karp.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUT",
   "language": "python",
   "name": "cut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
