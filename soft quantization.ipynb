{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 4\n",
    "t = 11\n",
    "first_blow = 6\n",
    "embd_size = 13\n",
    "\n",
    "idx = torch.rand(b, t)  # 4 x 1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 11]) tensor([[[1.0000, 0.9067, 0.1870, 1.0000, 0.4365, 0.5388, 1.0000, 0.1947,\n",
      "          0.5917, 1.0000, 0.1421],\n",
      "         [0.7780, 1.0000, 0.7130, 0.8128, 1.0000, 1.0000, 0.8128, 0.7275,\n",
      "          1.0000, 0.9735, 0.6216],\n",
      "         [0.2227, 0.4057, 1.0000, 0.2430, 0.8428, 0.6827, 0.2430, 1.0000,\n",
      "          0.6217, 0.3486, 1.0000]],\n",
      "\n",
      "        [[0.6907, 0.3554, 0.1691, 0.5126, 0.1400, 1.0000, 0.4900, 1.0000,\n",
      "          1.0000, 0.6359, 1.0000],\n",
      "         [1.0000, 0.9829, 0.6779, 1.0000, 0.6169, 0.7146, 1.0000, 0.8565,\n",
      "          0.6774, 1.0000, 0.6524],\n",
      "         [0.5326, 1.0000, 1.0000, 0.7177, 1.0000, 0.1879, 0.7508, 0.2698,\n",
      "          0.1688, 0.5785, 0.1566]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.6171, 0.3263, 0.9488, 0.1444, 0.1453, 0.4485,\n",
      "          0.7538, 0.3871, 0.8208],\n",
      "         [0.7616, 0.6871, 1.0000, 0.9418, 1.0000, 0.6265, 0.6285, 1.0000,\n",
      "          1.0000, 1.0000, 1.0000],\n",
      "         [0.2134, 0.1737, 0.5961, 1.0000, 0.3877, 1.0000, 1.0000, 0.8203,\n",
      "          0.4881, 0.9504, 0.4482]],\n",
      "\n",
      "        [[1.0000, 0.7094, 0.7872, 0.8963, 0.7703, 0.1577, 0.4130, 1.0000,\n",
      "          0.6498, 0.6354, 1.0000],\n",
      "         [0.7094, 1.0000, 1.0000, 1.0000, 1.0000, 0.6548, 1.0000, 0.8624,\n",
      "          1.0000, 1.0000, 0.7764],\n",
      "         [0.1851, 0.5186, 0.4673, 0.4104, 0.4776, 1.0000, 0.8909, 0.2736,\n",
      "          0.5661, 0.5790, 0.2218]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 11])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_batchwise(func, M):\n",
    "    tList = [ func(m) for m in torch.unbind(M, dim=0) ]  # batch is first index\n",
    "    return torch.stack(tList, dim=0)\n",
    "\n",
    "\n",
    "def minmax_norm():\n",
    "    def _f(x):\n",
    "        d = lambda x: torch.div(x, torch.max(x))\n",
    "        return apply_batchwise(d, x)\n",
    "    \n",
    "    return _f\n",
    "\n",
    "\n",
    "def normal(mu, sigma):\n",
    "    def _f(x):\n",
    "          return 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (x - mu)**2 / (2 * sigma**2))\n",
    "    return _f\n",
    "\n",
    "  \n",
    "def soft_quant(classes, sigma, norm=minmax_norm(), trans=True):\n",
    "    basis = torch.linspace(0, classes - 1, classes)\n",
    "        \n",
    "    def _f(x):\n",
    "        N = normal(x * (classes - 1), sigma)\n",
    "        vector = torch.stack([\n",
    "            N(b) for b in basis\n",
    "        ], dim=0)\n",
    "        \n",
    "        if norm:\n",
    "            vector = norm(torch.transpose(vector, 0, 1))\n",
    "            vector = torch.transpose(vector, 0, 1)\n",
    "        \n",
    "        if trans:\n",
    "            vector = torch.transpose(vector, 0, 1)\n",
    "\n",
    "        return vector\n",
    "    return _f\n",
    "\n",
    "\n",
    "def soft_torch(**kwargs):\n",
    "    s = soft_quant(**kwargs)\n",
    "\n",
    "    def _f(x):  # x ~ batch x elements\n",
    "        return apply_batchwise(s, x)\n",
    "\n",
    "    return _f\n",
    "\n",
    "\n",
    "te = soft_torch(classes=3, sigma=1, trans=False)(idx)\n",
    "print(te.shape, te)\n",
    "\n",
    "gc = nn.Conv1d(3, 256, kernel_size=1, stride=1, bias=False)\n",
    "gc(te).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figsize(n_rows, n_cols):\n",
    "    row_size = 8  # heigth\n",
    "    column_size = 20  # width\n",
    "\n",
    "    return (n_cols * column_size, n_rows * row_size)\n",
    "\n",
    "\n",
    "def get_figa(n_rows, n_cols):\n",
    "    fig, ax = plt.subplots(n_rows, n_cols, figsize=get_figsize(n_rows, n_cols))\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7e20cc6280>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/stefano/scratch/_kernels/.venv/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[0;34m(self, prop)\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/jh/_kernels/.venv/lib/python3.8/site-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[0;34m(filename, hinting_factor)\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/stefano/scratch/_kernels/.venv/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_soft_classes = 256\n",
    "\n",
    "\n",
    "def normal(mu, sigma):\n",
    "    def _f(x):\n",
    "          return 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (x - mu)**2 / (2 * sigma**2))\n",
    "    return _f\n",
    "\n",
    "  \n",
    "def soft_quant(classes=32, sigma=10, norm=None):\n",
    "    def _f(x):\n",
    "        N = normal(x, sigma)\n",
    "        vector = [\n",
    "            N(b)\n",
    "            for b in range(classes)\n",
    "        ]\n",
    "        \n",
    "        if norm:\n",
    "            return norm(vector)\n",
    "        \n",
    "        return vector\n",
    "    return _f\n",
    "  \n",
    "\n",
    "s = soft_quant(n_soft_classes, sigma=10, norm=softmax)\n",
    "basis = list(range(n_soft_classes))\n",
    "\n",
    "fig, axis = get_figa(1, 1)\n",
    "batch = np.random.uniform(0, n_soft_classes, size=4)\n",
    "representation = s(batch).T  # 4 x 256\n",
    "\n",
    "for x, r in zip(batch, representation):    \n",
    "    axis.plot(basis, r, label='{:.3f}'.format(x))\n",
    "    axis.vlines(x=x, ymin=min(r), ymax=max(r), color='black', linestyle='dotted')\n",
    "    \n",
    "axis.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57444252, 0.42555748])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([0.5, 0.2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
